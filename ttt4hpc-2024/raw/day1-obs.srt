1
00:00:00,000 --> 00:00:02,000
CodeRefinery.org

2
00:00:30,000 --> 00:00:32,060
you

3
00:01:00,000 --> 00:01:02,060
you

4
00:01:30,000 --> 00:01:32,060
you

5
00:02:00,000 --> 00:02:02,060
you

6
00:02:30,000 --> 00:02:32,060
you

7
00:03:00,000 --> 00:03:02,060
you

8
00:03:30,000 --> 00:03:32,060
you

9
00:04:00,000 --> 00:04:02,060
you

10
00:04:30,000 --> 00:04:32,060
you

11
00:05:00,000 --> 00:05:02,060
you

12
00:05:30,000 --> 00:05:32,060
you

13
00:06:00,000 --> 00:06:02,060
you

14
00:06:30,000 --> 00:06:32,060
you

15
00:07:00,000 --> 00:07:02,060
you

16
00:07:30,000 --> 00:07:32,060
you

17
00:08:00,000 --> 00:08:02,060
you

18
00:08:30,000 --> 00:08:32,060
you

19
00:09:00,000 --> 00:09:02,060
you

20
00:09:30,000 --> 00:09:32,060
you

21
00:10:00,000 --> 00:10:02,060
you

22
00:10:30,000 --> 00:10:32,060
you

23
00:11:00,000 --> 00:11:02,060
you

24
00:11:30,000 --> 00:11:32,060
you

25
00:12:00,000 --> 00:12:02,060
you

26
00:12:30,000 --> 00:12:32,060
you

27
00:13:00,000 --> 00:13:02,060
you

28
00:13:30,000 --> 00:13:32,060
you

29
00:14:00,000 --> 00:14:02,060
you

30
00:14:30,000 --> 00:14:39,120
Test, test, can anyone hear us out there?

31
00:14:39,120 --> 00:14:41,120
Check, check.

32
00:14:41,120 --> 00:14:45,880
Test, test, one, one, two, two.

33
00:14:45,880 --> 00:14:49,720
I think I need to make the instructors a little bit louder.

34
00:14:49,720 --> 00:14:53,680
Can someone say something?

35
00:14:53,680 --> 00:14:56,680
Saying something.

36
00:14:56,680 --> 00:15:11,240
Let's see. Okay, someone says, sound okay. Good. Yeah, welcome everyone. So, here we

37
00:15:11,240 --> 00:15:22,000
are. We're live. Hopefully, every will get lots of people coming. We're in the icebreaker

38
00:15:22,000 --> 00:15:25,600
time now. So let's see, what do we have for icebreakers?

39
00:15:27,600 --> 00:15:33,600
I've got a couple of generic demographics icebreakers.

40
00:15:33,600 --> 00:15:34,700
Let's see what people are.

41
00:15:36,900 --> 00:15:37,800
So how does this work?

42
00:15:37,800 --> 00:15:44,200
So if you are registered, you should have a link to this

43
00:15:44,200 --> 00:15:47,000
note.coderefinery.org document.

44
00:15:47,400 --> 00:15:49,900
You should be able to switch to edit mode.

45
00:15:49,900 --> 00:15:53,420
and then basically write stuff here.

46
00:15:53,420 --> 00:15:56,240
So this is the way we use to communicate.

47
00:15:56,240 --> 00:15:59,240
So instead of the Twitch chat, which is linear,

48
00:15:59,240 --> 00:16:01,040
you can come here,

49
00:16:01,040 --> 00:16:04,640
you can ask questions in any order.

50
00:16:04,640 --> 00:16:10,640
We have a section for questions which is appearing down here,

51
00:16:10,640 --> 00:16:13,440
and answer and ask anytime.

52
00:16:13,440 --> 00:16:18,480
So yeah, let's see what people say.

53
00:16:18,480 --> 00:16:23,560
There was a good icebreaker from last night, what was it?

54
00:16:23,560 --> 00:16:30,160
How would you explain HPC to someone from a hundred years ago?

55
00:16:30,160 --> 00:16:31,160
Should we add that there?

56
00:16:31,160 --> 00:16:32,160
I'm adding it.

57
00:16:32,160 --> 00:16:41,840
There we go, we see it coming.

58
00:16:41,840 --> 00:16:52,920
is so difficult. I mean, in the 19th century, there used to be some calculators. So maybe

59
00:16:52,920 --> 00:16:58,480
that would be the metaphor. And they are probably steam-operated, right?

60
00:16:58,480 --> 00:17:04,560
Steam machines that keep this going. And then we need a mechanism to send messages from one

61
00:17:04,560 --> 00:17:10,280
steam factory to the other, like some conveyor belts or something. That's the network. And

62
00:17:10,280 --> 00:17:15,560
all just work together. Maybe the industrial revolution, is that like a metaphor for HPC?

63
00:17:20,600 --> 00:17:26,520
Yeah. Or the printing machines that, you know, that you're able to

64
00:17:27,720 --> 00:17:34,920
in parallel print the same book. Yeah. I guess the high performance part,

65
00:17:34,920 --> 00:17:44,120
Well, computing part, do we have to explain what computing is to someone from a hundred

66
00:17:44,120 --> 00:17:45,120
years ago?

67
00:17:45,120 --> 00:17:49,920
I guess there's probably some mechanical calculators as an analogy.

68
00:17:49,920 --> 00:17:50,920
I think so.

69
00:17:50,920 --> 00:17:58,320
These ones with the, you know, the wheel that you could sum and subtract.

70
00:17:58,320 --> 00:18:02,000
So can we say we made that much, much, much faster?

71
00:18:02,000 --> 00:18:10,440
all using electricity. And then, say, for the high-performance part, say, we can't make

72
00:18:10,440 --> 00:18:17,680
one of these fast enough, so we make a lot of them, and then they communicate together

73
00:18:17,680 --> 00:18:26,800
really efficiently.

74
00:18:26,800 --> 00:18:29,780
Electricity existed back then, right?

75
00:18:29,780 --> 00:18:32,700
Like saying there's electric lights.

76
00:18:32,700 --> 00:18:33,700
Technically.

77
00:18:33,700 --> 00:18:38,300
Technically, as electricity has been there before us, but yeah.

78
00:18:38,300 --> 00:18:41,240
Did telegraphs exist back then?

79
00:18:41,240 --> 00:18:51,100
I think it's the last few decades of the 19th century, I think, let me check.

80
00:18:51,100 --> 00:18:54,020
No, actually, it was 1835.

81
00:18:54,020 --> 00:18:55,020
Okay.

82
00:18:55,020 --> 00:19:00,300
like the most or yeah no that was the [?] coat

83
00:19:05,180 --> 00:19:11,900
but anyway yeah it's exciting to be here because we've been planning and discussing this course

84
00:19:11,900 --> 00:19:18,220
for maybe i don't know two years or something like that and today finally it's happening

85
00:19:21,340 --> 00:19:24,700
so what would you say is the spirit of this course like why are you here what do you

86
00:19:25,020 --> 00:19:27,620
what's the thing about what we do?

87
00:19:29,440 --> 00:19:30,720
Well, I don't know.

88
00:19:30,720 --> 00:19:32,760
At least I've never seen something like this

89
00:19:32,760 --> 00:19:35,660
that we are putting together in this four episode

90
00:19:35,660 --> 00:19:37,560
in a sense that we've been running

91
00:19:37,560 --> 00:19:39,300
and I'm sure we've been taking part

92
00:19:39,300 --> 00:19:43,060
to introductory courses to HPC,

93
00:19:43,060 --> 00:19:44,460
but at the end of the day, okay, good.

94
00:19:44,460 --> 00:19:47,320
You learned those commands that you need to run,

95
00:19:47,320 --> 00:19:51,140
but it's the daily struggling with working

96
00:19:51,140 --> 00:19:54,260
with these clusters and remote and local

97
00:19:54,260 --> 00:20:02,340
And so something that I guess everyone has just learned by doing on their own or by watching

98
00:20:02,340 --> 00:20:03,980
others.

99
00:20:03,980 --> 00:20:09,940
So I wish I had this type of introduction, I don't know, 15 years ago when I started.

100
00:20:09,940 --> 00:20:10,940
Yeah.

101
00:20:10,940 --> 00:20:19,340
I'd say it's best practices filtered by people at different centers, so really taking the

102
00:20:19,340 --> 00:20:23,940
most common, most useful.

103
00:20:23,940 --> 00:20:28,880
And I think what is so fun is that we will see that many, many things are really similar

104
00:20:28,880 --> 00:20:29,880
across all the centers.

105
00:20:29,880 --> 00:20:33,280
We will also probably see that some things are not a little bit different.

106
00:20:33,280 --> 00:20:37,000
As instructors, we hope that they are not we will not.

107
00:20:37,000 --> 00:20:40,700
We are a little bit afraid that some things that we assume to work works everywhere might

108
00:20:40,700 --> 00:20:43,380
not work everywhere.

109
00:20:43,380 --> 00:20:49,360
But it's also to me the first first time that we try something like this cross border trying

110
00:20:49,360 --> 00:20:53,220
to distill out what is what is it that is common?

111
00:20:53,220 --> 00:20:56,140
And what can we learn from all of us?

112
00:20:56,140 --> 00:21:02,560
And can we somehow abstract away the details and focus on the big picture?

113
00:21:02,560 --> 00:21:06,980
So for me, the course is really about the big picture.

114
00:21:06,980 --> 00:21:14,680
Do any of you know about other courses which actually use multiple, like is taught and

115
00:21:14,680 --> 00:21:20,300
have participants with access to multiple different clusters by different organizations

116
00:21:20,300 --> 00:21:25,380
and the course might work for them.

117
00:21:25,380 --> 00:21:26,380
Not across borders.

118
00:21:26,380 --> 00:21:27,380
No.

119
00:21:27,380 --> 00:21:34,580
I guess maybe our June kickstart course is the closest then.

120
00:21:34,580 --> 00:21:35,580
Yeah.

121
00:21:35,580 --> 00:21:36,580
Even that is.

122
00:21:36,580 --> 00:21:37,580
Yeah.

123
00:21:37,580 --> 00:21:43,420
But yeah, so during that June kickstart course, something we always heard was people, it was

124
00:21:43,420 --> 00:21:49,060
a basic course where people saw, well, how to get started.

125
00:21:49,060 --> 00:21:56,340
But then there's a lot of people who want some lessons about how we actually use it,

126
00:21:56,340 --> 00:22:02,460
like what's the advanced side of things, which is a little bit hard to teach because if you

127
00:22:02,460 --> 00:22:08,580
have basic people just learning the cluster and command line and advanced people, you

128
00:22:08,580 --> 00:22:15,260
can't really easily serve both audiences at the same time.

129
00:22:15,260 --> 00:22:22,460
So here what we've done is, this is not a basic course, and in fact a lot of things

130
00:22:22,460 --> 00:22:34,480
you see might be too advanced to really fit in one thing together, but, I mean not too

131
00:22:34,480 --> 00:22:41,660
advanced for most people here, for everyone here to do, but instead it's cool demos.

132
00:22:41,660 --> 00:22:46,180
how we actually use it, you can get some ideas, and then go back and study yourself.

133
00:22:46,180 --> 00:22:50,500
Okay, did I finally say that properly?

134
00:22:50,500 --> 00:22:52,500
Yep.

135
00:22:52,500 --> 00:22:54,500
Okay.

136
00:23:11,660 --> 00:23:21,480
So, what are the topics for today? Who are the teachers? Is it [name] and [name]?

137
00:23:21,480 --> 00:23:27,960
So the first part will be [name] and me, and the second part is [name] and [name]. And today

138
00:23:27,960 --> 00:23:34,840
we talk about resource use. We will do a super brief intro into what is high-performance computing,

139
00:23:34,840 --> 00:23:41,040
but really like in one minute, in two minutes. And then how do we, how do we use resources

140
00:23:41,040 --> 00:23:45,680
really in a good way. How should we approach it? And what are the different dimensions

141
00:23:45,680 --> 00:23:54,060
there? So we'll talk about number of cores, amount of memory, time, and then input output.

142
00:23:54,060 --> 00:24:01,040
So how should we think about reading from disk and writing to disk?

143
00:24:01,040 --> 00:24:09,640
And I saw some really cool pictures last night, which were like, well, made by [name]. Such

144
00:24:09,640 --> 00:24:12,760
an amazing metaphor for what the cluster's doing.

145
00:24:12,760 --> 00:24:13,760
So...

146
00:24:13,760 --> 00:24:17,280
Yeah, and there are different possible analogies.

147
00:24:17,280 --> 00:24:24,200
We might mention some of them, just to get a real-world analogy to what's going on.

148
00:24:24,200 --> 00:24:30,000
Okay, should we get started then?

149
00:24:30,000 --> 00:24:31,600
Let's see.

150
00:24:31,600 --> 00:24:35,960
So I think [name] and I, we're going to do a short introduction.

151
00:24:35,960 --> 00:24:41,280
So can we do a poll, who's done a live stream course before?

152
00:24:41,280 --> 00:24:44,160
Can someone add that while we're talking?

153
00:24:44,160 --> 00:24:47,540
I can add it.

154
00:24:47,540 --> 00:24:58,640
So this is a live stream course, which means that

155
00:24:58,640 --> 00:25:04,600
you don't interact with us directly, instead we have this notes document.

156
00:25:04,600 --> 00:25:07,120
So there is the Twitch chat.

157
00:25:07,120 --> 00:25:11,960
We recommend you don't use that because we don't watch it really closely.

158
00:25:11,960 --> 00:25:15,480
We have all the questions here, which means that you can ask any time.

159
00:25:15,480 --> 00:25:19,060
We can come back and answer asynchronously.

160
00:25:19,060 --> 00:25:23,360
We have multiple different people here in the background who will be answering the questions

161
00:25:23,360 --> 00:25:26,080
at the same time the instructors are talking.

162
00:25:26,080 --> 00:25:32,040
So feel free to dump in all your most advanced questions there, and we'll answer what we

163
00:25:32,040 --> 00:25:37,360
can during the course, and in the afternoon we'll go through and answer the rest of them.

164
00:25:37,360 --> 00:25:39,860
So this is really a time to answer whatever.

165
00:25:39,860 --> 00:25:43,440
At the same time, there's going to be a lot of questions there.

166
00:25:43,440 --> 00:25:48,300
One common problem people complain about at the end of every course is that there's too

167
00:25:48,300 --> 00:25:53,000
much information, I couldn't follow all the notes.

168
00:25:53,000 --> 00:25:56,400
Notes is what we call this document here.

169
00:25:56,400 --> 00:26:03,380
And for that, well, what we say is, if you can't follow the notes, then don't.

170
00:26:03,380 --> 00:26:06,040
It's really kind of simple when you look at it that way.

171
00:26:06,040 --> 00:26:14,320
We know there's too much there, so leave it, don't try to follow it all, and go back

172
00:26:14,320 --> 00:26:16,200
in the afternoon, whatever.

173
00:26:16,200 --> 00:26:20,440
You can even write your question there and not look at the answer until later.

174
00:26:20,440 --> 00:26:27,560
And at the same time, many people feel that this notes way works really well because you

175
00:26:27,560 --> 00:26:30,720
actually can ask questions that you couldn't ask before.

176
00:26:30,720 --> 00:26:33,760
And there is more interaction than usual.

177
00:26:33,760 --> 00:26:35,440
So do use it.

178
00:26:35,440 --> 00:26:40,080
If you happen to be watching and haven't registered, register and you will get the link.

179
00:26:40,080 --> 00:26:43,120
So it's only for registered participants.

180
00:26:43,120 --> 00:26:51,080
And registering does really help us to justify the time we put into here because of the number

181
00:26:51,080 --> 00:26:53,440
of people we get.

182
00:26:53,440 --> 00:26:55,320
This is being recorded.

183
00:26:55,320 --> 00:27:04,760
We will see about publishing the recordings later versus leaving the Q&A and writing available.

184
00:27:04,760 --> 00:27:08,040
Let's see, what else can go wrong?

185
00:27:08,040 --> 00:27:15,000
If the stream suddenly dies, that means my computer has crashed, in which case wait a

186
00:27:15,000 --> 00:27:18,280
few minutes and I will bring it back up.

187
00:27:18,280 --> 00:27:24,920
So that's happened only once during a meeting, I think, because Zoom has crashed.

188
00:27:24,920 --> 00:27:30,320
But anyway, something to be aware of.

189
00:27:30,320 --> 00:27:35,720
If it doesn't come back up, I guess that means my computer is really broken or the internet

190
00:27:35,720 --> 00:27:43,740
is completely down, in which case, well, I guess we've got a problem anyway.

191
00:27:43,740 --> 00:27:47,780
What else?

192
00:27:47,780 --> 00:27:57,180
The notes will always contain updates for how to, like, where we are.

193
00:27:57,180 --> 00:28:00,540
So if you scroll up, you'll see right now we're in a questions mode.

194
00:28:00,540 --> 00:28:08,220
We will add in sections for each page we go to, so you can always catch up again.

195
00:28:08,220 --> 00:28:13,860
And here we see someone writing that we were in the intro.

196
00:28:13,860 --> 00:28:16,380
What else can happen?

197
00:28:16,380 --> 00:28:22,820
A cat can come and visit me, in which case I will turn on my video, because that always

198
00:28:22,820 --> 00:28:24,300
entertains people.

199
00:28:24,300 --> 00:28:26,700
That's what we call the opposite of a problem.

200
00:28:26,700 --> 00:28:36,500
I don't know if any other people will have cats coming and visiting them.

201
00:28:36,500 --> 00:28:38,660
Do use the notes immediately.

202
00:28:38,660 --> 00:28:44,100
If for example you can't understand, or we're too quiet, or you can't see what you need

203
00:28:44,100 --> 00:28:54,020
on the screen, whatever, just throw it in there and say, help, I can't see, I can't, whatever.

204
00:28:54,020 --> 00:28:58,220
Yeah, with that said, I mean, welcome.

205
00:28:58,220 --> 00:29:00,660
So should we begin then?

206
00:29:00,660 --> 00:29:01,660
Yeah.

207
00:29:01,660 --> 00:29:08,700
Maybe I could briefly mention because this was asked that this, the core structure in

208
00:29:08,700 --> 00:29:15,420
the morning, we will have two hours of kind of lecture based and then for those who are

209
00:29:15,420 --> 00:29:20,100
willing to try these things and so on in the afternoon, there will be a Zoom session that

210
00:29:20,100 --> 00:29:28,260
will not be recorded so that everyone can freely ask questions, form groups and do the

211
00:29:28,260 --> 00:29:35,100
exercises together. And a couple of have asked about credits. So yes, it is possible to receive

212
00:29:35,100 --> 00:29:41,460
credits and I added some details on the course web page. And what else? Well, this is kind

213
00:29:41,460 --> 00:29:48,380
of the first ever run of this course. So it's more like a pilot of the maybe official run

214
00:29:48,380 --> 00:29:56,220
which will be later in the year, in the fall. So most likely I will send anonymous questionnaires

215
00:29:56,220 --> 00:30:01,100
and feedback and any sort of feedback you can have, be as critical as you can so that we can

216
00:30:01,900 --> 00:30:05,260
make it turn this beta version into the release one.

217
00:30:07,180 --> 00:30:12,780
Otherwise I think I don't have any other practical details so I'm happy to pass the

218
00:30:12,780 --> 00:30:17,580
voice to pass the stage to our instructors.

219
00:30:17,580 --> 00:30:23,860
Super, I will take the screen share first and then let's introduce ourselves and let's

220
00:30:23,860 --> 00:30:24,860
get started.

221
00:30:24,860 --> 00:30:33,620
Here, I still need to adjust it a little bit.

222
00:30:33,620 --> 00:30:36,420
And a question to the studio, should I make it a little bit wider?

223
00:30:36,420 --> 00:30:38,540
It can be a little bit wider.

224
00:30:38,540 --> 00:30:39,540
How about this?

225
00:30:39,540 --> 00:30:40,540
Looks good.

226
00:30:40,540 --> 00:30:41,540
Yeah.

227
00:30:41,540 --> 00:30:42,540
Okay.

228
00:30:42,540 --> 00:30:46,100
Okay, so then just a little adjustment here.

229
00:30:46,100 --> 00:30:47,700
Okay.

230
00:30:47,700 --> 00:30:49,440
So first, hello everybody.

231
00:30:49,440 --> 00:30:50,280
This is really exciting.

232
00:30:50,280 --> 00:30:52,820
First time we do something like this.

233
00:30:53,940 --> 00:30:55,320
And it's a pilot.

234
00:30:56,660 --> 00:30:58,220
And then later people can say,

235
00:30:58,220 --> 00:31:00,380
well, we were there when the pilot happened.

236
00:31:01,740 --> 00:31:02,740
Yeah, we are really excited.

237
00:31:02,740 --> 00:31:03,780
We are nervous.

238
00:31:03,780 --> 00:31:05,160
My name is [name].

239
00:31:06,180 --> 00:31:07,820
I will be co-teaching this.

240
00:31:07,820 --> 00:31:10,980
So I'm at University of TromsÃ¸ doing support

241
00:31:10,980 --> 00:31:17,140
in high-performance computing, but also in everything that is programming software development

242
00:31:17,140 --> 00:31:22,700
in research. And really looking forward to teach this together with [name] from Sweden.

243
00:31:22,700 --> 00:31:30,260
Yeah. Hi. Hi, everyone. I'm [name]. I'm working for Uppmax cluster at Uppsala University

244
00:31:30,260 --> 00:31:37,140
in Sweden. Very happy to be here. I'm also doing support for users as [name] been telling

245
00:31:37,140 --> 00:31:43,380
a little bit of RSC like. So yeah, really happy to be here. And we'll be teaching this

246
00:31:43,380 --> 00:31:51,700
together with [name] and [name]. So [name], maybe they'll introduce themselves later.

247
00:31:51,700 --> 00:31:59,780
Yeah. Okay. So the plan now, let me, let me show you where you can find everything. So

248
00:31:59,780 --> 00:32:04,860
hopefully you have this document that I'm sharing open. This is the, these are our notes.

249
00:32:04,860 --> 00:32:07,100
Please ask questions here.

250
00:32:07,100 --> 00:32:09,740
And here you can also find all the links.

251
00:32:09,740 --> 00:32:14,220
So if you have one, one thing open somewhere in your browser is this document.

252
00:32:14,220 --> 00:32:17,560
And here, please ask us lots of questions, we will be watching this.

253
00:32:17,560 --> 00:32:23,540
And this is now the best way to participate in the next two hours, we will have a break.

254
00:32:23,540 --> 00:32:27,740
So we will also take a break halfway through.

255
00:32:27,740 --> 00:32:32,820
And the next really two hours will be discussions demonstration.

256
00:32:32,820 --> 00:32:38,740
And if you scroll up to the top, you can also find all the like the link to the material

257
00:32:38,740 --> 00:32:44,300
I will open it up. So I will follow this link here. And if you open up this link, this is

258
00:32:44,300 --> 00:32:51,420
the lesson. And just to make it a bit more readable, I will zoom in. So what to expect,

259
00:32:51,420 --> 00:32:59,540
We will the next things we will know for the next 45 minutes.

260
00:32:59,540 --> 00:33:06,960
We will talk about really what is high performance computing in like two sentences.

261
00:33:06,960 --> 00:33:08,400
What is job scheduling?

262
00:33:08,400 --> 00:33:14,220
How do we schedule jobs on a high performance computing resource?

263
00:33:14,220 --> 00:33:17,140
We we are now on many clusters.

264
00:33:17,140 --> 00:33:19,900
I see that you are from different countries, different clusters.

265
00:33:19,900 --> 00:33:24,960
One thing that probably all clusters have in common these days is that they use a tool

266
00:33:24,960 --> 00:33:25,960
called Slurm.

267
00:33:25,960 --> 00:33:29,000
So we will tell you a little bit about the tool.

268
00:33:29,000 --> 00:33:34,120
And then using a visual analogy, we will then discuss two things.

269
00:33:34,120 --> 00:33:39,600
One is how to choose the number of cores.

270
00:33:39,600 --> 00:33:41,280
That's very important.

271
00:33:41,280 --> 00:33:45,940
And we will show you a method that almost always works.

272
00:33:45,940 --> 00:33:49,800
And then how to measure and choose the right amount of memory.

273
00:33:49,800 --> 00:33:55,680
why it matters, and how to do it, again, with a method that almost always works.

274
00:33:55,680 --> 00:33:58,600
And then we will discuss a little bit, we will take a break.

275
00:33:58,600 --> 00:34:07,000
And after that, we will talk about input output, how to use the disk in a good way.

276
00:34:07,000 --> 00:34:10,400
And later, we will have an exercise session, which is optional.

277
00:34:10,400 --> 00:34:12,600
The exercise session will not be streamed, not recorded.

278
00:34:12,600 --> 00:34:15,600
And then we can try these things out hands on.

279
00:34:15,600 --> 00:34:22,920
But now, the best way to participate is to watch what we do and ask us questions.

280
00:34:22,920 --> 00:34:25,920
So you don't have to type with us.

281
00:34:25,920 --> 00:34:36,440
All right, I will open up the first episode, which is job scheduling and Sloan Basics.

282
00:34:36,440 --> 00:34:41,120
And we will show you a few pictures and discuss a little bit.

283
00:34:41,120 --> 00:34:45,400
But very soon, I will also open up a terminal, I will log into one of these clusters, and

284
00:34:45,400 --> 00:34:49,960
And I will test these things out.

285
00:34:49,960 --> 00:34:54,460
The learning goals is that we really understand what the job scheduler tries to do.

286
00:34:54,460 --> 00:34:57,740
What is the motivation for a job scheduler?

287
00:34:57,740 --> 00:34:59,460
We know what is the motivation for the researcher.

288
00:34:59,460 --> 00:35:03,300
The motivation for the researcher is to, you want your calculation to start as soon as

289
00:35:03,300 --> 00:35:05,380
possible and to finish as soon as possible.

290
00:35:05,380 --> 00:35:06,460
That's what you want.

291
00:35:06,460 --> 00:35:10,500
But I will tell you what the job scheduler tries to do, and then we will learn how we

292
00:35:10,500 --> 00:35:13,620
we can work together with the computer.

293
00:35:15,660 --> 00:35:18,500
What are the dimensions of a job and how to specify them,

294
00:35:19,780 --> 00:35:24,500
but also understand that choosing good parameters

295
00:35:24,500 --> 00:35:26,260
will not only affect resource use,

296
00:35:26,260 --> 00:35:29,220
but also how long you wait in the queue.

297
00:35:29,220 --> 00:35:31,980
And these are things where you want to minimize.

298
00:35:33,160 --> 00:35:35,980
And what we want to give you is a good visual understanding

299
00:35:35,980 --> 00:35:37,720
of what a job scheduler does.

300
00:35:37,720 --> 00:35:42,220
And I'm watching the questions, so please keep them coming.

301
00:35:42,220 --> 00:35:43,880
Any comments, welcome.

302
00:35:43,880 --> 00:35:47,560
What is a supercomputer or a cluster?

303
00:35:47,560 --> 00:35:51,440
Probably many of you already know, so I'll try to keep it really short.

304
00:35:51,440 --> 00:35:53,080
It's a large collection of computers.

305
00:35:53,080 --> 00:35:57,280
They are connected together through a network.

306
00:35:57,280 --> 00:36:01,680
And each of these computers is often called a node.

307
00:36:01,680 --> 00:36:03,880
And some clusters have thousands of these nodes.

308
00:36:03,880 --> 00:36:07,240
They have thousands of these little computers.

309
00:36:07,240 --> 00:36:11,220
And these compute nodes often have multiple cores.

310
00:36:11,220 --> 00:36:19,140
So when we talk about cores, we often use it synonymous to CPUs.

311
00:36:19,140 --> 00:36:24,800
But some of these compute nodes also have graphical processing units.

312
00:36:24,800 --> 00:36:31,900
What is surprising to when when people start working on a on a supercomputer or a cluster.

313
00:36:31,900 --> 00:36:35,080
And for me, a supercomputer and a cluster is the same thing.

314
00:36:35,080 --> 00:36:40,840
But what is surprising to people starting on supercomputers and clusters is that these

315
00:36:40,840 --> 00:36:46,000
these cores are often not faster than the ones that are in my laptop.

316
00:36:46,000 --> 00:36:47,640
But the difference is there are many more.

317
00:36:47,640 --> 00:36:53,480
So in my laptop are I don't know, six, and in on on the supercomputer are there could

318
00:36:53,480 --> 00:36:55,940
be 50,000.

319
00:36:55,940 --> 00:37:00,720
So it's not faster, it's more sometimes faster.

320
00:37:00,720 --> 00:37:05,340
And then the nodes are connected through a high speed network.

321
00:37:05,340 --> 00:37:11,060
The other thing that is different is they often share a common file system.

322
00:37:11,060 --> 00:37:17,220
So all of these many compute nodes, they can all read and write from a common file system.

323
00:37:17,220 --> 00:37:25,260
And we will, we will discuss what that means in the second part of today.

324
00:37:25,260 --> 00:37:29,700
And then when we log into clusters to do our work, we typically log in through some of

325
00:37:29,700 --> 00:37:35,780
a login node, and then I will submit a job. I submit a calculation which then waits in

326
00:37:35,780 --> 00:37:43,500
the queue until it starts and then it runs on the compute node. So that's just for background.

327
00:37:43,500 --> 00:37:49,620
And of course, the other comment, if I forget something really essential. Now I said that

328
00:37:49,620 --> 00:37:54,380
the one thing that is probably common to all the clusters that we are on today is a tool

329
00:37:54,380 --> 00:38:02,820
called slurm is it is a tool that helps scheduling and queuing and monitoring jobs on these compute

330
00:38:02,820 --> 00:38:09,500
nodes. Jobs often have to wait a little bit before they start, because the resource is

331
00:38:09,500 --> 00:38:16,980
limited. And one analogy is, you can think of slurm as like the matter the inner at the

332
00:38:16,980 --> 00:38:21,740
restaurant, so the person who is at the entrance of a restaurant, and if you want, if you come

333
00:38:21,740 --> 00:38:27,300
there without a table booking, without a reservation, and you want a table for eight people, you

334
00:38:27,300 --> 00:38:31,580
might need to wait a little bit. And Slurm really works the same way. We have a limited

335
00:38:31,580 --> 00:38:37,020
resource, we have a lot of demand, and there needs to be somebody in charge of scheduling

336
00:38:37,020 --> 00:38:44,500
and making sure that, yeah, just managing the queue. It is, Slurm is the most widely

337
00:38:44,500 --> 00:38:48,700
used job scheduler these days. It's not the only one, but I think it's the most widely

338
00:38:48,700 --> 00:38:55,420
use one and the visual so there are different analogies you could think

339
00:38:55,420 --> 00:39:02,060
about restaurant reservation or hotel reservation the one analogy I will we

340
00:39:02,060 --> 00:39:07,460
will use today is if maybe many of you remember playing this game here so the

341
00:39:07,460 --> 00:39:13,980
blocks fall from the sky and you need to arrange them to fill up rows so this is

342
00:39:13,980 --> 00:39:14,980
It's a Tetris game.

343
00:39:18,100 --> 00:39:21,180
And we can think of a job scheduler doing something similar.

344
00:39:23,060 --> 00:39:25,020
And here I try to translate it.

345
00:39:25,020 --> 00:39:27,860
Like how does a job scheduler look at jobs?

346
00:39:29,340 --> 00:39:31,300
These calculations for a job scheduler,

347
00:39:31,300 --> 00:39:32,700
they are often rectangular.

348
00:39:32,700 --> 00:39:37,700
So we don't have these like stair shape or T shape.

349
00:39:38,500 --> 00:39:40,100
All of these calculations

350
00:39:40,100 --> 00:39:43,860
are the first approximation rectangular.

351
00:39:43,860 --> 00:39:47,300
And here in this plot, I have, there are different colors.

352
00:39:47,300 --> 00:39:50,740
And then the job scheduler tries to arrange them.

353
00:39:50,740 --> 00:39:52,540
And what the job scheduler really wants to do

354
00:39:52,540 --> 00:39:55,420
is to keep the bottom row always full.

355
00:39:57,940 --> 00:40:01,780
And here the dimension could be the number of cores

356
00:40:01,780 --> 00:40:05,380
or a memory or the number of GPUs.

357
00:40:06,700 --> 00:40:08,940
And the other dimension is time.

358
00:40:08,940 --> 00:40:11,900
So as time goes on, new blocks fall from the sky

359
00:40:11,900 --> 00:40:16,060
And Slurm is constantly busy arranging these blocks.

360
00:40:20,720 --> 00:40:22,200
So we can think of that the scheduler

361
00:40:22,200 --> 00:40:25,160
tries to keep the bottom row always full.

362
00:40:25,160 --> 00:40:26,720
So the motivation for the job scheduler

363
00:40:26,720 --> 00:40:29,560
is keep all the cores busy all the time.

364
00:40:29,560 --> 00:40:33,040
That's what the computer wants because it was expensive.

365
00:40:33,040 --> 00:40:37,900
It would be a waste of taxpayer money to keep them idling.

366
00:40:37,900 --> 00:40:44,820
What is the motivation for me as a researcher, I want my job to get started and finished

367
00:40:44,820 --> 00:40:49,940
as soon as possible.

368
00:40:49,940 --> 00:40:56,020
And then there are long jobs that take a lot of time but maybe only a few course in this

369
00:40:56,020 --> 00:40:58,260
case it's this violet job here.

370
00:40:58,260 --> 00:41:03,360
So that it takes a number of time units but not too many resources.

371
00:41:03,360 --> 00:41:10,320
And then there are the so called wide jobs this green, the green set, which is lots of

372
00:41:10,320 --> 00:41:14,800
resources but not very long time.

373
00:41:14,800 --> 00:41:21,520
And the cost of a job is the area of this of these rectangles, you can think of it that

374
00:41:21,520 --> 00:41:23,820
way.

375
00:41:23,820 --> 00:41:27,200
And that is of course just a simplification now imagine there is one more dimension.

376
00:41:27,200 --> 00:41:32,860
So here we look at the 2d Tetris but imagine the Tetris is 3d, three dimensional or four

377
00:41:32,860 --> 00:41:39,940
dimensional because the third dimension could be memory.

378
00:41:39,940 --> 00:41:44,460
So what is maybe more realistic is that the scheduler plays kind of a cubicle Tetris all

379
00:41:44,460 --> 00:41:46,460
the time.

380
00:41:46,460 --> 00:41:49,520
And some of these jobs crash immediately.

381
00:41:49,520 --> 00:41:53,900
Some of these jobs are added to the queue but get canceled.

382
00:41:53,900 --> 00:41:57,660
So they never start.

383
00:41:57,660 --> 00:41:59,140
And I think that's maybe.

384
00:41:59,140 --> 00:42:00,560
So hopefully that's a useful analogy.

385
00:42:00,560 --> 00:42:03,300
But now let's, what can we do with this?

386
00:42:03,300 --> 00:42:11,180
If we, so first of all, something I want to tell you is that today, now in the next 40

387
00:42:11,180 --> 00:42:13,020
minutes, we want to discuss these dimensions.

388
00:42:13,020 --> 00:42:14,080
So how do I choose?

389
00:42:14,080 --> 00:42:20,960
How do I tell my job whether it should use, you know, five blocks or 20?

390
00:42:20,960 --> 00:42:23,420
How do I choose the dimension number of course?

391
00:42:23,420 --> 00:42:26,680
How do I choose the number of dimension time?

392
00:42:26,680 --> 00:42:31,620
And how do I choose the third dimension that we don't see here, which is the memory?

393
00:42:31,620 --> 00:42:35,020
How do I do technically, but also which number should I use?

394
00:42:35,020 --> 00:42:40,420
So that's the goal for the first part.

395
00:42:40,420 --> 00:42:46,220
Once we accept that this is maybe a useful analogy, we can even understand concepts like

396
00:42:46,220 --> 00:42:48,140
backfilling.

397
00:42:48,140 --> 00:42:55,980
And to tell you what that means is, so we have this situation currently, currently what

398
00:42:55,980 --> 00:43:02,740
is really running the sort of the processes they are busy computing the bottom row.

399
00:43:02,740 --> 00:43:06,700
And they just finished the bottom row and now they will switch to the second row. So

400
00:43:06,700 --> 00:43:12,620
now they will switch to compute this one here, the second row. And now imagine suddenly this

401
00:43:12,620 --> 00:43:19,300
pink, the pink job suddenly crashes. It crashes after two seconds.

402
00:43:19,300 --> 00:43:23,520
So what do you think will happen Maybe question to my co instructor

403
00:43:23,520 --> 00:43:31,080
Yeah, so then the turquoise top job is going to fill in that space.

404
00:43:31,080 --> 00:43:37,420
Yeah, so the schedule with notice that pink jobs crashes suddenly there are eight of these

405
00:43:37,420 --> 00:43:44,280
places available. And in this situation, the job schedule doesn't have any it will notice

406
00:43:44,280 --> 00:43:48,860
is that, hmm, I can actually move this one down here

407
00:43:48,860 --> 00:43:50,820
and it can start immediately.

408
00:43:51,680 --> 00:43:52,520
It can backfill.

409
00:43:52,520 --> 00:43:55,060
It can even start before the other green job starts

410
00:43:55,060 --> 00:43:56,740
because the green cannot start immediately.

411
00:43:56,740 --> 00:43:58,580
It doesn't have enough space for it.

412
00:43:58,580 --> 00:44:00,620
So something that the job scheduler cannot do,

413
00:44:00,620 --> 00:44:03,120
it cannot turn the pieces.

414
00:44:03,120 --> 00:44:04,020
It cannot do that.

415
00:44:05,380 --> 00:44:07,680
So now we also understand what backfilling means.

416
00:44:07,680 --> 00:44:09,780
And what I wanted to tell with this is that

417
00:44:09,780 --> 00:44:18,100
It matters how long the time the time a job is scheduled for will matter on how soon it

418
00:44:18,100 --> 00:44:20,820
can start.

419
00:44:20,820 --> 00:44:30,140
If a job is short, and suddenly, some resources become available, I can go in and and get the

420
00:44:30,140 --> 00:44:31,860
get the resources.

421
00:44:31,860 --> 00:44:37,820
Okay, and now, how does it look really in real life?

422
00:44:37,820 --> 00:44:40,180
Here I have an example slum script.

423
00:44:40,180 --> 00:44:50,820
So this is what, this is how we tell the high performance computing cluster of what we want.

424
00:44:50,820 --> 00:44:51,980
Here is my computation.

425
00:44:51,980 --> 00:44:56,700
I want to compute something currently, let's not focus too much on what we do, but I need

426
00:44:56,700 --> 00:45:03,100
to tell now here in this block, I tell the scheduler of what, what will I need?

427
00:45:03,100 --> 00:45:05,480
And often you need to specify the account.

428
00:45:05,480 --> 00:45:11,440
So this is the, you have like a quota of how many of these jobs you can run and how long

429
00:45:11,440 --> 00:45:12,440
they can run.

430
00:45:12,440 --> 00:45:16,680
So this is my, this is my account, you give it a name.

431
00:45:16,680 --> 00:45:19,960
But here is the one dimension, this is the time dimension.

432
00:45:19,960 --> 00:45:22,940
This job here would run for five minutes.

433
00:45:22,940 --> 00:45:28,160
So minutes, seconds, hours, days.

434
00:45:28,160 --> 00:45:33,320
Often there is a limit on how long you can run on some of clusters in Norway.

435
00:45:33,320 --> 00:45:36,920
The limit is either one week or two weeks.

436
00:45:36,920 --> 00:45:41,480
But there exists clusters where the limit can be one day.

437
00:45:41,480 --> 00:45:49,480
Here is the other dimension and tasks and task is this number of course, approximately.

438
00:45:49,480 --> 00:45:54,120
So in this case, I would ask for four course.

439
00:45:54,120 --> 00:45:57,440
And here we ask also for the how much memory I need.

440
00:45:57,440 --> 00:46:01,040
So this is how you do it technically.

441
00:46:01,040 --> 00:46:09,000
So then the question is, is it a good idea to specify the memory needed for the job?

442
00:46:09,000 --> 00:46:15,000
On some clusters, you have to, if you don't have to, or you can maybe leave it out.

443
00:46:15,000 --> 00:46:19,880
And then it will take, it will assume that you want approximately the memory that the

444
00:46:19,880 --> 00:46:21,920
CPU has.

445
00:46:21,920 --> 00:46:26,480
On one of the clusters in Norway, where I work, we, we have to specify it because it

446
00:46:26,480 --> 00:46:33,440
It depends whether multiple researchers can run their jobs simultaneously on one compute

447
00:46:33,440 --> 00:46:35,080
node or not.

448
00:46:35,080 --> 00:46:41,160
And if yes, you often need to specify this because this is then also a limited resource.

449
00:46:41,160 --> 00:46:43,840
And depending on the cluster, you might need to specify more.

450
00:46:43,840 --> 00:46:48,520
Sometimes you need to specify something called partition because there are different partitions

451
00:46:48,520 --> 00:46:51,860
in the resource.

452
00:46:51,860 --> 00:46:52,860
And you can do a lot more.

453
00:46:52,860 --> 00:46:56,100
can specify the number of nodes or how many of the,

454
00:46:56,100 --> 00:46:59,280
how many tasks per node one can do a lot.

455
00:47:02,220 --> 00:47:04,560
I listed here some more options that might be handy one day,

456
00:47:04,560 --> 00:47:08,540
which is how is the, how are the outputs called?

457
00:47:08,540 --> 00:47:11,760
You can even make some calculations dependent

458
00:47:11,760 --> 00:47:13,000
on other calculations.

459
00:47:13,000 --> 00:47:16,320
So if you want one calculation to only start,

460
00:47:16,320 --> 00:47:20,560
once the other one finishes, you can define dependencies

461
00:47:20,560 --> 00:47:25,280
And you can even submit an entire array of jobs,

462
00:47:25,280 --> 00:47:27,080
of very similar jobs.

463
00:47:27,080 --> 00:47:29,660
And later in this course, it will not happen today,

464
00:47:29,660 --> 00:47:31,860
but one of the future weeks,

465
00:47:31,860 --> 00:47:36,860
we will show you how do we split up a computation

466
00:47:38,760 --> 00:47:41,800
into smaller pieces so that we can run them as an array.

467
00:47:45,480 --> 00:47:46,320
Okay, a few more things,

468
00:47:46,320 --> 00:47:48,620
but then I will also demonstrate this.

469
00:47:48,620 --> 00:47:53,740
And what I will then also demonstrate that once we have such a so-called run

470
00:47:53,740 --> 00:47:59,260
script, once we have the job script run script, then what we will do is we will

471
00:47:59,260 --> 00:48:04,420
submit it. And the command that I will use is sbatch. With sbatch I add

472
00:48:04,420 --> 00:48:09,700
my job to the queue. And I wait until the job scheduler tells me that

473
00:48:09,700 --> 00:48:12,700
now you can start.

474
00:48:13,060 --> 00:48:17,460
And instead of putting things into a script you can also specify all of these

475
00:48:17,460 --> 00:48:23,220
things on the command line, which I personally recommend not to do because if it's in the

476
00:48:23,220 --> 00:48:27,380
script, I don't have to remember it. I can open it up half a year later and I can see

477
00:48:27,380 --> 00:48:35,300
what I did. If I did it on the command line, I cannot remember it half a year later.

478
00:48:35,300 --> 00:48:42,140
What I would add is that I also like to use the script. The only time when I don't is

479
00:48:42,140 --> 00:48:46,020
If I want to do a test, a quick test job,

480
00:48:46,020 --> 00:48:48,720
just to see that the inputs I have in my job script

481
00:48:48,720 --> 00:48:53,460
are correct, then I would just add in the command line

482
00:48:53,460 --> 00:48:55,540
a shorter time for the job,

483
00:48:55,540 --> 00:48:58,340
just to see everything is working as it should.

484
00:48:58,340 --> 00:49:02,560
And also another exception is when I use dependencies,

485
00:49:02,560 --> 00:49:04,840
I have those in the command line,

486
00:49:04,840 --> 00:49:08,260
and then I just prepare different job scripts

487
00:49:08,260 --> 00:49:18,480
in different folders or as needed for different steps of my workflow.

488
00:49:18,480 --> 00:49:22,420
And here I list two more useful things that I use all the time. So I really only remember

489
00:49:22,420 --> 00:49:28,780
a handful of these commands. One is to list all my jobs. And sometimes I need to cancel

490
00:49:28,780 --> 00:49:35,060
a job and you don't. So to all the other learners here, the goal here is not that we remember

491
00:49:35,060 --> 00:49:40,420
all these slum commands. The goal is what Deanna and me will try to show you is how

492
00:49:40,420 --> 00:49:47,100
do we think about the job? How do we approach a job so that we choose these parameters? Because

493
00:49:47,100 --> 00:49:53,100
it's easy to look up, well, how do I specify it here? This is how, but what, what, what

494
00:49:53,100 --> 00:49:56,980
is much harder and I find really important. How do I choose the number? Should it be four

495
00:49:56,980 --> 00:50:02,940
or should it be 40? And should this be five minutes or should it be five hours? And that

496
00:50:02,940 --> 00:50:04,420
is that is the goal of today.

497
00:50:05,780 --> 00:50:08,580
So I will scroll down and this is really about

498
00:50:08,580 --> 00:50:11,040
how to choose the parameters, not technically.

499
00:50:11,900 --> 00:50:14,500
This we can look up, but how do I choose the number?

500
00:50:16,940 --> 00:50:21,400
And for the time, well, there are often time limits.

501
00:50:22,740 --> 00:50:25,580
And what we recommend is that, well, it's hard to predict.

502
00:50:25,580 --> 00:50:27,300
You need to maybe run a series of jobs

503
00:50:27,300 --> 00:50:29,940
and get a feeling for how much time it will take.

504
00:50:29,940 --> 00:50:32,100
Hopefully you can extrapolate

505
00:50:32,100 --> 00:50:35,260
and then maybe add 20%.

506
00:50:35,260 --> 00:50:38,860
Don't make it too long just in case.

507
00:50:38,860 --> 00:50:41,500
If I know that my job takes five minutes,

508
00:50:41,500 --> 00:50:44,220
it's not a good idea to ask for seven days

509
00:50:44,220 --> 00:50:47,940
because the job scheduler doesn't look,

510
00:50:47,940 --> 00:50:49,500
the job scheduler doesn't know,

511
00:50:49,500 --> 00:50:52,980
doesn't understand what I try to do down here.

512
00:50:52,980 --> 00:50:55,260
The job scheduler doesn't know my calculation.

513
00:50:55,260 --> 00:50:58,620
It doesn't know my code.

514
00:50:58,620 --> 00:51:00,660
It will look at what I'm asking for.

515
00:51:00,660 --> 00:51:04,500
And if I ask for seven days, then imagine back to Tetris,

516
00:51:04,500 --> 00:51:08,540
imagine this gigantically long piece that lasts seven days

517
00:51:08,540 --> 00:51:11,400
and it will try to fit it somewhere into the resources.

518
00:51:13,580 --> 00:51:16,680
So it might then queue for a very long time.

519
00:51:16,680 --> 00:51:19,740
If the job is short, ask for a short time.

520
00:51:19,740 --> 00:51:21,060
Also, when you debug a problem,

521
00:51:21,060 --> 00:51:25,740
try to reduce the system size to reduce the queue time.

522
00:51:25,740 --> 00:51:28,840
And I will show you that in a moment.

523
00:51:28,840 --> 00:51:35,280
And then in the next so now in the next half an hour we will really talk about how do I

524
00:51:35,280 --> 00:51:41,380
do this if I how do I decide how many course and how do I decide how much memory we will

525
00:51:41,380 --> 00:51:50,880
show you that just catching up here with questions whether anything that we should lift and discuss

526
00:51:50,880 --> 00:51:58,040
and while I look there I want to give a bit of a preview of what we will also do later

527
00:51:58,040 --> 00:52:09,560
in the course. One is that some jobs, if you look at them, they run for a long time, sometimes

528
00:52:09,560 --> 00:52:14,720
hours days. But if you really look at them and see what do they really do is that they

529
00:52:14,720 --> 00:52:20,760
they compute independent things one after the other. Sometimes there is a loop and we

530
00:52:20,760 --> 00:52:27,680
iterate over lots of tasks, lots of little units, but they are independent of each other

531
00:52:27,680 --> 00:52:29,600
or mostly independent of each other.

532
00:52:30,720 --> 00:52:33,460
And what we will do in,

533
00:52:34,960 --> 00:52:37,600
I think it will be the session number four of this course

534
00:52:37,600 --> 00:52:40,640
is we will show you how do you split it up

535
00:52:40,640 --> 00:52:42,780
into independent jobs.

536
00:52:44,400 --> 00:52:46,880
And maybe we also understand what can be the advantage

537
00:52:46,880 --> 00:52:48,920
because the advantage of doing that is that

538
00:52:48,920 --> 00:52:51,440
now the pieces that are now independent,

539
00:52:51,440 --> 00:52:55,600
they can fall down and they can start at the same time.

540
00:52:55,600 --> 00:52:57,640
And the scheduler has much more flexibility

541
00:52:57,640 --> 00:53:04,180
to fill up all the holes, and we will maybe get the result sooner, the overall result.

542
00:53:04,180 --> 00:53:10,680
What is the disadvantage is that we might need to combine the individual results into

543
00:53:10,680 --> 00:53:16,720
a combined result. So this is something for later. And one more thing I wanted to show

544
00:53:16,720 --> 00:53:25,280
is that I told you that all the jobs are rectangular or cubic cubic. But if you really look at

545
00:53:25,280 --> 00:53:31,160
them if you really open them up and see what is the actual resource use so here

546
00:53:31,160 --> 00:53:35,520
the gray thing imagine the like the whole rectangle is what I asked for

547
00:53:35,520 --> 00:53:41,540
maybe for CPUs and a certain amount of time but if I if I would open up the job

548
00:53:41,540 --> 00:53:47,000
and look into it often the resource the actual what is actually used is not

549
00:53:47,000 --> 00:53:52,400
rectangular but it varies over time at the beginning it it uses very few CPUs

550
00:53:52,400 --> 00:53:57,920
use, then it uses all of the CPUs for a certain amount of time. And then at the end, it uses

551
00:53:57,920 --> 00:54:07,600
half the CPUs for a certain amount of time. And why did I show that? Because sometimes

552
00:54:07,600 --> 00:54:13,880
it can be beneficial to so how could we solve this? If I some if I look at this job here,

553
00:54:13,880 --> 00:54:20,040
we are wasting almost half the resources. And one solution can be that we split up the

554
00:54:20,040 --> 00:54:26,280
job into pieces and run them one after the other because the pieces have

555
00:54:26,280 --> 00:54:31,740
different demands for resources and one way to cut here would be and I don't

556
00:54:31,740 --> 00:54:37,040
know whether you can see like my mouse pointer but I could cut here after two

557
00:54:37,040 --> 00:54:42,200
lines and after two lines I need a different resource and then I could cut

558
00:54:42,200 --> 00:54:47,720
again after the fourth line after the fourth row sometimes it can be

559
00:54:47,720 --> 00:54:54,660
beneficial to cut and then run them as independent, separate steps, separate jobs.

560
00:54:54,660 --> 00:54:57,400
And each of them have different resource demands.

561
00:54:57,400 --> 00:55:03,200
And I would add that if if they are not independent, then you may use dependencies to ensure that

562
00:55:03,200 --> 00:55:11,320
the middle block will start after the first one is finished, for example.

563
00:55:11,320 --> 00:55:13,400
Very good question on line 171.

564
00:55:13,400 --> 00:55:20,460
So do I have to ask here, I will also make that more visible.

565
00:55:20,460 --> 00:55:24,360
This question here, do I have to ask exactly the same amount of time and number of course

566
00:55:24,360 --> 00:55:28,680
for a job to start to make a square block.

567
00:55:28,680 --> 00:55:32,900
So don't ask exactly for the amount of time, add a little bit more.

568
00:55:32,900 --> 00:55:37,720
Because sometimes the CPUs are a little bit busier, it takes a little bit longer.

569
00:55:37,720 --> 00:55:41,620
So at 20% 25%.

570
00:55:41,620 --> 00:55:47,460
But you ask for a certain amount of course of the amount of memory certain amount of time.

571
00:55:47,460 --> 00:55:54,660
And even though your job internally might, the resource use might actually vary.

572
00:55:54,660 --> 00:55:56,700
But now we should really look at that.

573
00:55:56,700 --> 00:56:00,680
So let's talk about how do I choose the number of course.

574
00:56:00,680 --> 00:56:03,860
And let's talk about how do I choose the right amount of memory.

575
00:56:03,860 --> 00:56:10,200
And for this, I will open up the material, keep the questions coming, and I will also

576
00:56:10,200 --> 00:56:15,200
open up my terminal and we'll try these things out.

577
00:56:15,200 --> 00:56:24,760
And why it matters, I will now not go into details, but it matters both for the cluster,

578
00:56:24,760 --> 00:56:31,120
because if you use, if you choose well, we will have a better resource use.

579
00:56:31,120 --> 00:56:34,400
More calculations will be able to finish.

580
00:56:34,400 --> 00:56:37,100
More papers will be published.

581
00:56:37,100 --> 00:56:42,540
It also matters for you as a researcher because your computation will start sooner and sooner

582
00:56:42,540 --> 00:56:49,560
and you will pay less, although sometimes you don't pay for it.

583
00:56:49,560 --> 00:56:53,960
Sometimes it's the taxpayer who pays for it.

584
00:56:53,960 --> 00:56:56,720
So you don't want to ask for too many cores.

585
00:56:56,720 --> 00:57:00,960
You don't want to ask for too few, depending on what your goal is.

586
00:57:00,960 --> 00:57:04,120
And we don't want to waste resources.

587
00:57:04,120 --> 00:57:09,440
And the example project that I will use is

588
00:57:09,440 --> 00:57:13,600
So I wrote an example code, but we don't have to if you if you want to have a look at it,

589
00:57:13,600 --> 00:57:16,320
you can you can look at the code.

590
00:57:16,320 --> 00:57:19,200
We don't have to understand it.

591
00:57:19,200 --> 00:57:23,740
It's it's a road code written in a language called C.

592
00:57:23,740 --> 00:57:29,760
The big picture is that we simulate planets, imagine a galaxy of planets.

593
00:57:29,760 --> 00:57:34,960
And they all, there is gravitational force, so all of these planets attract each other.

594
00:57:34,960 --> 00:57:36,320
They have random position.

595
00:57:36,320 --> 00:57:39,740
They start with a random position and random velocity.

596
00:57:39,740 --> 00:57:43,760
And what this code does is that it, it does a little time step.

597
00:57:43,760 --> 00:57:46,980
It computes the gravitational force between all of planets.

598
00:57:46,980 --> 00:57:53,880
It adjusts the velocity and moves them a little bit.

599
00:57:53,880 --> 00:57:59,240
And then again, another time step, it computes gravitational force.

600
00:57:59,240 --> 00:58:02,080
It moves the planets a little bit.

601
00:58:02,080 --> 00:58:11,480
And we can, the code can use multiple cores and distribute the work across the cores.

602
00:58:11,480 --> 00:58:20,600
And then each of the cores will only move a smaller part of the planets.

603
00:58:20,600 --> 00:58:25,480
But we still need to exchange the positions of all the planets between the cores.

604
00:58:25,480 --> 00:58:26,560
So that's the communication.

605
00:58:26,560 --> 00:58:31,120
The cores have to communicate through the high-speed network, and they have to exchange

606
00:58:31,120 --> 00:58:35,440
the positions.

607
00:58:35,440 --> 00:58:39,440
But whatever, this is just an example.

608
00:58:39,440 --> 00:58:47,480
So I will build the code in a moment, we can run it, and the code is called planets.

609
00:58:47,480 --> 00:58:51,640
What is nice is that I can here on the command line, I will be able to specify how many planets,

610
00:58:51,640 --> 00:58:55,800
So here I have 30,000 random planets in a galaxy.

611
00:58:55,800 --> 00:58:59,080
And how many steps I want to run, 10,000 steps.

612
00:58:59,080 --> 00:59:05,000
And I can even make the network artificially slower.

613
00:59:05,000 --> 00:59:12,440
So I can increase the network penalty and simulate how long will it take if the network

614
00:59:12,440 --> 00:59:18,480
communication takes longer or less long.

615
00:59:18,480 --> 00:59:20,360
And here, it doesn't matter what the code does.

616
00:59:20,360 --> 00:59:25,420
What I want to find out is how on how many cores should I run it here somebody somebody

617
00:59:25,420 --> 00:59:34,060
ran the code on four cores, and it took a long time 11,000 seconds.

618
00:59:34,060 --> 00:59:39,660
The question that we have here in the next 10 minutes 15 minutes is

619
00:59:39,660 --> 00:59:45,920
Should I choose four or 40 or eight or what is the setting, how do we find out

620
00:59:45,920 --> 00:59:51,680
And how, so how do you, how do you approach this typically [name], and I can also, if you

621
00:59:51,680 --> 00:59:55,440
have such a question, how do we, how do we approach the problem?

622
00:59:55,440 --> 01:00:03,120
Whenever, whenever I run a new piece of software, I would start to find a manual or some documentation,

623
01:00:03,120 --> 01:00:11,720
some examples, as usual, someone has run this before using a certain size of the problem

624
01:00:11,720 --> 01:00:18,200
and it took that much time, I would try to do that, try to do something similar,

625
01:00:18,200 --> 01:00:24,120
maybe use the same input, try to play around with different sizes of the resources.

626
01:00:24,120 --> 01:00:28,680
I mean, different number of cores, maybe different number of nodes if it's parallelized.

627
01:00:29,320 --> 01:00:32,600
And of course, I mean, it may be different because all hardware is different.

628
01:00:32,600 --> 01:00:34,920
There are going to be different interconnects.

629
01:00:34,920 --> 01:00:36,760
So it's really something that one should test.

630
01:00:36,760 --> 01:00:49,760
And once I know how it scales maybe for a certain size of the problem, I should actually also keep in mind that it may scale differently if the size of the problem is different.

631
01:00:49,760 --> 01:01:00,760
So just because someone found certain scaling for a certain type of simulation does not mean that it's going to be the same if I change the input.

632
01:01:00,760 --> 01:01:04,760
So do your own tests, I would say.

633
01:01:04,760 --> 01:01:09,520
So yes, that's more or less what I would do.

634
01:01:09,520 --> 01:01:13,600
Thanks and what I try to do here in the meantime is I download the code and I try to compile

635
01:01:13,600 --> 01:01:20,160
it and this is so we don't expect here the learners to do that or to even remember how

636
01:01:20,160 --> 01:01:21,160
to do that.

637
01:01:21,160 --> 01:01:23,580
That's not the point.

638
01:01:23,580 --> 01:01:25,440
And it's also really different on different clusters.

639
01:01:25,440 --> 01:01:28,640
This is something we can then try later in the exercise session in the exercise session.

640
01:01:28,640 --> 01:01:31,080
We can actually all test it.

641
01:01:31,080 --> 01:01:38,800
I'm now loading a module on the cluster that I'm on which can then compile the code.

642
01:01:38,800 --> 01:01:43,560
And I'm following, I will compile the code.

643
01:01:43,560 --> 01:01:53,360
All right, and now I have the, I have the code here that I can run.

644
01:01:53,360 --> 01:02:00,880
And if I could now do this, but I don't want to wait 11,000 seconds.

645
01:02:00,880 --> 01:02:09,720
So I want to know, take some of these job scripts that I was talking about earlier,

646
01:02:09,720 --> 01:02:12,160
and I want to create a job script.

647
01:02:12,160 --> 01:02:20,080
And now how do we select the number of course, I will call it run.sh.

648
01:02:20,080 --> 01:02:27,560
And inside there, I have this example, I need to specify my project, which for me on my cluster

649
01:02:27,560 --> 01:02:30,580
happens to be some name.

650
01:02:30,580 --> 01:02:33,220
So this will not work for everybody else.

651
01:02:33,220 --> 01:02:42,620
I will start on eight course, nine minutes just though it's just a guess.

652
01:02:42,620 --> 01:02:52,580
And the first insight I wanted to everybody to take away is that

653
01:02:52,580 --> 01:02:57,020
if I look at this example that somebody gave me 10,000 steps, the first thing I would probably

654
01:02:57,020 --> 01:03:05,180
do I will think, do I really need 10,000 steps? And something I would probably test is how

655
01:03:05,180 --> 01:03:11,180
long does it take to run 10, 10 steps and 20 steps and 40 steps. And what I would then

656
01:03:11,180 --> 01:03:20,060
see is that in this case, the runtime is it scales linearly with the number of steps.

657
01:03:20,060 --> 01:03:25,340
Each step approximately cost the same. So I don't need to run 10,000 steps and I don't

658
01:03:25,340 --> 01:03:32,180
need to wait for 11,000 seconds to, to try to run this and to study this. So the first

659
01:03:32,180 --> 01:03:36,820
thing I will do, and this is also what I did here is I will do some testing and figure

660
01:03:36,820 --> 01:03:42,980
out that it might be actually okay to run just 100 tests, 100 steps. And this will,

661
01:03:42,980 --> 01:03:51,660
this will take a couple of seconds, minutes. What I try to achieve is a calculation that

662
01:03:51,660 --> 01:03:57,780
few minutes I don't want to I don't want to wait hours few minutes in this case

663
01:03:57,780 --> 01:04:04,220
it will take maybe a minute and then I often start with something and later I

664
01:04:04,220 --> 01:04:14,140
will vary this so I will change from 8 to 4 and 16 and 32 and 64 and 128 and it

665
01:04:14,140 --> 01:04:18,460
doesn't have to be a power of 2 but this is just was what computer people like to

666
01:04:18,460 --> 01:04:30,480
do. Let me submit this and see what happens as batch. Sorry, what? Sorry for these commands.

667
01:04:30,480 --> 01:04:38,820
So what I have this transcript and I can submit it. So now I sent my job to the queue. If

668
01:04:38,820 --> 01:04:46,420
I want to see how it is doing, it is now running. Nice. So this was a short job it there was

669
01:04:46,420 --> 01:04:51,220
somewhere there was some resource available and it immediately started

670
01:04:51,220 --> 01:04:55,620
and now i will impatiently repeat the command

671
01:04:56,260 --> 01:05:00,740
and i think it will take i don't know

672
01:05:02,100 --> 01:05:05,460
30 seconds 40 seconds

673
01:05:07,140 --> 01:05:11,940
and i did that now for eight cores now it should take approximately

674
01:05:11,940 --> 01:05:14,660
60 seconds

675
01:05:16,420 --> 01:05:27,920
We are going to do this exercise in, in two hours time. So you don't have to do it immediately.

676
01:05:27,920 --> 01:05:32,480
So everybody just watch this. And we know that on different clusters, the scripts look

677
01:05:32,480 --> 01:05:36,440
slightly different, but we will then help you help you with that. So later in the exercise,

678
01:05:36,440 --> 01:05:43,480
you can try this. You can also try this with your own code. So instead of simulating planets,

679
01:05:43,480 --> 01:05:45,580
you can try to do this study with your own code.

680
01:05:45,580 --> 01:05:46,920
And the two steps were,

681
01:05:48,020 --> 01:05:50,900
what is the shortest time that I can get away with

682
01:05:50,900 --> 01:05:55,900
and still get a representative answer in terms of timing.

683
01:05:57,300 --> 01:06:00,060
And then run it on a series of course.

684
01:06:02,380 --> 01:06:04,940
Did my job finish?

685
01:06:04,940 --> 01:06:06,740
It finished and then I can,

686
01:06:08,580 --> 01:06:11,780
simulation completed.

687
01:06:13,480 --> 01:06:23,660
In this case, this took almost a minute on eight cores, and I simulated 30,000 planets

688
01:06:23,660 --> 01:06:26,260
and 100 steps.

689
01:06:26,260 --> 01:06:32,720
If I would run it for 1000 steps, it will probably take 600 seconds.

690
01:06:32,720 --> 01:06:38,180
And something I will not do now, but what we can do later is we can really try it out

691
01:06:38,180 --> 01:06:44,220
instead of eight cores, 16 cores and 32 cores and so on and so on.

692
01:06:44,220 --> 01:06:48,700
Here I made it a little bit more readable on the table.

693
01:06:48,700 --> 01:06:50,980
And what can we see from this table?

694
01:06:50,980 --> 01:06:55,780
So the big question is how many cores should I use?

695
01:06:55,780 --> 01:06:58,180
And what do I see here?

696
01:06:58,180 --> 01:07:02,740
If you run it on one core, it takes 420 seconds.

697
01:07:02,740 --> 01:07:06,440
We double the resources, we half the time.

698
01:07:06,440 --> 01:07:12,360
We double the resources, we still half the time, we still half the time, still half the

699
01:07:12,360 --> 01:07:14,000
time.

700
01:07:14,000 --> 01:07:18,240
And now, now it's not any more half the time.

701
01:07:18,240 --> 01:07:24,540
You see that I don't doubling the resources at some point doesn't doesn't cut the time

702
01:07:24,540 --> 01:07:26,420
in half anymore.

703
01:07:26,420 --> 01:07:31,440
And something interesting happens here is that I went to lots of course 256 and the

704
01:07:31,440 --> 01:07:33,600
time even goes up.

705
01:07:33,600 --> 01:07:34,600
And why is that?

706
01:07:34,600 --> 01:07:41,440
point, the communication to update the positions of the planets to communicate between all

707
01:07:41,440 --> 01:07:47,480
the CPUs at some point is more costly than the computation. And in this case, where would

708
01:07:47,480 --> 01:07:51,280
you how many CPUs would you choose? [name], where would you stop?

709
01:07:51,280 --> 01:07:57,440
I would stop at 16. But it also depends on the number of cores on the cluster. Because

710
01:07:57,440 --> 01:08:06,240
Because if it's better that we fill up the note, then maybe 42 is a better number.

711
01:08:06,240 --> 01:08:09,280
So it really depends on, on the cluster configuration.

712
01:08:09,280 --> 01:08:12,320
So yeah, but somewhere there, 16 or 42.

713
01:08:12,320 --> 01:08:16,480
And it's important that you're thinking time spent per number of course.

714
01:08:16,480 --> 01:08:17,480
Yeah.

715
01:08:17,480 --> 01:08:22,720
And if you, if you don't, if you are in no hurry, maybe it is fine too.

716
01:08:22,720 --> 01:08:28,580
But we clearly see that in this case, it doesn't make any sense to run this on 256 cores.

717
01:08:28,580 --> 01:08:36,140
So here I would also choose 8 or 16, maybe 32 if there is a deadline and PhD has to be

718
01:08:36,140 --> 01:08:39,700
ready by Friday afternoon.

719
01:08:39,700 --> 01:08:42,620
But we don't move on much further.

720
01:08:42,620 --> 01:08:45,260
So what is the takeaway?

721
01:08:45,260 --> 01:08:50,700
Here the takeaway is two things.

722
01:08:50,700 --> 01:08:54,620
It's both for timing and for debugging.

723
01:08:54,620 --> 01:09:01,160
It can be really useful to reduce the time of the job so that it's so that this information

724
01:09:01,160 --> 01:09:04,040
is still meaningful.

725
01:09:04,040 --> 01:09:08,680
That is one skill and the other skill is run it on a series of course.

726
01:09:08,680 --> 01:09:11,520
And you don't have to do this for every job that you try to do.

727
01:09:11,520 --> 01:09:20,840
I do this only if I have if I plan to do 100 similar jobs.

728
01:09:20,840 --> 01:09:26,720
Then before running these 100 similar jobs, I do this study for one of those.

729
01:09:26,720 --> 01:09:29,960
And then all my 99 other jobs, I know what to choose.

730
01:09:29,960 --> 01:09:31,960
I know that I should choose 16.

731
01:09:31,960 --> 01:09:36,720
And I know that it will take so and so many seconds.

732
01:09:36,720 --> 01:09:40,020
So this calibration doesn't have to do for every single job that would be unreasonable

733
01:09:40,020 --> 01:09:43,300
as well.

734
01:09:43,300 --> 01:09:44,420
And thanks for all the questions.

735
01:09:44,420 --> 01:09:48,380
Thanks to my colleagues for answering them.

736
01:09:48,380 --> 01:09:53,540
And we have now I would like to take maybe 10 more minutes on talking about the memory

737
01:09:53,540 --> 01:09:56,180
part.

738
01:09:56,180 --> 01:10:01,580
And then we will take a break and talk about disk.

739
01:10:01,580 --> 01:10:08,300
So now I will switch over to this episode here, which is now that we know how to choose

740
01:10:08,300 --> 01:10:15,380
the number of cores. And this is really a method that really almost always works. I

741
01:10:15,380 --> 01:10:23,420
want to show you how do I choose the memory. Because sometimes you have to especially if

742
01:10:23,420 --> 01:10:34,760
you need more memory than the processor has. Let's open this up and let's try this out.

743
01:10:34,760 --> 01:10:40,680
Why does it matter similar motivation, it's

744
01:10:40,680 --> 01:10:45,060
If you ask for excessive number of memory

745
01:10:45,060 --> 01:10:49,000
You might block resources for for other people

746
01:10:49,000 --> 01:10:53,280
If you pay for the resource use, you might pay too much

747
01:10:53,280 --> 01:10:55,080
And you

748
01:10:55,080 --> 01:10:59,820
Your job may wait long or forever in the queue

749
01:10:59,820 --> 01:11:05,060
until these resources become available.

750
01:11:05,060 --> 01:11:10,940
Also later in the course, we will take a problem and we will chop it up into smaller problems

751
01:11:10,940 --> 01:11:14,400
and we will try to run them in parallel at the same time.

752
01:11:14,400 --> 01:11:23,860
We will try to have jobs that are independent and can compute simultaneously.

753
01:11:23,860 --> 01:11:29,580
And if I'm not careful about the memory, I might severely limit my ability to parallelize

754
01:11:29,580 --> 01:11:40,620
is my job. So it matters often. And I will, I want to show you how I do that. And this

755
01:11:40,620 --> 01:11:48,740
is a method that maybe I will show you two methods that are probably available on most

756
01:11:48,740 --> 01:11:54,940
of the clusters that we are on. So again, before running many similar jobs, I typically

757
01:11:54,940 --> 01:11:58,120
To calibrate, I don't do that for every computation,

758
01:11:58,120 --> 01:12:01,480
but if I plan to run a hundred similar computations,

759
01:12:01,480 --> 01:12:02,960
I do some calibration study.

760
01:12:02,960 --> 01:12:05,660
And here, what I want to calibrate here is the memory.

761
01:12:07,400 --> 01:12:12,400
And the example code that I will use now is a Python code.

762
01:12:14,840 --> 01:12:18,960
Again, this is something you can try later in the exercise.

763
01:12:18,960 --> 01:12:23,960
And this Python code, it computes,

764
01:12:25,460 --> 01:12:28,380
you can tell it to compute 5,000 random numbers

765
01:12:29,740 --> 01:12:32,180
between minus one and one, and to sum them up.

766
01:12:33,300 --> 01:12:36,900
You can also give it a certain time to wait

767
01:12:36,900 --> 01:12:39,320
between computing and summing.

768
01:12:40,180 --> 01:12:42,580
And I will show you why I did that.

769
01:12:43,740 --> 01:12:46,420
But let me go to, I will now go to a different cluster

770
01:12:46,420 --> 01:12:47,500
for reasons.

771
01:12:48,960 --> 01:12:53,780
So now I'm on a different cluster.

772
01:12:53,780 --> 01:12:58,300
Again, we are not expected to remember auto-type.

773
01:12:58,300 --> 01:13:00,100
I'm on a different Norwegian cluster.

774
01:13:02,980 --> 01:13:05,100
I will create a new folder for this.

775
01:13:07,220 --> 01:13:11,060
And I will try to run this Python code.

776
01:13:13,740 --> 01:13:14,900
Example.

777
01:13:19,920 --> 01:13:21,840
We don't have to look at the Python code.

778
01:13:26,080 --> 01:13:29,440
The Python code creates random numbers, sums them up, prints the result.

779
01:13:30,960 --> 01:13:33,280
Now, I should really...

780
01:13:35,680 --> 01:13:38,320
I should run a script for this. I should write a script for this.

781
01:13:38,320 --> 01:13:50,200
I should not run it directly on the command line or sorry directly on the login node so

782
01:13:50,200 --> 01:13:57,000
I will again write a little script which I will adjust and we will in the exercise adjust

783
01:13:57,000 --> 01:14:05,280
to our clusters that we are on I will again call it run.sh

784
01:14:05,280 --> 01:14:06,840
Let me discuss what we see here.

785
01:14:06,840 --> 01:14:08,720
I need to adjust my account.

786
01:14:08,720 --> 01:14:11,300
In my case, it happens to be this one.

787
01:14:12,720 --> 01:14:15,700
I give it a name, five minutes, absolutely enough.

788
01:14:17,280 --> 01:14:19,600
On this cluster, I have to specify memory.

789
01:14:20,680 --> 01:14:22,280
And I don't actually know how much.

790
01:14:22,280 --> 01:14:26,180
I will start with something, two and a half gigabyte,

791
01:14:26,180 --> 01:14:27,660
2,500 megabyte.

792
01:14:30,160 --> 01:14:33,880
For this example, I don't need more than one core.

793
01:14:33,880 --> 01:14:37,360
it will be run on one so-called task or one core.

794
01:14:38,560 --> 01:14:40,400
And now I could run it like this.

795
01:14:40,400 --> 01:14:44,200
I could sum up, here I want to sum up lots of numbers.

796
01:14:44,200 --> 01:14:45,980
How many are these?

797
01:14:45,980 --> 01:14:50,220
Million, 50 million numbers.

798
01:14:50,220 --> 01:14:53,320
I want to sum up 50 million random numbers.

799
01:14:53,320 --> 01:14:57,080
I want to wait for 10 seconds and then print me the result.

800
01:14:57,080 --> 01:14:58,280
I could run it like this,

801
01:14:59,640 --> 01:15:02,580
but one tool that is available almost everywhere,

802
01:15:02,580 --> 01:15:05,660
which is really nice is that you can put this one

803
01:15:05,660 --> 01:15:07,780
in front of any of your commands

804
01:15:08,660 --> 01:15:12,340
and it will measure the so-called high watermark

805
01:15:14,140 --> 01:15:15,500
of the memory use.

806
01:15:15,500 --> 01:15:19,060
You can think of like when you imagine

807
01:15:19,060 --> 01:15:21,700
there is like a flooding, you know, the water goes up

808
01:15:21,700 --> 01:15:23,820
and then the water disappears again

809
01:15:23,820 --> 01:15:26,980
and then you can see how far did the water reach.

810
01:15:26,980 --> 01:15:28,500
So that's a high watermark.

811
01:15:29,340 --> 01:15:31,620
And this tool will tell me this.

812
01:15:31,620 --> 01:15:34,480
So my code will allocate memory and it will tell me

813
01:15:34,480 --> 01:15:39,020
what was the highest memory allocation during the runtime.

814
01:15:42,980 --> 01:15:47,740
Let me submit this and let's see what happens.

815
01:15:47,740 --> 01:15:51,340
So again, I send it to the queuing system.

816
01:15:51,340 --> 01:15:53,220
I send it to Slurm to...

817
01:15:56,940 --> 01:15:58,620
And again, it was really short.

818
01:15:58,620 --> 01:15:59,860
It needs only one core.

819
01:15:59,860 --> 01:16:01,120
It started immediately.

820
01:16:01,120 --> 01:16:09,480
nice. I expect this to run. So I asked for 10 seconds, it will actually run for a bit

821
01:16:09,480 --> 01:16:17,520
longer than 10 seconds because the allocating 50 allocating and computing 50 million random

822
01:16:17,520 --> 01:16:21,600
numbers will take a little bit of time. It takes a few seconds. So it's still running

823
01:16:21,600 --> 01:16:36,280
Running 28 seconds, 31 seconds, and it will soon finish.

824
01:16:36,280 --> 01:16:38,400
Still running.

825
01:16:38,400 --> 01:16:43,560
Well, actually, maybe it will take a minute.

826
01:16:43,560 --> 01:16:49,200
But it gives me a chance to look at the questions here on the notes.

827
01:16:49,200 --> 01:16:53,380
Thanks a lot for all my colleagues for answering.

828
01:16:53,380 --> 01:16:56,760
And thank you all for the good questions.

829
01:16:56,760 --> 01:17:01,160
And we are maybe five minutes away from a break.

830
01:17:01,160 --> 01:17:11,080
All right, job finished.

831
01:17:11,080 --> 01:17:16,840
What we have here is my Python code, my job script, but now I also have an output from

832
01:17:16,840 --> 01:17:28,420
slurm and I will let's see what is in this output there is stuff here okay this

833
01:17:28,420 --> 01:17:37,280
doesn't belong here but the important thing with when putting /usr/bin/time -v

834
01:17:37,280 --> 01:17:44,100
in front of your command you will get this block here and

835
01:17:44,100 --> 01:17:46,040
And there are lots of numbers,

836
01:17:46,040 --> 01:17:48,780
but the one that I'm interested in is this one.

837
01:17:48,780 --> 01:17:50,680
Maximum resident set size.

838
01:17:51,600 --> 01:17:56,600
So this tells me that the code used,

839
01:17:57,080 --> 01:17:59,400
so this is kilobyte, so this would be,

840
01:18:01,020 --> 01:18:04,400
it would be almost 2000 megabytes.

841
01:18:04,400 --> 01:18:06,280
So approximately two gigabyte.

842
01:18:07,400 --> 01:18:09,400
That was the highest memory allocation

843
01:18:09,400 --> 01:18:10,800
during the run of the code.

844
01:18:10,800 --> 01:18:15,280
So that's one tool that is almost always available.

845
01:18:15,280 --> 01:18:19,960
This is the tool that I use to figure out what is the highest memory allocation and

846
01:18:19,960 --> 01:18:27,040
now I know and now for all my jobs I can take this number and maybe add 20% to it just to

847
01:18:27,040 --> 01:18:33,040
be on the safe side and then you know if you need to specify it.

848
01:18:33,040 --> 01:18:38,600
And in the material I will show you there is one more method which is I think available

849
01:18:38,600 --> 01:18:43,580
on all slurm scheduled clusters. I think so too.

850
01:18:43,580 --> 01:18:47,640
And I will try that method, it will tell it will give me a similar answer. But there is

851
01:18:47,640 --> 01:18:56,840
a risk to it. As act, I think this means maybe as accounting, then the job number, my job

852
01:18:56,840 --> 01:19:06,120
number here was this one. And then I am only interested in this maximum resident set size,

853
01:19:06,120 --> 01:19:10,840
which is the memory.

854
01:19:10,840 --> 01:19:14,520
And in this case, it tells me the result.

855
01:19:14,520 --> 01:19:17,920
It's again,

856
01:19:17,920 --> 01:19:22,760
almost approximately two gigabytes.

857
01:19:22,760 --> 01:19:27,920
The problem with this tool is that it uses sampling.

858
01:19:27,920 --> 01:19:31,520
Every on our clusters in Norway, every 30 seconds,

859
01:19:31,520 --> 01:19:33,320
it asks the job.

860
01:19:33,320 --> 01:19:36,360
What is the memory that you use right now?

861
01:19:36,360 --> 01:19:39,840
And 30 seconds later, it asks again.

862
01:19:39,840 --> 01:19:45,640
And if the job is shorter than 30 seconds, well, let's try.

863
01:19:45,640 --> 01:19:49,080
What happens if the job is shorter than 30 seconds?

864
01:19:49,080 --> 01:19:50,200
Let's make it shorter.

865
01:19:50,200 --> 01:19:54,440
Let's remove a zero here.

866
01:19:54,440 --> 01:19:56,640
Because that will make it shorter.

867
01:19:56,640 --> 01:20:02,220
And let's add only, I don't know, five seconds wait time.

868
01:20:02,220 --> 01:20:05,360
And I will submit again.

869
01:20:05,360 --> 01:20:10,420
It will finish way sooner.

870
01:20:10,420 --> 01:20:17,220
Because to compute 10 times less fewer number of sticks, I think it should finish hopefully

871
01:20:17,220 --> 01:20:18,700
in very soon.

872
01:20:18,700 --> 01:20:19,700
Now it finished.

873
01:20:19,700 --> 01:20:22,780
12 seconds in.

874
01:20:22,780 --> 01:20:30,460
I have now a second output.

875
01:20:30,460 --> 01:20:38,700
The the result from so this number here is still correct.

876
01:20:38,700 --> 01:20:44,420
In this case, it the the memory demand was 10 times lower.

877
01:20:44,420 --> 01:20:48,260
It's only 200 megabytes.

878
01:20:48,260 --> 01:20:54,180
But if I ask Slurm

879
01:20:54,180 --> 01:20:57,260
and now I need to replace the number by this number.

880
01:20:57,260 --> 01:21:02,100
it will tell me that, whoa, why is that?

881
01:21:02,100 --> 01:21:05,380
No, okay, because I made a mistake.

882
01:21:05,380 --> 01:21:07,000
It's not 34, it's 44.

883
01:21:08,620 --> 01:21:10,040
This is the right number, 44,

884
01:21:10,040 --> 01:21:12,740
because what I expected to see that the memory is zero.

885
01:21:13,760 --> 01:21:16,220
So this tool tells me that my job consumes zero memory,

886
01:21:16,220 --> 01:21:17,220
and that's not true.

887
01:21:19,260 --> 01:21:20,420
But to be fair to this tool,

888
01:21:20,420 --> 01:21:22,700
this tool uses sampling every 30 seconds.

889
01:21:22,700 --> 01:21:25,100
It had no chance to see the memory demand.

890
01:21:25,100 --> 01:21:27,920
And what I want you to take away from here

891
01:21:27,920 --> 01:21:31,400
is that depending on which tool you use,

892
01:21:31,400 --> 01:21:33,420
it might be using sampling.

893
01:21:34,620 --> 01:21:39,320
And if there is a memory peak, this tool might miss it.

894
01:21:40,760 --> 01:21:45,380
The other one, the other tool, USR Bintime,

895
01:21:46,400 --> 01:21:50,360
this one, to my knowledge, in my experience,

896
01:21:50,360 --> 01:21:53,560
will always report you the high memory watermark.

897
01:21:53,560 --> 01:21:54,860
It doesn't use sampling.

898
01:21:55,100 --> 01:22:01,540
Not in the same way.

899
01:22:01,540 --> 01:22:03,660
And maybe there are other tools.

900
01:22:03,660 --> 01:22:04,660
We can share them on the notes.

901
01:22:04,660 --> 01:22:07,620
We can then later share them in the exercise session.

902
01:22:07,620 --> 01:22:10,780
And again, in the exercise session, the goal will be that you can try this out with my

903
01:22:10,780 --> 01:22:13,420
example Python code.

904
01:22:13,420 --> 01:22:17,660
But what is maybe more interesting for you is to try this out with your own code and

905
01:22:17,660 --> 01:22:20,740
figure out how much memory does it really use.

906
01:22:20,740 --> 01:22:23,260
Yes, exactly.

907
01:22:23,260 --> 01:22:28,300
Sometimes it's good that you check the memory requirements

908
01:22:28,300 --> 01:22:30,180
for different sizes of your arguments,

909
01:22:30,180 --> 01:22:33,740
and maybe try to extrapolate, possibly,

910
01:22:33,740 --> 01:22:36,300
and get an idea on what you would actually

911
01:22:36,300 --> 01:22:38,780
need for your real simulations.

912
01:22:38,780 --> 01:22:40,420
And of course, I mean, this is easier

913
01:22:40,420 --> 01:22:47,620
to do if it's linear or square.

914
01:22:47,620 --> 01:22:52,660
But it's a good way to try to estimate that.

915
01:22:52,660 --> 01:22:57,700
And [name] said, I mean, at different clusters you may have different tools which can do this

916
01:22:58,500 --> 01:23:04,020
memory profiling. And we'll definitely talk about more in the exercise session. So.

917
01:23:04,740 --> 01:23:08,980
Yeah. And sometimes we get asked for a lot of memory.

918
01:23:10,580 --> 01:23:14,660
And sometimes the answer is to change the code. And many of the people who work in,

919
01:23:16,580 --> 01:23:19,300
who are instructors here and in the Code Refinery project,

920
01:23:19,300 --> 01:23:23,000
really like to help you also improve the code.

921
01:23:23,000 --> 01:23:25,580
So for those of you who write Python,

922
01:23:27,580 --> 01:23:29,560
there is a little bonus that you can see that

923
01:23:29,560 --> 01:23:32,360
just by changing two characters in the code,

924
01:23:32,360 --> 01:23:35,840
memory demand can go from a lot to almost zero.

925
01:23:37,480 --> 01:23:39,240
And good questions there can be,

926
01:23:39,240 --> 01:23:41,680
is there any way that we can change the sampling?

927
01:23:42,640 --> 01:23:45,080
To my knowledge, the user cannot change it.

928
01:23:45,080 --> 01:23:47,680
We can change the configuration of the cluster,

929
01:23:47,680 --> 01:23:49,860
but it happens to be configured for 30 seconds.

930
01:23:49,860 --> 01:23:53,560
So at least to my knowledge, it's not something I can change

931
01:23:53,560 --> 01:23:55,320
but please correct me if I'm wrong.

932
01:23:56,440 --> 01:23:58,120
And I don't want to eat more into the break time.

933
01:23:58,120 --> 01:24:01,040
I think so many good questions, so many good answers.

934
01:24:01,040 --> 01:24:04,720
I suggest we take a break and then we talk about disk.

935
01:24:06,240 --> 01:24:07,760
And how long will the break be?

936
01:24:07,760 --> 01:24:11,760
Maybe my studio colleagues can help me.

937
01:24:11,760 --> 01:24:13,220
Is it 15 minutes?

938
01:24:13,220 --> 01:24:20,500
Should we be back at 15 past the hour, but is that also right for the instructors who

939
01:24:20,500 --> 01:24:22,380
come after me?

940
01:24:22,380 --> 01:24:25,380
Maybe they can have a say?

941
01:24:25,380 --> 01:24:29,420
Yeah, 15 minutes works.

942
01:24:29,420 --> 01:24:30,420
Good.

943
01:24:30,420 --> 01:24:36,420
So then we'll be back 15 minutes past the hour, we will talk about DISC, and I will also then

944
01:24:36,420 --> 01:24:39,660
here have a look at all your questions and add more answers to it.

945
01:24:39,660 --> 01:24:41,740
Thanks so much for listening.

946
01:24:41,740 --> 01:24:46,860
the big picture got clear, the thinking got clear, the details we can always look up.

947
01:24:46,860 --> 01:24:51,740
Thanks to Deanna also for doing this here for going through the lesson here with me.

948
01:24:51,740 --> 01:24:55,100
See you in now 14 minutes.

949
01:24:55,100 --> 01:24:55,660
See you.

950
01:25:11,740 --> 01:25:13,800
you

951
01:25:41,740 --> 01:25:43,800
you

952
01:26:11,740 --> 01:26:13,800
you

953
01:26:41,740 --> 01:26:43,800
you

954
01:27:11,740 --> 01:27:13,800
you

955
01:27:41,740 --> 01:27:43,800
you

956
01:28:11,740 --> 01:28:13,800
you

957
01:28:41,740 --> 01:28:43,800
you

958
01:29:11,740 --> 01:29:13,800
you

959
01:29:41,740 --> 01:29:43,800
you

960
01:30:11,740 --> 01:30:13,800
you

961
01:30:41,740 --> 01:30:43,800
you

962
01:31:11,740 --> 01:31:13,800
you

963
01:31:41,740 --> 01:31:43,800
you

964
01:32:11,740 --> 01:32:13,800
you

965
01:32:41,740 --> 01:32:43,800
you

966
01:33:11,740 --> 01:33:13,800
you

967
01:33:41,740 --> 01:33:43,800
you

968
01:34:11,740 --> 01:34:13,800
you

969
01:34:41,740 --> 01:34:43,800
you

970
01:35:11,740 --> 01:35:13,800
you

971
01:35:41,740 --> 01:35:43,800
you

972
01:36:11,740 --> 01:36:13,800
you

973
01:36:41,740 --> 01:36:43,800
you

974
01:37:11,740 --> 01:37:13,800
you

975
01:37:41,740 --> 01:37:43,800
you

976
01:38:11,740 --> 01:38:13,800
you

977
01:38:41,740 --> 01:38:59,900
Hey welcome back. So we'll go back to the materials and talk about I.O. in a moment.

978
01:38:59,900 --> 01:39:08,380
Let's first do some quick introduction. So I'm [name]. I work at Aalto University so

979
01:39:08,380 --> 01:39:17,380
So I'm mostly familiar with the Triton cluster, and yeah, I work there as a software engineer.

980
01:39:17,380 --> 01:39:18,380
Yeah.

981
01:39:18,380 --> 01:39:21,740
Hi, my name is [name].

982
01:39:21,740 --> 01:39:26,280
I'm also from Aalto, so the same stuff.

983
01:39:26,280 --> 01:39:32,940
And today we'll talk a bit about IO best practices, or like IO in general.

984
01:39:32,940 --> 01:39:39,740
Yeah. So should we go just directly into the material?

985
01:39:39,740 --> 01:39:41,260
Yeah, let's do that.

986
01:39:41,260 --> 01:39:43,620
So I'll open this.

987
01:39:45,020 --> 01:39:52,180
So what we really want to go into is just,

988
01:39:52,180 --> 01:39:58,820
we want to give a model of how input and output works,

989
01:39:58,820 --> 01:40:06,660
and why it can be, or when it can be a bottleneck for your program.

990
01:40:06,660 --> 01:40:14,660
So, well, let's just go into it, because it's probably just better to show

991
01:40:14,660 --> 01:40:19,140
and show and tell rather than go through the objectives here.

992
01:40:19,140 --> 01:40:23,780
So compared to CPU and RAM that was mentioned previously,

993
01:40:23,780 --> 01:40:31,380
IO is a bit of this kind of like the eternal wallflower or like something that is not

994
01:40:31,380 --> 01:40:40,500
often discussed or it's not so heavily like it's not maintained by the Slurm. So Slurm doesn't

995
01:40:40,500 --> 01:40:47,860
necessarily know about the IO in the same way that memory and CPUs are like

996
01:40:47,860 --> 01:40:57,620
their resources. So with the IO, you need to be a bit more conscious of what the program

997
01:40:57,620 --> 01:41:06,420
does underneath it. And for this, we want to show first, what is file? And let's start

998
01:41:06,420 --> 01:41:15,900
with that. What is a file in a Linux file system? And file is metadata and file contents.

999
01:41:15,900 --> 01:41:22,840
And this metadata here doesn't mean metadata as in your dataset has metadata with it.

1000
01:41:22,840 --> 01:41:25,220
Your dataset describes what's in the data.

1001
01:41:25,220 --> 01:41:30,780
It means metadata as in who owns the file, when was it last modified, how big is the

1002
01:41:30,780 --> 01:41:34,180
file, and this kind of stuff.

1003
01:41:34,180 --> 01:41:38,900
And then the file contents is the actual byte data inside of it.

1004
01:41:38,900 --> 01:41:45,060
So that is the metadata that you would think about when you write, let's say, explanation

1005
01:41:45,060 --> 01:41:52,180
what your data set has. But the file system sees stuff like this. So file system sees the metadata

1006
01:41:52,180 --> 01:41:58,820
and the file contents. And when the metadata is accessed, this is done using these so-called

1007
01:41:58,820 --> 01:42:09,540
stat calls. So they check the stats or the status of the file. And the file contents are modified

1008
01:42:09,540 --> 01:42:17,540
by opening so-called file descriptors. So the file is opened. So if you're using like Python or

1009
01:42:17,540 --> 01:42:24,820
whatever like language, you usually have something like open a file and that is basically it opens

1010
01:42:24,820 --> 01:42:29,780
the file, it opens a file descriptor and then you can do like read and write calls to the file

1011
01:42:29,780 --> 01:42:36,820
that actually like take the data in and out of the file. So if we look at below,

1012
01:42:36,820 --> 01:42:45,820
We can see that, for example, if you run like an ls-l, that doesn't actually look at anything inside the file.

1013
01:42:45,820 --> 01:42:47,820
It will just check the metadata.

1014
01:42:47,820 --> 01:42:55,820
It will just show the permissions and ownerships of who owns the files and lists the file metadata.

1015
01:42:55,820 --> 01:43:01,820
And if you catenate the file with cat, so you just print it to the terminal,

1016
01:43:01,820 --> 01:43:07,900
know, that basically means that, okay, open the file or read only like file

1017
01:43:07,900 --> 01:43:13,100
descriptor, read everything that is inside the file and print it out into the

1018
01:43:13,100 --> 01:43:13,860
standard output.

1019
01:43:14,900 --> 01:43:16,820
So it will only access the file contents.

1020
01:43:17,060 --> 01:43:20,380
And if you don't have access to the file, or if you don't have permissions, then,

1021
01:43:20,660 --> 01:43:26,380
um, it doesn't, it can't, cannot do it, but, um, it, it will just try to access

1022
01:43:26,380 --> 01:43:31,340
the file contents and let's keep this as, as this kind of a, like a backdrop for

1023
01:43:31,340 --> 01:43:33,420
what we're about to demo then.

1024
01:43:33,420 --> 01:43:35,540
So we have a few demos.

1025
01:43:35,540 --> 01:43:38,900
So [name], do you want to describe the demos a bit?

1026
01:43:38,900 --> 01:43:39,860
Yeah.

1027
01:43:39,860 --> 01:43:43,100
So like in the previous one, so these are demonstrations.

1028
01:43:43,100 --> 01:43:47,940
So the intention is not that you follow along,

1029
01:43:47,940 --> 01:43:50,540
but that it's not that you type along,

1030
01:43:50,540 --> 01:43:52,380
but that you follow.

1031
01:43:52,380 --> 01:43:53,620
But there are instructions here,

1032
01:43:53,620 --> 01:43:55,820
and this is where the examples are.

1033
01:43:55,820 --> 01:44:00,180
And after each section,

1034
01:44:00,180 --> 01:44:06,340
is expected results which should tell you or give you an idea of whether your result if you run the

1035
01:44:06,340 --> 01:44:13,700
code is what I was expecting when I wrote this. So you can run them on your own and you can see

1036
01:44:13,700 --> 01:44:21,620
what happens. That's useful to do if you are ahead at the moment or if you want to do them later in

1037
01:44:21,620 --> 01:44:29,300
the exercise sessions. Okay. So what is the motivation behind the data? What is the,

1038
01:44:30,340 --> 01:44:39,700
like the, yeah. So let's go into the actual example. So I'll just make this a little bit

1039
01:44:39,700 --> 01:44:46,020
smaller so that we can see a terminal window here. Okay, maybe not quite that small.

1040
01:44:46,020 --> 01:44:53,380
And now I am actually in the folder with the examples. Why can't I type into this window?

1041
01:44:53,380 --> 01:45:01,380
I guess I have a broken connection. Good start. So I guess it's the demo effect.

1042
01:45:02,260 --> 01:45:06,980
Let's take a connection to the Triton cluster. Yeah, this is not working. Okay.

1043
01:45:06,980 --> 01:45:15,020
This is also taking a while.

1044
01:45:15,020 --> 01:45:20,460
So fortunately, I did already run these commands on the cluster and we have the expected results

1045
01:45:20,460 --> 01:45:21,460
panels.

1046
01:45:21,460 --> 01:45:27,500
It would still at the very least be nice to run them locally, but can you think of a reason

1047
01:45:27,500 --> 01:45:30,220
why I couldn't access Triton right now?

1048
01:45:30,220 --> 01:45:35,780
I don't know, but maybe you have them locally.

1049
01:45:35,780 --> 01:45:40,580
I do have the examples locally. It's just a very different disk system. It doesn't exactly

1050
01:45:40,580 --> 01:45:47,380
demonstrate what we wanted to demonstrate. This is a little bit annoying. It might be that login

1051
01:45:47,380 --> 01:46:01,540
is just slow. It's also slow to me. Okay, well, we can look at the files locally.

1052
01:46:01,540 --> 01:46:07,060
Oh, here we are. Great. Should I do the source? Okay.

1053
01:46:11,220 --> 01:46:16,180
So just that we can follow, you can more easily follow along with the commands. I'll do this.

1054
01:46:19,140 --> 01:46:25,620
So now when I type something here, okay, this is also not updating. Okay, that's fine.

1055
01:46:26,900 --> 01:46:31,460
So we'll just have this terminal now. That's fine. Can you see the lowest line? Let me know

1056
01:46:31,460 --> 01:46:37,540
if if the lowest line at the terminal is not visible. Can you make it a white background?

1057
01:46:39,540 --> 01:46:45,860
I am not sure how to do that. Right click or maybe it's too late to do it. Okay.

1058
01:46:49,380 --> 01:46:52,260
Okay, so I am in the folder with the examples

1059
01:46:52,260 --> 01:46:58,260
And the examples, let's also activate the conda repository.

1060
01:47:03,260 --> 01:47:05,260
I had all of this prepared.

1061
01:47:06,260 --> 01:47:08,260
But this is how it works, right?

1062
01:47:08,260 --> 01:47:22,180
Yeah, so in the example data what we have is like we have a code that just creates like a simple

1063
01:47:23,380 --> 01:47:31,140
example data set motivated by [name]'s like fitness tracker. Yeah, so this is an example,

1064
01:47:31,140 --> 01:47:36,420
it's a generated example but it's relatively close to what I have seen in actual research projects.

1065
01:47:36,420 --> 01:47:45,300
And I'm going to be doing things in good ways and bad ways and I don't think that anybody

1066
01:47:45,300 --> 01:47:50,380
in the research project is actually doing them in such bad ways, but anyway.

1067
01:47:50,380 --> 01:47:55,780
So there is a script to create this data, but let's just take a look.

1068
01:47:55,780 --> 01:47:57,520
So there's this data folder.

1069
01:47:57,520 --> 01:48:07,920
It includes activity data, which represents how much I have been moving according to a

1070
01:48:07,920 --> 01:48:11,920
fitness watch, for example, at a given time.

1071
01:48:11,920 --> 01:48:21,880
So let's take a look at 2008 and 10 is the month, so October.

1072
01:48:21,880 --> 01:48:29,200
And it includes a lot of files, well, it includes one file for each day of the month.

1073
01:48:29,200 --> 01:48:32,000
Let's look at 30.

1074
01:48:32,000 --> 01:48:34,640
And let's actually cut it so we'll see the data.

1075
01:48:34,640 --> 01:48:40,920
So the number here represents the activity level.

1076
01:48:40,920 --> 01:48:45,040
The last number here, the other one represents hour, and this is actually the index, so it's

1077
01:48:45,040 --> 01:48:47,680
actually the same as the hour.

1078
01:48:47,680 --> 01:48:49,960
So for each hour there is a number.

1079
01:48:49,960 --> 01:48:55,640
It's a single number, it's an integer, and we want to do some analysis on all of these

1080
01:48:55,640 --> 01:48:56,640
numbers.

1081
01:48:56,640 --> 01:49:00,240
So if you think about it, there's a large number of files here actually, I did the calculation.

1082
01:49:00,240 --> 01:49:09,680
So 7,300 files, it's not that bad, it's just my data, but if when I actually start doing

1083
01:49:09,680 --> 01:49:17,000
the research and I have the data for 200 people, 500 people, 1,000 people, that's a lot.

1084
01:49:17,000 --> 01:49:20,280
So it can really become a bottleneck, the number of files.

1085
01:49:20,280 --> 01:49:21,640
So let's go back though.

1086
01:49:21,640 --> 01:49:26,400
And for these examples, like throughout these examples, we will get some numbers and you

1087
01:49:26,400 --> 01:49:31,320
have to always think of these numbers like, okay, what are the scales between the different

1088
01:49:31,320 --> 01:49:33,000
things that we're doing?

1089
01:49:33,000 --> 01:49:34,000
What happened?

1090
01:49:34,000 --> 01:49:38,680
Same with the [name]'s MPI example, what is the scaling speed when you increase the number

1091
01:49:38,680 --> 01:49:40,260
of CPUs?

1092
01:49:40,260 --> 01:49:42,460
We also have to think about scaling here.

1093
01:49:42,460 --> 01:49:48,180
So think of these like, let's think that each file, imagine that they are 10 gigabyte files

1094
01:49:48,180 --> 01:49:49,500
or something like that.

1095
01:49:49,500 --> 01:49:53,840
So then suddenly we have a huge number, huge amount of data.

1096
01:49:53,840 --> 01:49:58,740
So then we can think about, okay, what are the savings that we would get if the files

1097
01:49:58,740 --> 01:50:02,540
would be a lot bigger or the number of files would be a lot larger.

1098
01:50:02,540 --> 01:50:03,540
Yeah.

1099
01:50:03,540 --> 01:50:09,540
If there's a, like you could have a measurement per second of this activity level, although

1100
01:50:09,540 --> 01:50:14,020
So I guess this particular level is really defined on a one-minute interval.

1101
01:50:14,020 --> 01:50:17,900
But that would already be a lot more text, but of course, it's not the only measurement.

1102
01:50:17,900 --> 01:50:20,460
You get the heart rate per second, for example.

1103
01:50:20,460 --> 01:50:24,340
You get a lot of measurements from a device like that.

1104
01:50:24,340 --> 01:50:29,300
And so you could have a much bigger file, but you can also have a lot more of these

1105
01:50:29,300 --> 01:50:33,340
really small files, which also is a problem on its own.

1106
01:50:33,340 --> 01:50:37,220
So let's check like a typical IO pattern now.

1107
01:50:37,220 --> 01:50:38,220
What happened?

1108
01:50:38,220 --> 01:50:43,900
The first thing I in fact wrote, and not just as an example. This is not just an example of

1109
01:50:45,180 --> 01:50:52,780
something that I'm purposely doing it in a bad way. This is actually the first thing I would write.

1110
01:50:55,340 --> 01:51:07,900
This readfiles.py. So what it does in short is just read all the

1111
01:51:07,900 --> 01:51:14,060
files in a for loop. We'll list all the files in the data folder. For each folder, list all of

1112
01:51:14,060 --> 01:51:22,380
these files in there. So this is the CSV files. Open and read. So I'm actually doing it in a

1113
01:51:22,380 --> 01:51:28,860
slightly better way than my first idea would be. I'm reading the text content and putting it in a

1114
01:51:28,860 --> 01:51:37,580
list and then turning that into a CSV file and then that into a pandas data frame. Probably the

1115
01:51:37,580 --> 01:51:41,340
first thing I would do is actually turn it into a pandas data frame here, but that would take a lot

1116
01:51:41,340 --> 01:51:48,540
of time. And actually, it would kind of obscure the fact that it's reading a lot of stuff because

1117
01:51:49,100 --> 01:51:55,420
it would be not just reading, but also doing useless computation between every file.

1118
01:51:55,420 --> 01:51:58,860
Yeah, we want to measure or demonstrate the reading.

1119
01:52:00,300 --> 01:52:05,100
So, I'm doing it in a much better and faster way than my first idea actually would be, but that's

1120
01:52:05,100 --> 01:52:10,700
That's partly to not obscure the fact that I'm really doing a lot of reads.

1121
01:52:10,700 --> 01:52:11,700
Okay.

1122
01:52:11,700 --> 01:52:15,700
So, now let's try this.

1123
01:52:15,700 --> 01:52:16,700
Oops.

1124
01:52:16,700 --> 01:52:17,700
Yeah.

1125
01:52:17,700 --> 01:52:18,700
Okay.

1126
01:52:18,700 --> 01:52:26,180
So, this actually does take a while.

1127
01:52:26,180 --> 01:52:31,820
You might notice that there's also a strange-looking command before the Python thing, and that

1128
01:52:31,820 --> 01:52:40,060
is the command called trace which is part of Linux system tools that can be used to trace.

1129
01:52:41,580 --> 01:52:48,220
It can trace different kinds of operations that the programs might do and what it can do is that

1130
01:52:48,220 --> 01:52:54,780
in this case we want to trace file descriptors so basically whenever files are being accessed or

1131
01:52:54,780 --> 01:53:02,860
done and then we have this -c there as well to produce like overall results or summaries

1132
01:53:03,820 --> 01:53:08,780
for the results. So we want to see what the Python program did

1133
01:53:09,900 --> 01:53:18,380
and what we get is something like this. Yeah so I guess these are how many times a file

1134
01:53:18,380 --> 01:53:27,980
was opened. That's 8000, so roughly the number of files we have. I guess, so this is asking

1135
01:53:27,980 --> 01:53:36,140
for file information. Yeah. And looking for a specific place in the file. Yeah. I mean

1136
01:53:36,140 --> 01:53:41,260
overall lots of operations. Yes, so we can look from the different columns that on the left we

1137
01:53:41,260 --> 01:53:45,820
can see what took most of the time. So it was the file opening that took most of the time and

1138
01:53:45,820 --> 01:53:50,620
stacking, so basically figuring out who owns the file, are we allowed to access the file,

1139
01:53:50,620 --> 01:53:58,300
this sort of stuff. That took the most of the time and you can see how many microseconds it took

1140
01:53:59,580 --> 01:54:06,700
per call or milliseconds, I don't know. What's the actual, it doesn't really matter.

1141
01:54:06,700 --> 01:54:10,380
I think it's percent. Yeah, it's percent of the time, so it's not quite seconds.

1142
01:54:10,380 --> 01:54:15,900
And then how many calls we have, and what is the call at the right side?

1143
01:54:15,900 --> 01:54:18,140
And the whole thing took five seconds, by the way.

1144
01:54:19,740 --> 01:54:24,940
So if we think about what the program was inside the program, we had a for loop that

1145
01:54:24,940 --> 01:54:30,700
opened files in a for loop. So for each file, it had to open the file, it had to access the

1146
01:54:30,700 --> 01:54:36,940
metadata and the actual data of the file, and it had to do it. And we can see that being reflected

1147
01:54:36,940 --> 01:54:44,540
here in the output. For each file, we did a lot of these open calls and we did a lot of these

1148
01:54:45,100 --> 01:54:52,380
stat calls. The files are really small. What we basically did is that we had to do it for all

1149
01:54:52,380 --> 01:55:00,300
files. Each of these operations was quite small, but they still have a lot of latency with them.

1150
01:55:00,300 --> 01:55:09,300
So let's, like a normal, normally in this kind of a situation where you want to access all of the data once, like you just want to go through the data.

1151
01:55:09,300 --> 01:55:20,300
A better solution is to usually bunch up the data into an archive, because then you don't have to like do these individual calls and it will speed up the code grammatically.

1152
01:55:20,300 --> 01:55:26,060
So one question was why did we have this many more file opens than

1153
01:55:27,980 --> 01:55:34,060
that we have files or data files and the answer is that we are importing Python libraries which

1154
01:55:34,060 --> 01:55:40,780
contain a lot of files, .py files and all sorts of different files. So we will actually

1155
01:55:40,780 --> 01:55:48,300
not get very close to zero at any point. So there's always going to be like a baseline

1156
01:55:48,300 --> 01:55:54,060
like a startup same with the like NPR programs you have a certain like startup things that you

1157
01:55:54,060 --> 01:56:01,020
always have to calculate as a part of the whole thing but then you can like... But that's a fixed

1158
01:56:01,820 --> 01:56:08,540
so when you increase the number of participants that part will not increase so it's kind of

1159
01:56:08,540 --> 01:56:13,740
yeah a fixed part of the computation. Let's look at the archive reading. So yeah now we have this

1160
01:56:13,740 --> 01:56:21,340
tar file. A tar file is a single file, but it's essentially just the contents of the files put

1161
01:56:21,340 --> 01:56:27,100
in right after each other. It's a very simple archive format. This is not even compressed,

1162
01:56:27,100 --> 01:56:31,500
so it's just actually the full contents of the files with some little bit of metadata in between.

1163
01:56:31,500 --> 01:56:38,300
Do you want to show the Python code quickly? Yeah, it is relatively straightforward.

1164
01:56:38,300 --> 01:56:44,020
Well, there is a difference between streaming mode and just read.

1165
01:56:44,020 --> 01:56:49,300
We want to be streaming because otherwise it will read the file multiple times.

1166
01:56:49,300 --> 01:56:53,660
That's just this particular tar opening library.

1167
01:56:53,660 --> 01:56:58,700
Otherwise we open the file once and then we get a list of, well, actually we don't get

1168
01:56:58,700 --> 01:57:04,300
a list of members because what this is doing is actually it's reading through this list

1169
01:57:04,300 --> 01:57:05,580
of files, like I said.

1170
01:57:05,580 --> 01:57:11,260
At the beginning, there's a marker, the file begins, then there's the file name and some

1171
01:57:11,260 --> 01:57:17,900
other information. This will actually contain the file name. Well, actually, this member.name

1172
01:57:17,900 --> 01:57:24,940
is the file name. We check that it's a CSV file from that. But then this extract file will just

1173
01:57:24,940 --> 01:57:33,420
go on and read the chunk of data that is the actual file. Then we read it and we append it

1174
01:57:33,420 --> 01:57:42,940
again to this list of texts. You notice that in this for loop, previously we had like before

1175
01:57:42,940 --> 01:57:48,300
we'll have for loop over the folders and then we had a for loop over the files in the folder and

1176
01:57:48,300 --> 01:57:55,100
then we opened each of them and you might notice that over here we have the open call at the outside

1177
01:57:55,100 --> 01:58:00,940
of the for loops so basically we open the tar file and then we go through the tar file each file in

1178
01:58:00,940 --> 01:58:08,860
there. So what we can expect from this is that okay, we probably have less open calls,

1179
01:58:08,860 --> 01:58:15,740
so maybe we should try it out. Before I do, just more for the audience than you,

1180
01:58:16,460 --> 01:58:22,860
are you expecting, if we just don't count all of the Python library importing and that stuff,

1181
01:58:23,500 --> 01:58:28,780
do you expect just one call to open the file and read? It is just one file.

1182
01:58:28,780 --> 01:58:33,980
Let's see. So I don't know actually how I would answer this question

1183
01:58:33,980 --> 01:58:37,580
because there are the Python file reads but the answer is not quite one.

1184
01:58:41,420 --> 01:58:46,140
So that was faster. It actually did take two seconds. So two compared to five.

1185
01:58:47,420 --> 01:58:54,300
So like it's still not trivial to process the data and to actually like stream it from the file

1186
01:58:54,300 --> 01:59:03,020
But we can notice that there's a complete difference in what calls are now the most

1187
01:59:03,020 --> 01:59:07,660
important ones. So now we notice that most of the time was actually just reading the data.

1188
01:59:08,220 --> 01:59:13,980
This is because now it can just go through the file and just read it from start to finish.

1189
01:59:14,700 --> 01:59:22,540
And it can read it in bigger blocks. So normally it can read something like 10 kilobytes

1190
01:59:22,540 --> 01:59:28,220
at a time, whereas previously all of the files were like only like a few hundred bytes or something.

1191
01:59:28,220 --> 01:59:34,860
So now it can read like multiple files at one time from the file system. So there's less read

1192
01:59:34,860 --> 01:59:42,700
calls. Previously there were 15 000, now there's only 2 500 and there's much less file open calls.

1193
01:59:43,900 --> 01:59:50,780
So in practice, if I wanted to answer the question I just started with,

1194
01:59:50,780 --> 01:59:58,540
it would be the block size of the system so it would be able to read one entire block at a time

1195
01:59:58,540 --> 02:00:03,100
but the files are stored in blocks so you actually do need to read multiple times

1196
02:00:03,100 --> 02:00:09,740
if the file is big enough. So at some point if the files are big enough to start

1197
02:00:09,740 --> 02:00:16,940
actually accumulating the read calls anyway but still you only need to have one stat call

1198
02:00:16,940 --> 02:00:20,740
for one file.

1199
02:00:20,740 --> 02:00:23,460
And there's good questions in the chat,

1200
02:00:23,460 --> 02:00:26,380
like can the tar file trick to use

1201
02:00:26,380 --> 02:00:28,140
in file transfers as well?

1202
02:00:28,140 --> 02:00:32,300
And definitely, like combining multiple files,

1203
02:00:32,300 --> 02:00:34,260
like if you need to do a transfer

1204
02:00:34,260 --> 02:00:37,260
between let's say your computer and the cluster,

1205
02:00:37,260 --> 02:00:39,540
and you need to transfer like a hundred files,

1206
02:00:39,540 --> 02:00:43,780
for each file, the transfer tool of your choice

1207
02:00:43,780 --> 02:00:48,480
has to write the files, write the metadata,

1208
02:00:48,480 --> 02:00:50,040
check the permissions, whatever,

1209
02:00:50,040 --> 02:00:52,680
and also do the transfer through the network.

1210
02:00:52,680 --> 02:00:55,480
And it's much faster to just process one file.

1211
02:00:55,480 --> 02:00:58,800
Of course, up to a point where the file is so big

1212
02:00:58,800 --> 02:01:01,900
that you might get into like,

1213
02:01:04,000 --> 02:01:06,600
it might just take too long to transfer one file

1214
02:01:06,600 --> 02:01:08,060
and it might crash or something,

1215
02:01:08,060 --> 02:01:10,680
but that's up to gigabytes.

1216
02:01:10,680 --> 02:01:14,680
So, so it's always faster until you reach those places.

1217
02:01:15,360 --> 02:01:17,520
And also there was a good question.

1218
02:01:18,360 --> 02:01:25,200
Uh, like, uh, can this be used with pickle objects, for example, in Python?

1219
02:01:25,600 --> 02:01:29,220
Like, well, there's other data formats that do this kind of stuff as well.

1220
02:01:29,280 --> 02:01:33,720
Like we will talk about this a bit that later, but this is just like a simple

1221
02:01:33,720 --> 02:01:38,680
example, but there's other formats that you can use that, that store everything

1222
02:01:38,680 --> 02:01:45,140
as one file and pickle is one of them, like it will store stuff in one file instead of

1223
02:01:45,140 --> 02:01:46,140
multiple files.

1224
02:01:46,140 --> 02:01:57,560
So I guess if you have a large number of pickle files storing different things, then if you

1225
02:01:57,560 --> 02:02:01,080
have a large number of files, you can use tar, of course, to combine them into one.

1226
02:02:01,080 --> 02:02:06,840
But of course, you could only create, potentially you could create just one tar file, so you

1227
02:02:06,840 --> 02:02:11,020
You can stream data into it if it doesn't fit in the memory, if you want to just make

1228
02:02:11,020 --> 02:02:12,840
one big tar file.

1229
02:02:12,840 --> 02:02:18,520
And remember here that tar is, like this example uses tar, but it can be other file format.

1230
02:02:18,520 --> 02:02:24,320
But the main point is that, do you have the files, thousands of files there, or do you

1231
02:02:24,320 --> 02:02:27,080
have them combined in some format?

1232
02:02:27,080 --> 02:02:32,000
Like it can be a mat file, it can be like a R data file, it can be a pickle file, it

1233
02:02:32,000 --> 02:02:33,000
can be whatever.

1234
02:02:33,000 --> 02:02:37,240
target is something that people quite often use and that's easy to demonstrate.

1235
02:02:38,600 --> 02:02:47,240
So there was one question, how did I create the tar file? One reason I chose tar here is that

1236
02:02:47,240 --> 02:02:56,360
it's available on essentially any Unix, POSIX file system. It's a POSIX utility. So there is this tar

1237
02:02:56,360 --> 02:03:02,520
command. So you can use this command. This is for reading.

1238
02:03:06,920 --> 02:03:11,320
This one is for creating the tar file from the data.

1239
02:03:11,320 --> 02:03:15,320
So this command exists on any Linux system but because of course I'm

1240
02:03:19,080 --> 02:03:23,000
a perfectionist and I wanted to make sure that you can run this even without the tar command

1241
02:03:23,000 --> 02:03:33,800
and there is also this create_archive, so if you want, you can also do this from Python.

1242
02:03:33,800 --> 02:03:39,640
But another thing just on that, there is this web dataset example at the end of the notes,

1243
02:03:39,640 --> 02:03:44,160
which we'll clearly not get into, but let's see.

1244
02:03:44,160 --> 02:03:52,280
But yeah, so that also uses the tar data format and has a nicer way of creating tar files and

1245
02:03:52,280 --> 02:04:00,040
these sharded tar files that are large. A large file with a lot of data, but still

1246
02:04:01,000 --> 02:04:04,040
multiple files so that you can read them in random order and all of that.

1247
02:04:04,760 --> 02:04:09,880
So that's a nice thing to look into. There was a good follow-up question there also that

1248
02:04:10,680 --> 02:04:15,720
does creating the tar file just move the slowness of opening files to another script?

1249
02:04:15,720 --> 02:04:20,760
And of course it does. In order to create the tar file, you first need to open all of the

1250
02:04:20,760 --> 02:04:24,720
the files, you need to load all of the files and create the target file.

1251
02:04:25,200 --> 02:04:32,720
But the thing is that, what accumulates, if you do it once, like pre-processing

1252
02:04:32,720 --> 02:04:38,540
step, instead of having the individual files, you collect them together, like

1253
02:04:38,540 --> 02:04:46,960
you do it once so that you don't have to do it again, then you can mitigate

1254
02:04:46,960 --> 02:04:54,160
some of the, like something you can like accumulate if you do it over and over again, like, let's

1255
02:04:54,160 --> 02:04:58,820
say you want to do the same analysis with different kinds of parameters and you always

1256
02:04:58,820 --> 02:05:04,160
access all of the files, then suddenly you can do like, I don't know, a thousand times

1257
02:05:04,160 --> 02:05:07,600
the same IO kind of a thing, and that will like accumulate.

1258
02:05:07,600 --> 02:05:14,440
If you're running the same thing many times, then it is useful to do this tar command

1259
02:05:14,440 --> 02:05:23,640
once, even though it of course takes some time. And the other thing is if the whole data doesn't

1260
02:05:23,640 --> 02:05:28,440
fit into memory once, then you will probably end up reading it multiple times, even in a single run.

1261
02:05:29,160 --> 02:05:36,280
So this should be common in machine learning. And then using a good data format for reading is

1262
02:05:36,280 --> 02:05:47,320
important. But let's go to the next example. So the next example is motivated by the machine

1263
02:05:47,320 --> 02:05:54,840
learning world, where basically quite often you want to load data in a random way. And in this,

1264
02:05:54,840 --> 02:05:59,720
tar is usually not the best way, unless you use something like the web dataset mentioned by

1265
02:05:59,720 --> 02:06:05,880
I don't know, because let's demonstrate what happens when you try to read the files in random.

1266
02:06:06,440 --> 02:06:10,440
WebDataSet kind of uses a trick in that it's not completely randomized.

1267
02:06:11,880 --> 02:06:19,000
But yeah, so essentially if you try to read random chunks from a file, that usually means you will

1268
02:06:21,800 --> 02:06:29,080
open the file and then seek until you find the place. It's like running a tape. You read through

1269
02:06:29,080 --> 02:06:35,160
the file until you find the place that you actually want to read and then you can read that chunk and

1270
02:06:35,160 --> 02:06:41,320
then you have to open the file again if the part you want to read is earlier. So random access is

1271
02:06:41,320 --> 02:06:51,240
not a great pattern for reading files in general. Yes. So you can imagine what the Python code

1272
02:06:51,240 --> 02:06:55,240
looks like. I'm just randomizing the list of files here. So let's just run this.

1273
02:06:55,240 --> 02:07:08,200
This takes a little bit longer, so here we had 1.73 seconds, 2.8, so not as bad as reading

1274
02:07:08,200 --> 02:07:09,200
all the files.

1275
02:07:09,200 --> 02:07:18,080
It ended up actually opening, here we open 580 times, read 2,500, okay.

1276
02:07:18,080 --> 02:07:24,280
Yeah, it had to open the same amount of, yeah, it had to open the same amount of files, but

1277
02:07:24,280 --> 02:07:29,720
like [name] said, now it has to like seek the different location where it wants to read.

1278
02:07:29,720 --> 02:07:36,360
So because the archive is one file, it has to suddenly like seek the correct place in the

1279
02:07:36,360 --> 02:07:41,320
archive and then read from there. So we get a lot more read calls because sometimes like when you

1280
02:07:41,320 --> 02:07:48,200
read, you might read a certain amount of data and your data is somewhere in the middle of that

1281
02:07:48,200 --> 02:07:54,760
like block of data that you want to read. And then you read more than you needed. So you read

1282
02:07:54,760 --> 02:07:59,080
basically just, you read more than you need, and then you read that part, and then you need to

1283
02:07:59,080 --> 02:08:05,240
go somewhere else and you need to read again. So that's why we get a lot of SQLs. It's still

1284
02:08:05,240 --> 02:08:12,440
faster than the individual files, but it's not good either. So for these, there are tools like

1285
02:08:12,440 --> 02:08:19,720
for random grids you usually want to have the data in some way that you can load the data in a

1286
02:08:19,720 --> 02:08:27,400
sequential order like as a one block but then randomize it in memory so instead of loading

1287
02:08:28,760 --> 02:08:35,320
the data from the disk in a random order you want to load the data into memory and randomize it in

1288
02:08:35,320 --> 02:08:41,720
memory because that is okay so I'll just show the example that comes next because that's the

1289
02:08:42,440 --> 02:08:55,640
chunked random access. So what we do here is this is a bit of a made-up case in that all of the

1290
02:08:56,680 --> 02:09:02,360
data actually does fit in the memory. But let's just think that if only 10 files fit in the memory

1291
02:09:02,360 --> 02:09:06,680
at a time and we want to have it somewhat randomized but not necessarily completely

1292
02:09:06,680 --> 02:09:14,760
randomized then we can extract the contents of 10 files and then once we have 10 files

1293
02:09:14,760 --> 02:09:22,280
we take a random permutation of those 10 files. So it's somewhat random but of course it's

1294
02:09:22,280 --> 02:09:28,140
not reading completely randomly from the file, it's just randomizing each chunk. So this

1295
02:09:28,140 --> 02:09:33,440
is commonly just good enough and you can also randomize the order of the chunks if you save

1296
02:09:33,440 --> 02:09:40,440
them in separate files. So that's a common way of doing it and it works well.

1297
02:09:40,440 --> 02:09:45,000
Yeah, this is what, for example, the web dataset uses. It loads, spreads the... If you have

1298
02:09:45,000 --> 02:09:52,520
a big dataset, the dataset is split into multiple TAR files in random ways, and then each of

1299
02:09:52,520 --> 02:09:59,320
those files is opened, read, and then the stuff is shuffled in memory. And because you

1300
02:09:59,320 --> 02:10:03,960
go load the different target files in the random order you basically get full randomness so you

1301
02:10:03,960 --> 02:10:10,680
don't have to ever like you don't have to read individual files you can still get one file.

1302
02:10:11,720 --> 02:10:17,560
Now let's see if the same thing happens as I saw previously and then I can ask you if you

1303
02:10:17,560 --> 02:10:27,400
can quickly say why it would happen. Yeah so why is this faster than the just reading the whole

1304
02:10:27,400 --> 02:10:33,080
archive in one go. And significantly faster every time.

1305
02:10:33,080 --> 02:10:42,520
Yeah. I think the thing here is that when you extract, well, I would guess that when

1306
02:10:42,520 --> 02:10:49,560
you extract the files or you read multiple chunks into memory, it can optimize the code

1307
02:10:49,560 --> 02:10:57,320
in a way that it doesn't have to, it can just pipe stuff into the chunks. It can

1308
02:10:57,320 --> 02:11:01,960
just â it doesn't have to do intermediate processing for each chunk one at a time,

1309
02:11:01,960 --> 02:11:05,720
but it can do it for multiple at one time. But I'm not certain.

1310
02:11:07,640 --> 02:11:11,000
Okay, maybe. Python usually doesn't do a lot ofâ¦

1311
02:11:11,800 --> 02:11:20,440
But then again, at this speed, it can be random noise as well. It's just random noise.

1312
02:11:20,440 --> 02:11:26,360
Yeah, but this is happening every time. This is repeatable. So, I'm just wondering. But okay,

1313
02:11:26,360 --> 02:11:33,560
Let's move on. One problem here is that the strace output â this is relatively good, I think,

1314
02:11:33,560 --> 02:11:43,640
but if you try to get all of the file read, for example, and do some proper profiling and not

1315
02:11:43,640 --> 02:11:55,160
just get the full sum in the end, it's not very readable. We haven't found great tools

1316
02:11:55,160 --> 02:12:00,920
for reading it. I don't want to say that these are not great. It's great that somebody took

1317
02:12:00,920 --> 02:12:09,080
the effort, took the time to write this. But there could be something better maybe around.

1318
02:12:09,960 --> 02:12:15,160
But in any case, these are what we found. It's great that people took the effort to write them.

1319
02:12:18,280 --> 02:12:23,000
Yeah, those tools can give you a bit more information of what files were accessed and

1320
02:12:23,000 --> 02:12:27,880
that sort of stuff which might be like if you don't know what your program is doing it might

1321
02:12:27,880 --> 02:12:36,680
be good to try out these tools. The second one has also like if you're running MPI programs and

1322
02:12:36,680 --> 02:12:44,520
you want just like only your run space on one of the tasks so you can just monitor one task

1323
02:12:44,520 --> 02:12:51,480
then that's pretty nice feature as well. But the main thing that we want to come across is that

1324
02:12:51,480 --> 02:12:58,200
this is what file access looks like and this is what the program tries to do and usually the best

1325
02:12:59,640 --> 02:13:05,240
like how could I say the best thing to do is to look at your program and see how it tries to access

1326
02:13:05,240 --> 02:13:10,360
the files if you can like if you if it's not hidden inside the program but but to think about

1327
02:13:10,360 --> 02:13:16,360
okay what files go into the program and what files come out of the program how many go in how many go

1328
02:13:16,360 --> 02:13:22,760
out and what is the way that the program tries to interact with the file system, because then you

1329
02:13:22,760 --> 02:13:29,240
can think about, okay, I can expect that, let's say one file access will cause certain amounts

1330
02:13:29,240 --> 02:13:37,720
of open calls and it might slow down the whole thing. Next, we could talk a bit about why is

1331
02:13:37,720 --> 02:13:45,080
this even a problem? If you run on your own computer, you might have a fast NVMe SSD or

1332
02:13:45,080 --> 02:13:50,840
something like that. Why is this even like a thing? Why are we talking about IO and these file calls?

1333
02:13:52,680 --> 02:13:59,320
The reason is that all of the HPC clusters, they usually have a network file system. We have a

1334
02:13:59,320 --> 02:14:03,960
low-structure file system. There might be other file systems in other clusters, but usually it's

1335
02:14:03,960 --> 02:14:13,160
something similar to what we have. There is a network file system. What happens when you try

1336
02:14:13,160 --> 02:14:17,880
to access a file there because the program doesn't know, right? The program just thinks that,

1337
02:14:17,880 --> 02:14:22,520
okay, there's a file system. I will try to do a file system call. It will do the same calls

1338
02:14:22,520 --> 02:14:28,200
whether you do it on an SSD file system or a network file system. It will do the file opens

1339
02:14:28,200 --> 02:14:36,520
and file writes and whatever. It doesn't care. It doesn't know what system answers those calls.

1340
02:14:36,520 --> 02:14:49,520
So, if you open the explanation, there is a diagram of a typical file system, like a network file system.

1341
02:14:49,520 --> 02:15:00,520
And what they usually are, like a Lustre file system, it's actually that there's multiple metadata servers that serve just the metadata.

1342
02:15:00,520 --> 02:15:04,960
data. And there's usually like corresponding or there's like

1343
02:15:04,960 --> 02:15:09,120
object storage service to actually store the data. And

1344
02:15:09,640 --> 02:15:14,280
whenever you are making a call, like you ask, let's say I want

1345
02:15:14,280 --> 02:15:17,920
to open this file, there is usually a file system client

1346
02:15:18,080 --> 02:15:23,760
that basically sends those calls then to the right places. So

1347
02:15:23,780 --> 02:15:26,960
when you try to access a file, you will send a call to the

1348
02:15:26,960 --> 02:15:30,320
metadata server that, hey, can I access this file? And we

1349
02:15:30,320 --> 02:15:36,080
actually is the file, because I don't know where is the actual content of the file, then that

1350
02:15:36,080 --> 02:15:41,360
response comes back to the client, which then if the response is like, yes, you can access it,

1351
02:15:41,360 --> 02:15:46,880
it will try to access the object storage server where it tries to access the actual file.

1352
02:15:46,880 --> 02:15:53,120
And there, the data, it will have to fetch the data from a disk where it actually gets the data

1353
02:15:53,120 --> 02:16:00,800
into and then it will send the data back. So you can think that there's like lots of overhead here

1354
02:16:00,800 --> 02:16:08,400
instead of like let's say your SSD in your computer which is fast but it's small and it's

1355
02:16:08,400 --> 02:16:13,360
not redundant or anything like that that is needed in the high performance computing system. What

1356
02:16:13,360 --> 02:16:19,280
happens is that instead of the data being right there in the SSD and the cores being served almost

1357
02:16:19,280 --> 02:16:24,960
immediately there's lots of network interactions like there has to be data transfer through the

1358
02:16:24,960 --> 02:16:33,360
network back and forth and this will call latency and then all of these individual calls

1359
02:16:34,240 --> 02:16:39,120
become longer and longer and this means that while they and usually in the programs while the

1360
02:16:39,120 --> 02:16:44,720
file system calls are being solved the program doesn't do anything like it doesn't continue

1361
02:16:44,720 --> 02:16:50,880
there's some programs that do like asynchronous file calls that they do stuff on the background

1362
02:16:50,880 --> 02:16:56,480
and this is of course good because then like it can continue working while the data is still

1363
02:16:56,480 --> 02:17:02,240
being fetched but but that is more complicated to program so usually it's better to not

1364
02:17:03,440 --> 02:17:08,880
not get the data or if you get the data from the file system like the shared file system you get

1365
02:17:08,880 --> 02:17:13,840
it in the right format because then you can minimize these latencies that can slow down the

1366
02:17:13,840 --> 02:17:26,000
program. Okay so basically is the the reading speed the bandwidth is I guess roughly the same

1367
02:17:26,000 --> 02:17:31,600
as you would have on a laptop or not that much slower but there's a lot of latency for accessing

1368
02:17:31,600 --> 02:17:37,920
the file through the network and also while making the stat call which is probably going

1369
02:17:37,920 --> 02:17:44,320
to a different server? Yeah, the file systems are of course very powerful, but the problem is that

1370
02:17:44,320 --> 02:17:50,240
there's hundreds of users using them at the same time, right? And there's a lot of people in the

1371
02:17:50,240 --> 02:17:57,440
network transferring MPI stuff as well, and they can be congested. And the data might just be like,

1372
02:17:57,440 --> 02:18:03,760
the disk is somewhere that it needs to fetch the data from the disk. So there's always going to be

1373
02:18:03,760 --> 02:18:07,840
like these intermediate steps that take time so that's why you don't usually want to like

1374
02:18:08,960 --> 02:18:16,880
waste time computing time to do this kind of IO calls. So that's another thing that

1375
02:18:16,880 --> 02:18:24,240
is I think good to bring up at bring back at this point so because file systems are not or just like

1376
02:18:24,960 --> 02:18:30,160
file access is not something you shuttle with Slurm you don't it is not a parameter that you

1377
02:18:30,160 --> 02:18:36,720
give the slurm and you submit your job. It's just a shared resource. If you manage to slow it down,

1378
02:18:36,720 --> 02:18:40,640
then you're slowing it down for everyone. You do have to do a lot to slow it down,

1379
02:18:40,640 --> 02:18:44,000
or multiple people need to be doing a good bit to slow it down.

1380
02:18:46,000 --> 02:18:49,520
If you have a thousand copies of a job and they all read a bunch of files,

1381
02:18:50,480 --> 02:18:54,960
that can do some damage. Then it will slow down for everyone. It's not just your job that

1382
02:18:54,960 --> 02:19:03,680
is slowing down for. That's an important thing to note. What else do we want to cover in six minutes?

1383
02:19:04,880 --> 02:19:10,960
Well, this is typical file system speeds, but I guess the latency is really the big thing

1384
02:19:11,840 --> 02:19:20,000
in this case. Because in the example we just did, it was all latency. The speed of reading

1385
02:19:20,000 --> 02:19:24,960
the file. The amount of data in the files was the same in each case.

1386
02:19:29,040 --> 02:19:36,400
There was also a good question in the chat about data formats to use. You should always

1387
02:19:36,400 --> 02:19:42,960
remember that if you can access the files using code, you can use an intermediate data

1388
02:19:42,960 --> 02:19:51,120
format. Let's say your original data is in CSVs, like [name]'s data. You can still have

1389
02:19:51,120 --> 02:19:55,920
the original data like that, but while you're working on the data, you can store it in a

1390
02:19:55,920 --> 02:20:01,920
better format, like a binary format or something like that, and work on it. Then at the end,

1391
02:20:01,920 --> 02:20:06,560
if you want to publish the results and you want to make it as readable as possible, you can

1392
02:20:06,560 --> 02:20:12,560
provide it in a different format. But during the processing, when the computations are being done,

1393
02:20:12,560 --> 02:20:20,080
it's usually important to like convert it into like a good data. So there's one more workflow

1394
02:20:21,040 --> 02:20:28,640
I want to mention in the last couple of minutes, a workflow thing. So it's kind of a cheat of

1395
02:20:29,360 --> 02:20:37,280
how to get away from having to deal with Lustre, which is if your cluster has local disks like

1396
02:20:37,280 --> 02:20:45,120
Triton has some subnodes then it's a very good idea to move your data into the local disk.

1397
02:20:45,120 --> 02:20:49,040
So by a local disk I mean something that's actually attached to the compute node.

1398
02:20:49,920 --> 02:20:55,600
You don't have to go through network to do any reading and that is still probably shared with

1399
02:20:55,600 --> 02:21:02,400
anyone else running on that same node but you don't have to use the network file system,

1400
02:21:02,400 --> 02:21:09,840
the shared file system. This is especially important for GPU jobs where you're doing like

1401
02:21:09,840 --> 02:21:16,560
GPU machine learning or whatever. Usually those machines are bought with fast SSDs for this

1402
02:21:16,560 --> 02:21:23,120
explicit reason because they are so data hungry, the deep learning models, that you need to have

1403
02:21:23,120 --> 02:21:29,840
the data locally or the GPU will idle. So it just cannot get enough data. So the local disks are

1404
02:21:29,840 --> 02:21:35,200
very important when you're doing like GP jobs.

1405
02:21:35,200 --> 02:21:40,960
Okay and there are also these RAM disks so any Linux system will have a

1406
02:21:40,960 --> 02:21:46,080
/dev/shm [shared memory] and that's also a file system but it's

1407
02:21:46,080 --> 02:21:49,600
actually in RAM so it's a really fast way of communicating.

1408
02:21:49,600 --> 02:21:52,720
If you have a lot of RAM you can put all of your

1409
02:21:52,720 --> 02:21:58,320
data into it but well you need to reserve it when queuing the job

1410
02:21:58,320 --> 02:22:00,200
and it is limited to RAM.

1411
02:22:00,200 --> 02:22:02,000
So if your data doesn't fit into RAM,

1412
02:22:02,000 --> 02:22:05,960
then there's no way you can use this to speed things up.

1413
02:22:05,960 --> 02:22:08,960
But it is still like, it's good to know about.

1414
02:22:08,960 --> 02:22:11,620
It can make things a lot easier and faster.

1415
02:22:12,600 --> 02:22:14,440
Yeah, for example, if your program

1416
02:22:14,440 --> 02:22:17,080
does like a lot of small intermediate files,

1417
02:22:17,080 --> 02:22:19,520
but it does them often or something like that,

1418
02:22:19,520 --> 02:22:22,920
like putting them into the RAM disk might be a good option.

1419
02:22:22,920 --> 02:22:32,040
Okay, so we are really probably getting right onto the lunch break.

1420
02:22:32,040 --> 02:22:33,760
One minute to go.

1421
02:22:33,760 --> 02:22:39,120
So anything you want to say before we wrap up?

1422
02:22:39,120 --> 02:22:48,160
We do have this web dataset example here which you can take a look at on your own and there

1423
02:22:48,160 --> 02:22:53,520
are also other exercises, of course, in the exercise session coming up.

1424
02:22:57,120 --> 02:23:03,200
That's all. Then let's go to the lunch break. If we go to the notes, there is some

1425
02:23:04,240 --> 02:23:09,920
feedback there. One minute while I switch. Okay, I've switched.

1426
02:23:09,920 --> 02:23:26,920
So, for some other daily notes, if you're registered, there's this bring your own code session. You can come and ask us questions. Or no, it's an exercise session, isn't it?

1427
02:23:26,920 --> 02:23:35,920
Well, I mean, you can come to have exercises, but also please do exercise code, basically, any kind of mentoring and individual follow up.

1428
02:23:35,920 --> 02:23:47,920
Also, many, and probably all of the partners you see listed on the website would be very happy to receive questions from about anything we discussed today.

1429
02:23:47,920 --> 02:23:49,600
anything we discussed today.

1430
02:23:49,600 --> 02:23:53,800
So go there, ask about how this applies to your cluster,

1431
02:23:53,800 --> 02:23:58,800
ask for help in how to configure things,

1432
02:23:58,800 --> 02:24:00,480
actually do it, all that stuff.

1433
02:24:03,160 --> 02:24:06,800
So the stream will stop now, right?

1434
02:24:06,800 --> 02:24:09,960
And we go only to Zoom after the lunch break.

1435
02:24:09,960 --> 02:24:11,120
Isn't that correct?

1436
02:24:13,480 --> 02:24:15,800
Yes, I think so.

1437
02:24:15,800 --> 02:24:20,800
Okay, so please fill in this feedback here.

1438
02:24:20,920 --> 02:24:24,360
Let us know all that stuff and have a good lunch.

1439
02:24:24,360 --> 02:24:25,640
See you later then.

1440
02:24:27,540 --> 02:24:28,840
See you.

1441
02:24:28,840 --> 02:24:29,680
Okay, bye.

1442
02:24:29,680 --> 02:24:30,520
Bye.

1443
02:24:30,520 --> 02:24:31,340
See you.

1444
02:24:45,800 --> 02:24:47,860
you

1445
02:25:15,800 --> 02:25:17,860
you

1446
02:25:45,800 --> 02:25:47,860
you

1447
02:26:15,800 --> 02:26:17,860
you

1448
02:26:45,800 --> 02:26:47,860
you

1449
02:27:15,800 --> 02:27:17,860
you

1450
02:27:45,800 --> 02:27:47,860
you

1451
02:28:15,800 --> 02:28:17,860
you

1452
02:28:45,800 --> 02:28:47,860
you

1453
02:29:15,800 --> 02:29:17,860
you

1454
02:29:45,800 --> 02:29:47,860
you

1455
02:30:15,800 --> 02:30:17,860
you

1456
02:30:45,800 --> 02:30:47,860
you

1457
02:31:15,800 --> 02:31:17,860
you

1458
02:31:45,800 --> 02:31:47,860
you

