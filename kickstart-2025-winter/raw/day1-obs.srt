1
00:00:00,000 --> 00:00:02,000
CodeRefinery.org

2
00:00:30,000 --> 00:00:32,060
you

3
00:01:00,000 --> 00:01:02,060
you

4
00:01:30,000 --> 00:01:32,060
you

5
00:02:00,000 --> 00:02:02,060
you

6
00:02:30,000 --> 00:02:32,060
you

7
00:03:00,000 --> 00:03:02,060
you

8
00:03:30,000 --> 00:03:32,060
you

9
00:04:00,000 --> 00:04:02,060
you

10
00:04:30,000 --> 00:04:32,060
you

11
00:05:00,000 --> 00:05:02,060
you

12
00:05:30,000 --> 00:05:32,060
you

13
00:06:00,000 --> 00:06:02,060
you

14
00:06:30,000 --> 00:06:32,060
you

15
00:07:00,000 --> 00:07:02,060
you

16
00:07:30,000 --> 00:07:32,060
you

17
00:08:00,000 --> 00:08:02,060
you

18
00:08:30,000 --> 00:08:32,060
you

19
00:09:00,000 --> 00:09:02,060
you

20
00:09:30,000 --> 00:09:32,060
you

21
00:10:00,000 --> 00:10:02,060
you

22
00:10:30,000 --> 00:10:32,060
you

23
00:11:00,000 --> 00:11:02,060
you

24
00:11:30,000 --> 00:11:32,060
you

25
00:12:00,000 --> 00:12:02,060
you

26
00:12:30,000 --> 00:12:32,060
you

27
00:13:00,000 --> 00:13:02,060
you

28
00:13:30,000 --> 00:13:32,060
you

29
00:14:00,000 --> 00:14:02,060
you

30
00:14:30,000 --> 00:14:54,000
Hello, can anyone hear us out there?

31
00:14:54,000 --> 00:15:00,120
Hello, hello.

32
00:15:00,120 --> 00:15:05,080
So yes, someone says hi.

33
00:15:05,080 --> 00:15:06,520
Okay.

34
00:15:06,520 --> 00:15:08,840
Should we do our audio balance check?

35
00:15:08,840 --> 00:15:09,840
Yes.

36
00:15:09,840 --> 00:15:14,280
So the order can be me, [name], [name], and [name].

37
00:15:14,280 --> 00:15:15,280
One.

38
00:15:15,280 --> 00:15:16,280
[name]?

39
00:15:16,280 --> 00:15:17,280
Two.

40
00:15:17,280 --> 00:15:18,280
One.

41
00:15:18,280 --> 00:15:19,280
Two.

42
00:15:19,280 --> 00:15:20,280
No.

43
00:15:20,280 --> 00:15:21,280
Three.

44
00:15:21,280 --> 00:15:22,280
Three.

45
00:15:22,280 --> 00:15:23,280
Two.

46
00:15:23,280 --> 00:15:24,280
No.

47
00:15:24,280 --> 00:15:25,280
Three.

48
00:15:25,280 --> 00:15:26,280
Okay.

49
00:15:26,280 --> 00:15:27,280
Four.

50
00:15:27,280 --> 00:15:28,280
Five.

51
00:15:28,280 --> 00:15:29,280
Six.

52
00:15:29,280 --> 00:15:30,280
Seven.

53
00:15:30,280 --> 00:15:31,280
Eight.

54
00:15:31,280 --> 00:15:32,280
Okay.

55
00:15:32,280 --> 00:15:36,280
It sounds pretty balanced to me.

56
00:15:36,280 --> 00:15:37,280
Yeah.

57
00:15:37,280 --> 00:15:38,280
Okay.

58
00:15:38,280 --> 00:15:44,280
This was already an example of multiprocessing with message passing.

59
00:15:44,280 --> 00:15:45,280
Yeah.

60
00:15:45,280 --> 00:15:46,280
Okay.

61
00:15:46,280 --> 00:15:55,840
Okay, so now we're in the pre-live or pre-main course icebreaker time, where we'll talk to

62
00:15:55,840 --> 00:15:58,860
you a little bit and get ready to go.

63
00:15:58,860 --> 00:16:09,120
So what you see shared here is the, what we call the notes document, or just notes.

64
00:16:09,120 --> 00:16:15,780
It is a place where everyone can edit, so you can't see it on this share.

65
00:16:15,780 --> 00:16:21,700
if you go up here you can switch to an edit mode and then you can write stuff here so it's marked

66
00:16:21,700 --> 00:16:28,500
down the exact format doesn't matter that much but the important thing is if you take it up and the

67
00:16:28,500 --> 00:16:33,460
only people that have it are people that have registered so you should have just gotten a

68
00:16:33,460 --> 00:16:41,940
reminder email that also has this inside of it is that true okay yes and if you scroll down to the

69
00:16:41,940 --> 00:16:50,700
bottom you see icebreakers here. So the purpose of this is you can come and you

70
00:16:50,700 --> 00:16:55,280
can switch to edit mode and answer these questions and we'll discuss. So for

71
00:16:55,280 --> 00:17:02,280
example I just put an "o" right here to show that I'm very familiar with command

72
00:17:02,280 --> 00:17:09,880
line in Shell. So it's sort of like a bar graph we're making collaboratively. So

73
00:17:09,880 --> 00:17:20,160
Everyone go open this up, vote for whichever one there is, and we can get an idea of how

74
00:17:20,160 --> 00:17:23,160
we should be presenting stuff.

75
00:17:23,160 --> 00:17:31,520
So the questions are, how familiar are you with command line shell?

76
00:17:31,520 --> 00:17:35,400
Have you used version control before?

77
00:17:35,400 --> 00:17:42,920
types of computers have used for work before? What types of programming you do? And then just

78
00:17:42,920 --> 00:17:49,720
a free-form question and answer. What kinds of scientific work do you do or think you do? Like,

79
00:17:51,560 --> 00:17:57,800
whether it's machine learning stuff or physics or chemistry, whatever it may be.

80
00:17:57,800 --> 00:18:07,700
Okay, let's talk about what our answers for these would be. So, first off, I'm [name]

81
00:18:07,700 --> 00:18:14,940
[name]. I work at Aalto University in the Aalto Scientific Computing team, and our job is

82
00:18:14,940 --> 00:18:24,600
basically to help you with scientific computing kind of work. I guess you probably know that

83
00:18:24,600 --> 00:18:26,600
because that's why we're here giving this course.

84
00:18:29,200 --> 00:18:34,760
So of these topics here, I'd say I'm probably

85
00:18:34,760 --> 00:18:37,120
very familiar with command line shell.

86
00:18:37,120 --> 00:18:40,720
I use it all the time and script in it.

87
00:18:40,720 --> 00:18:42,880
I've done plenty of version control before.

88
00:18:47,040 --> 00:18:52,320
I've used mostly own laptops, desktops, group servers,

89
00:18:52,320 --> 00:18:54,620
and high performance clusters.

90
00:18:54,620 --> 00:18:57,920
And my main programming is in Python and shell scripting.

91
00:19:01,700 --> 00:19:04,220
[name], would you like to introduce yourself?

92
00:19:04,220 --> 00:19:06,020
Yeah, so hi everybody.

93
00:19:06,020 --> 00:19:07,860
My name is [name].

94
00:19:07,860 --> 00:19:10,540
I'm a research software engineer

95
00:19:10,540 --> 00:19:12,420
in the autoscientific computing.

96
00:19:14,040 --> 00:19:19,040
So on the topics, yeah, I would say that I'm very familiar

97
00:19:19,900 --> 00:19:22,020
with the command line nowadays.

98
00:19:22,020 --> 00:19:26,500
I've worked in these topics for years, years now.

99
00:19:28,700 --> 00:19:31,220
Have I used version control? Yes.

100
00:19:31,220 --> 00:19:34,220
In fact, just yesterday we were talking about anecdotes

101
00:19:34,220 --> 00:19:36,380
on how, where we learned some of these skills.

102
00:19:36,380 --> 00:19:39,760
And in my first summer job in Aalto University,

103
00:19:40,820 --> 00:19:45,460
my supervisor wanted me to learn how to use version control

104
00:19:45,460 --> 00:19:47,460
and that has definitely paid off.

105
00:19:47,460 --> 00:19:50,080
Like that was years and years ago.

106
00:19:52,020 --> 00:19:55,020
What type of computers have I used before?

107
00:19:55,020 --> 00:19:58,020
Mainly, I do my work from my own laptop

108
00:19:58,020 --> 00:20:01,020
and connecting from that to various other machines

109
00:20:01,020 --> 00:20:06,020
like HPC clusters and a remote desktop and such.

110
00:20:06,020 --> 00:20:10,020
So the laptop is the connection that I use

111
00:20:10,020 --> 00:20:13,020
to the wider computing world.

112
00:20:13,020 --> 00:20:16,020
But I would say that all of those are basically

113
00:20:16,020 --> 00:20:19,020
what I've used so far.

114
00:20:19,020 --> 00:20:28,140
My programming background is on the physics side, but nowadays Python, I would say, is the one glue

115
00:20:28,140 --> 00:20:36,060
that glues most of the coding together. I would say Python is my main language, and then I would

116
00:20:36,060 --> 00:20:46,460
say maybe C or shell scripting, I wouldn't know really. But yeah, basically whatever works for

117
00:20:46,460 --> 00:20:54,380
the specific case at hand. Yeah, great. And [name], would you like to introduce yourself some?

118
00:20:55,260 --> 00:21:00,940
Yeah, okay. Hi, so I'm [name]. I'm, I think, the newest member still of the

119
00:21:00,940 --> 00:21:08,780
research software engineering team. Regarding the icebreaker questions, well, I'm familiar with

120
00:21:08,780 --> 00:21:14,700
the command line. I've used it for a long time now, but I wouldn't say that I'm very familiar

121
00:21:14,700 --> 00:21:22,300
with it. There's certainly areas I could still learn something about it. I've been using version

122
00:21:22,300 --> 00:21:29,260
control for a fair bit as well. Still sort of a myth that I didn't use version control for my

123
00:21:29,980 --> 00:21:39,100
PhD studies, but that's what it was back then. And well, I worked on my own computers,

124
00:21:39,100 --> 00:21:41,540
as laptops and desktop.

125
00:21:41,540 --> 00:21:46,060
I've worked remotely,

126
00:21:46,060 --> 00:21:48,700
and I've also worked on the cluster.

127
00:21:51,300 --> 00:21:53,380
Nowadays, that's just like similar.

128
00:21:53,380 --> 00:21:55,540
I mostly do Python programming-wise,

129
00:21:55,540 --> 00:21:59,900
but I've done a fair bit of other things.

130
00:21:59,900 --> 00:22:03,900
I've done Matlab, I've done R, I've done C.

131
00:22:03,900 --> 00:22:12,940
I've done SDCC, if anyone knows about that, it stands for Small Devices C Compiler, it's

132
00:22:12,940 --> 00:22:25,500
for very close to hardware programming, and that's basically what there is to tell about

133
00:22:25,500 --> 00:22:28,060
me in terms of computing, I think.

134
00:22:28,060 --> 00:22:29,060
Okay, cool.

135
00:22:29,060 --> 00:22:31,660
[name], would you like to introduce yourself?

136
00:22:31,660 --> 00:22:32,660
Yes.

137
00:22:32,660 --> 00:22:33,660
Hello everybody.

138
00:22:33,660 --> 00:22:39,260
couple of minutes before kind of the official start and before mentioning something about myself I'm

139
00:22:39,260 --> 00:22:44,700
checking the answers that you've been writing for those who join now you should have received

140
00:22:44,700 --> 00:22:52,940
this notes document at notes.coderefinery.org and there you can basically edit the document

141
00:22:52,940 --> 00:22:59,260
it's like a google doc but everyone can edit but it's just text based and when it comes to me

142
00:22:59,260 --> 00:23:06,220
I work with the same team as [name], [name], and [name], and yes, I'm very familiar with the

143
00:23:06,220 --> 00:23:15,660
command line. I started in, I think it was 1983 with the Commodore 64, and the only interface

144
00:23:15,660 --> 00:23:26,060
was the command line. 1983? Yeah, I think that's when I got my first computer. I mean,

145
00:23:26,060 --> 00:23:29,580
The commands that I was tapping was more like load and then name of the game.

146
00:23:29,580 --> 00:23:36,340
I don't remember now the basic commands, but you know, that was my first interface

147
00:23:36,340 --> 00:23:38,740
interaction with the computer.

148
00:23:38,740 --> 00:23:44,580
Even though I was ex-sport, because my dad with this job, he also has access to one of

149
00:23:44,580 --> 00:23:47,180
these computers with punch cards.

150
00:23:47,180 --> 00:23:53,900
So I've seen also those back in the days, but more, you know, back to nowadays, yes,

151
00:23:53,900 --> 00:23:56,980
the command line is maybe the most powerful tool.

152
00:23:56,980 --> 00:23:59,980
I will share a link actually, there's a nice nature paper

153
00:23:59,980 --> 00:24:03,300
that they show how important it is to learn the command line

154
00:24:03,300 --> 00:24:05,580
or all type of science.

155
00:24:05,580 --> 00:24:08,140
Virtual control, it's actually all the pages,

156
00:24:08,140 --> 00:24:13,020
the web pages that you see that we in our documentation

157
00:24:13,020 --> 00:24:14,780
or even the websites that we share sometimes,

158
00:24:14,780 --> 00:24:16,980
they're all actually based using,

159
00:24:16,980 --> 00:24:20,380
they're all written and shared through Git and GitHub.

160
00:24:20,380 --> 00:24:23,900
So even though it's not just for, you know,

161
00:24:23,900 --> 00:24:25,020
keeping track of your code,

162
00:24:25,020 --> 00:24:27,660
it can also be very useful for publishing.

163
00:24:29,260 --> 00:24:32,460
And in general, I mean, a bit of Python, a bit of R,

164
00:24:32,460 --> 00:24:34,580
MATLAB, I used a lot of MATLAB in the past

165
00:24:34,580 --> 00:24:37,540
because with neuroscience, which is my background,

166
00:24:37,540 --> 00:24:39,520
we have lots of those tools.

167
00:24:39,520 --> 00:24:44,380
But great to see that many people are connected.

168
00:24:44,380 --> 00:24:48,740
There's 41 people in this HedgeDoc notes document.

169
00:24:48,740 --> 00:24:50,960
So if you feel that it's getting a bit slow,

170
00:24:50,960 --> 00:24:54,040
you can switch to the view mode.

171
00:24:54,040 --> 00:24:55,780
And what were you saying, [name]?

172
00:24:55,780 --> 00:24:58,020
Yeah, and I guess we're about to start.

173
00:24:58,020 --> 00:25:00,600
If we look at the icebreaker answers here,

174
00:25:00,600 --> 00:25:03,960
people are basically answering what we'd expect.

175
00:25:03,960 --> 00:25:07,200
So the audience as a whole seems to be

176
00:25:07,200 --> 00:25:09,520
at the right level for this course.

177
00:25:09,520 --> 00:25:14,520
So we are not talking about the prerequisites

178
00:25:16,240 --> 00:25:18,520
of most of these kinds of things.

179
00:25:18,520 --> 00:25:26,680
important tools you'll use but not the main topic of the course. Our main topic is this section

180
00:25:26,680 --> 00:25:34,360
right here. Although our team doesn't just support the cluster, we support everything that you see

181
00:25:34,360 --> 00:25:41,560
on this list. So as you'll learn later on, we have different help sessions where you can come

182
00:25:41,560 --> 00:25:48,440
and we're around to help with all of these things because we completely understand that computers are

183
00:25:48,440 --> 00:25:54,520
complex. There's just so many different things that people have to know and learn in order to

184
00:25:54,520 --> 00:26:01,320
do stuff. And that's why our team's funded. So you can focus on your work and we focus on

185
00:26:02,280 --> 00:26:09,080
the other stuff. With that being said, I guess it's time to start. So I believe it's

186
00:26:09,080 --> 00:26:15,880
[name] and [name] with the intro. So I'll hide myself and switch to [name]'s screen.

187
00:26:18,440 --> 00:26:21,980
Uh, there you go.

188
00:26:21,980 --> 00:26:23,780
So see you later.

189
00:26:24,680 --> 00:26:27,020
So the page that I'm showing right now,

190
00:26:27,020 --> 00:26:29,640
the webpage that I'm showing is the same

191
00:26:29,640 --> 00:26:32,880
that you have received in the email if you register.

192
00:26:32,880 --> 00:26:36,500
And if you have access also to this notes document

193
00:26:36,500 --> 00:26:39,380
that you've been using for writing your answers,

194
00:26:39,380 --> 00:26:41,780
it's also at the very top.

195
00:26:41,780 --> 00:26:45,340
And this is basically kind of the collection of links

196
00:26:45,340 --> 00:26:47,740
that we will use throughout the day.

197
00:26:47,740 --> 00:26:51,420
So if I scroll down to the schedule,

198
00:26:51,420 --> 00:26:53,060
we are basically here.

199
00:26:53,060 --> 00:26:57,300
And very briefly, I give you a little start

200
00:26:57,300 --> 00:27:01,100
or a little intro of what is happening right now

201
00:27:01,100 --> 00:27:02,620
and what is this.

202
00:27:02,620 --> 00:27:04,900
So I guess you already heard who we are.

203
00:27:04,900 --> 00:27:08,500
We are the people from other scientific computing,

204
00:27:09,580 --> 00:27:12,060
kind of our part of the School of Science.

205
00:27:12,060 --> 00:27:14,020
We help everyone at Aalto basically,

206
00:27:14,020 --> 00:27:18,820
we support large performance, high performance computing.

207
00:27:18,820 --> 00:27:22,500
And as [name] just said, all sorts of requests

208
00:27:22,500 --> 00:27:24,580
that can be related to software,

209
00:27:24,580 --> 00:27:26,780
but not only software, also data,

210
00:27:26,780 --> 00:27:28,740
open science and many other things.

211
00:27:28,740 --> 00:27:30,820
We are well integrated with all the other

212
00:27:30,820 --> 00:27:34,100
research services network and IT services networks.

213
00:27:34,100 --> 00:27:37,460
So we're all in working together

214
00:27:37,460 --> 00:27:40,140
to support people at Aalto University.

215
00:27:40,140 --> 00:27:41,860
On top of that, we also collaborate a lot

216
00:27:41,860 --> 00:27:46,300
with other universities in Finland and with CSC,

217
00:27:46,300 --> 00:27:49,500
which is the main partner for computational resources

218
00:27:49,500 --> 00:27:53,100
for basically all the Finnish researchers.

219
00:27:53,100 --> 00:27:56,180
And we also belong to the Code Refinery Network,

220
00:27:56,180 --> 00:27:59,700
which is a network that spans across all the Nordic countries

221
00:27:59,700 --> 00:28:02,500
where we organize this type of workshop.

222
00:28:02,500 --> 00:28:06,460
The course for today, normally we have this course

223
00:28:06,460 --> 00:28:09,300
and we will have this course as a three days course,

224
00:28:09,300 --> 00:28:11,620
so much longer and much slower.

225
00:28:11,620 --> 00:28:13,480
We have it in the first week of June,

226
00:28:13,480 --> 00:28:15,160
and we do it because that's the week

227
00:28:15,160 --> 00:28:19,800
when the summer workers are joining at the university.

228
00:28:19,800 --> 00:28:21,840
So usually the scale there is much bigger.

229
00:28:21,840 --> 00:28:24,680
We have 300 participants,

230
00:28:24,680 --> 00:28:28,240
and then we basically,

231
00:28:28,240 --> 00:28:30,480
instead of having just a single day like we have today,

232
00:28:30,480 --> 00:28:33,080
we have multiple days where we can cover

233
00:28:33,080 --> 00:28:34,640
in detail all the topics.

234
00:28:34,640 --> 00:28:38,000
So if you wish to have a more in-depth,

235
00:28:38,000 --> 00:28:41,840
like deeper overview of everything.

236
00:28:41,840 --> 00:28:44,000
I recommend joining the June version,

237
00:28:44,000 --> 00:28:45,680
the longer version of this course.

238
00:28:45,680 --> 00:28:48,440
But now here, most of you already have a Triton account,

239
00:28:48,440 --> 00:28:52,040
already have maybe even submitted jobs

240
00:28:52,040 --> 00:28:53,880
and work with Triton.

241
00:28:53,880 --> 00:28:56,720
So this is more like a compressed two hours

242
00:28:56,720 --> 00:29:00,960
of what can you do with HPC and specifically with Triton.

243
00:29:00,960 --> 00:29:03,620
And then in the afternoon, we can actually spend time.

244
00:29:03,620 --> 00:29:05,720
We have three hours together where we can do

245
00:29:05,720 --> 00:29:10,160
whether you want to do the basic exercises that we have,

246
00:29:10,160 --> 00:29:14,860
or maybe you want to learn how to run large language models

247
00:29:14,860 --> 00:29:17,360
like local large language models on Triton,

248
00:29:17,360 --> 00:29:19,880
or maybe you have more advanced needs,

249
00:29:19,880 --> 00:29:22,040
whether you need to use GPUs

250
00:29:22,040 --> 00:29:25,200
or some other more advanced parallel programming.

251
00:29:25,200 --> 00:29:27,520
So the afternoon part, if you want to join,

252
00:29:27,520 --> 00:29:30,440
that will happen in Zoom,

253
00:29:30,440 --> 00:29:32,420
and it would be much more interactive.

254
00:29:32,420 --> 00:29:36,920
I don't basically need to go through all the practicalities,

255
00:29:36,920 --> 00:29:38,660
but maybe what you're already feeling right now

256
00:29:38,660 --> 00:29:40,660
that instead of being in a Zoom room,

257
00:29:40,660 --> 00:29:42,940
right now we're using Twitch TV,

258
00:29:42,940 --> 00:29:45,580
which is basically like a TV streaming.

259
00:29:45,580 --> 00:29:48,180
And the main advantage is that with Twitch TV,

260
00:29:48,180 --> 00:29:49,640
as soon as the streaming stops,

261
00:29:49,640 --> 00:29:51,980
the recording will be immediately available

262
00:29:51,980 --> 00:29:54,580
so that you can re-watch it later today

263
00:29:54,580 --> 00:29:56,420
or whenever you want.

264
00:29:56,420 --> 00:29:58,420
And on top of that, we don't have the issue that,

265
00:29:58,420 --> 00:29:59,780
you know, sometimes in Zoom,

266
00:29:59,780 --> 00:30:03,580
there might be some participants that might appear

267
00:30:03,580 --> 00:30:08,580
on the screen or maybe a microphone that are not unmuted.

268
00:30:09,740 --> 00:30:12,100
So we don't have this type of issues.

269
00:30:13,820 --> 00:30:16,180
Basically, what else can I say

270
00:30:16,180 --> 00:30:21,180
that we use this type of vertical screen sharing?

271
00:30:21,180 --> 00:30:25,900
And the reason is that for those who have only one screen,

272
00:30:25,900 --> 00:30:27,740
so kind of laptop users,

273
00:30:27,740 --> 00:30:30,780
they can have within the same screen space,

274
00:30:30,780 --> 00:30:33,560
basically a space for the Twitch stream,

275
00:30:33,560 --> 00:30:36,180
where they can watch the streaming

276
00:30:36,180 --> 00:30:39,700
and in the other, in the rest of the screen,

277
00:30:39,700 --> 00:30:42,460
they can keep the web browser open and so on.

278
00:30:42,460 --> 00:30:44,100
Of course, if you have multiple screens,

279
00:30:44,100 --> 00:30:45,140
you don't have this issue,

280
00:30:45,140 --> 00:30:48,100
but with this approach, we are able,

281
00:30:48,100 --> 00:30:50,860
you should be able to always have the window,

282
00:30:50,860 --> 00:30:52,380
the streaming window visible.

283
00:30:54,060 --> 00:30:56,700
Maybe I don't need to go through everything,

284
00:30:56,700 --> 00:31:02,940
but if something goes wrong, it can happen, stay in tune and, you know, if the streaming

285
00:31:04,140 --> 00:31:09,740
disappears or something like that, we will try to get it back and if there's larger technical

286
00:31:09,740 --> 00:31:17,260
issues, we have already a plan B for everything. Just a last reminder that, you know, we follow

287
00:31:17,260 --> 00:31:23,900
the Alto Code of Conduct and so we hope that this is a great experience for everyone and if you

288
00:31:23,900 --> 00:31:32,340
feel that something is wrong just get in touch with one of the organizers so we

289
00:31:32,340 --> 00:31:41,660
still have some 10 minutes [name] are you there? I'm here there was a short network

290
00:31:41,660 --> 00:31:48,020
error but I think we have recovered. Okay was it on my side or on your side? It

291
00:31:48,020 --> 00:31:49,580
It might be on my side.

292
00:31:49,580 --> 00:31:50,940
OK.

293
00:31:50,940 --> 00:31:54,140
So maybe I'll ask you.

294
00:31:54,140 --> 00:31:57,060
Did we say how people can write questions in the notes

295
00:31:57,060 --> 00:31:58,620
at any time?

296
00:31:58,620 --> 00:31:59,300
True.

297
00:31:59,300 --> 00:32:00,740
So that's the same notes document

298
00:32:00,740 --> 00:32:04,420
that you already were using for these icebreakers.

299
00:32:04,420 --> 00:32:06,820
You can use it for writing questions there.

300
00:32:06,820 --> 00:32:10,060
And so anything that comes to your mind,

301
00:32:10,060 --> 00:32:11,500
please write it there.

302
00:32:11,500 --> 00:32:14,380
And then we can give answers.

303
00:32:14,380 --> 00:32:16,320
It also gets all the links to whatever

304
00:32:16,320 --> 00:32:19,000
we're looking at and any notes we're sending to you.

305
00:32:19,000 --> 00:32:21,080
And everyone you don't see on the stream

306
00:32:21,080 --> 00:32:23,480
is there watching that and answering your questions.

307
00:32:23,480 --> 00:32:25,720
So go for it.

308
00:32:25,720 --> 00:32:26,560
Okay, that's all.

309
00:32:26,560 --> 00:32:30,640
Yes, we have a big network of helpers already.

310
00:32:30,640 --> 00:32:35,640
So if I ask you, Suza, what is scientific computing?

311
00:32:36,960 --> 00:32:38,280
How would you answer that?

312
00:32:40,120 --> 00:32:43,040
Basically, I would answer that scientific computing

313
00:32:43,040 --> 00:32:55,760
is, at the baseline, every part of computing that helps science, that helps researchers.

314
00:32:55,760 --> 00:33:03,920
And then, obviously, you would want to ask, what is computing? And, well, computing is

315
00:33:03,920 --> 00:33:12,520
using computers instead of pen and paper to solve your problems. So solving problems with

316
00:33:12,520 --> 00:33:17,320
help of computer to help research is what scientific computing is.

317
00:33:18,840 --> 00:33:26,840
Yes, I totally agree. There's this funny xkcd. Someone said that there's always an xkcd for

318
00:33:26,840 --> 00:33:33,080
anything related to computing or computers. And you know, is this your machine learning system?

319
00:33:33,080 --> 00:33:38,200
So you know, it's like a pile of stuff. And sometimes we have this maybe approach to computing

320
00:33:38,200 --> 00:33:43,960
that we might not understand all the bits that are happening inside the pile. So we kind of maybe

321
00:33:43,960 --> 00:33:49,400
have a kind of some sort of black box experience with the computing that some data comes in and

322
00:33:49,400 --> 00:33:57,080
something comes out. So this very short introduction is actually trying to, you know, open this black

323
00:33:57,080 --> 00:34:03,880
box. And I think it's still important to get the basic. So like [name] was saying, a common site,

324
00:34:03,880 --> 00:34:07,400
if you're computing flowchart would be that you know that you have some data,

325
00:34:07,400 --> 00:34:13,480
whether it's collected data or simulations, and then there is some processing happening,

326
00:34:13,480 --> 00:34:16,680
and then you generate some outputs that can be statistical tables,

327
00:34:18,680 --> 00:34:23,960
AI model, machine learning models, whatever is the output, and then you know you write papers,

328
00:34:23,960 --> 00:34:30,200
posters, figures, and publish, and become successful, and you know be a famous scientist.

329
00:34:30,200 --> 00:34:35,960
But then what actually happens in practice, and I think this is very important because

330
00:34:35,960 --> 00:34:43,800
we were chatting with others that sometimes this jargon of the basically hardware that

331
00:34:43,800 --> 00:34:49,480
is needed for doing scientific computing is just assumed that everybody knows about everything,

332
00:34:49,480 --> 00:34:51,320
but maybe it is not like that.

333
00:34:51,320 --> 00:34:56,720
And I also think that it's important once someone knows how the components are connected

334
00:34:56,720 --> 00:34:57,560
with each other.

335
00:34:57,560 --> 00:35:00,040
And if they're actually physically close to each other

336
00:35:00,040 --> 00:35:02,100
or physically far away from each other,

337
00:35:02,100 --> 00:35:03,960
then it can also affect, you know,

338
00:35:03,960 --> 00:35:05,160
is it going to be fast?

339
00:35:05,160 --> 00:35:07,240
Because yes, the memory that I'm using

340
00:35:07,240 --> 00:35:10,960
is really few millimeters away

341
00:35:10,960 --> 00:35:14,440
from the computing that is happening.

342
00:35:14,440 --> 00:35:17,480
Or is it that the data that I'm loading

343
00:35:17,480 --> 00:35:21,720
is far away in some remote server in the cloud,

344
00:35:21,720 --> 00:35:22,920
as they say.

345
00:35:22,920 --> 00:35:26,600
So what do you see here in this type of stacked

346
00:35:26,600 --> 00:35:30,000
picture is basically that we, you right now,

347
00:35:30,000 --> 00:35:32,200
even with your laptop or with your desktop computer

348
00:35:32,200 --> 00:35:33,520
that you're watching this stream,

349
00:35:33,520 --> 00:35:37,000
or even with the phone, because the thing is similar.

350
00:35:37,000 --> 00:35:39,560
We have the hardware level and inside the hardware,

351
00:35:39,560 --> 00:35:44,000
the physical box, there are CPUs, GPUs,

352
00:35:44,920 --> 00:35:47,560
RAM, SSD, and the network.

353
00:35:47,560 --> 00:35:51,320
So these elements, there are the definitions here

354
00:35:51,320 --> 00:35:53,040
and we will not go through the definitions.

355
00:35:53,040 --> 00:35:55,640
Maybe this is familiar to all of you,

356
00:35:55,640 --> 00:35:58,000
But already, if you feel that you don't know

357
00:35:58,000 --> 00:35:59,600
what are all these elements,

358
00:35:59,600 --> 00:36:02,480
then you already might be kind of missing

359
00:36:02,480 --> 00:36:04,800
in the moment where you later you will see

360
00:36:04,800 --> 00:36:07,560
that you request some computing resources

361
00:36:07,560 --> 00:36:09,340
from an HPC cluster.

362
00:36:09,340 --> 00:36:11,600
You are going to be asked, do you need CPUs?

363
00:36:11,600 --> 00:36:12,680
How many do you need?

364
00:36:12,680 --> 00:36:14,720
How much RAM do you need?

365
00:36:14,720 --> 00:36:15,800
Do you need GPUs?

366
00:36:15,800 --> 00:36:17,560
Do you need to use the local disk,

367
00:36:17,560 --> 00:36:19,880
which is this SST here?

368
00:36:19,880 --> 00:36:22,520
Or will you use some network disk

369
00:36:22,520 --> 00:36:27,520
that is not physically inside the hardware that you use.

370
00:36:27,520 --> 00:36:30,240
So these type of things are actually things

371
00:36:30,240 --> 00:36:31,800
that you will need to think about daily

372
00:36:31,800 --> 00:36:35,320
when you work with high-performance computing systems,

373
00:36:35,320 --> 00:36:39,640
but they're basically things that sometimes you,

374
00:36:39,640 --> 00:36:43,380
how can I say, forget that they are always there

375
00:36:43,380 --> 00:36:45,300
whenever you are working.

376
00:36:46,420 --> 00:36:48,160
On top of the hardware level,

377
00:36:48,160 --> 00:36:49,580
there's the operating system

378
00:36:49,580 --> 00:36:53,260
that basically is basically interacting with the hardware

379
00:36:53,260 --> 00:36:55,260
and then enabling the fact that on top

380
00:36:55,260 --> 00:36:56,340
of the operating system,

381
00:36:56,340 --> 00:36:59,780
you can run your Python or MATLAB or R.

382
00:36:59,780 --> 00:37:03,900
There's a nice little box here about containers.

383
00:37:03,900 --> 00:37:06,180
We will not cover those today,

384
00:37:06,180 --> 00:37:09,580
but basically it's like bringing another operating system

385
00:37:09,580 --> 00:37:12,820
with the software on top of the operating system

386
00:37:12,820 --> 00:37:13,660
and the hardware.

387
00:37:14,980 --> 00:37:17,460
So without going through this definition

388
00:37:17,460 --> 00:37:18,580
that maybe some of you have,

389
00:37:18,580 --> 00:37:22,500
I just want to show that we have a great video series

390
00:37:22,500 --> 00:37:26,260
on understanding computing through the kitchen metaphor.

391
00:37:26,260 --> 00:37:28,140
So I will not show the video right now,

392
00:37:28,140 --> 00:37:29,820
but it's linked in the page.

393
00:37:29,820 --> 00:37:34,700
And in the video, there's gonna be [name] with a cat.

394
00:37:34,700 --> 00:37:38,780
Actually, they are going to basically explain

395
00:37:38,780 --> 00:37:42,260
how all these elements, the CPU, the GPU,

396
00:37:42,260 --> 00:37:46,220
the RAM, and so on, are kind of connected to each other

397
00:37:46,220 --> 00:37:48,100
and what it actually means in practice

398
00:37:48,100 --> 00:37:51,340
for your day-to-day work.

399
00:37:51,340 --> 00:37:53,060
There's also a set of slides

400
00:37:53,060 --> 00:37:58,060
with this metaphor of the parallel computing in the kitchen.

401
00:38:00,180 --> 00:38:03,260
And so the metaphor kind of goes,

402
00:38:03,260 --> 00:38:04,820
if I can cover it just briefly,

403
00:38:04,820 --> 00:38:06,500
we have still a couple of minutes,

404
00:38:06,500 --> 00:38:10,620
that each burner of a stove is like a core,

405
00:38:10,620 --> 00:38:12,700
it's like one of this CPU.

406
00:38:12,700 --> 00:38:17,180
and then the whole store stove is like the processor.

407
00:38:17,180 --> 00:38:20,180
Then, you have the memory, which is the counter space

408
00:38:20,180 --> 00:38:23,460
where you can leave some of your ingredients that you need,

409
00:38:23,460 --> 00:38:25,460
that you need to move inside these pots

410
00:38:25,460 --> 00:38:27,820
on top of the burners.

411
00:38:27,820 --> 00:38:31,100
And then of course, if the kitchen counter

412
00:38:31,100 --> 00:38:34,660
have the ingredients that are ready easily to access,

413
00:38:34,660 --> 00:38:35,820
you might have more ingredient

414
00:38:35,820 --> 00:38:39,260
that are a little bit more far away in the fridge,

415
00:38:39,260 --> 00:38:41,900
for example, or in some other cupboards.

416
00:38:41,900 --> 00:38:44,820
And then you have the instructions, which is the program.

417
00:38:44,820 --> 00:38:47,780
So the recipe that takes all these ingredients

418
00:38:47,780 --> 00:38:50,580
and on top of one core or maybe more core,

419
00:38:50,580 --> 00:38:54,780
if you need to cook multiple things in parallel,

420
00:38:54,780 --> 00:38:57,260
can basically process the ingredients

421
00:38:57,260 --> 00:39:00,020
and generate the output, which is the food.

422
00:39:01,020 --> 00:39:03,660
We don't have time to go through this metaphor

423
00:39:03,660 --> 00:39:06,580
and everything, but I really like this picture

424
00:39:06,580 --> 00:39:10,140
that, for example, what if you don't have enough CPU

425
00:39:10,140 --> 00:39:11,540
or enough memory.

426
00:39:11,540 --> 00:39:13,460
This, I don't know if this has ever happened to you

427
00:39:13,460 --> 00:39:15,760
in your kitchen, probably not.

428
00:39:15,760 --> 00:39:17,540
But you know, you have these cases

429
00:39:17,540 --> 00:39:19,820
where the kitchen counter is too small.

430
00:39:19,820 --> 00:39:21,980
You just can't fit all the ingredients there.

431
00:39:21,980 --> 00:39:26,740
You don't have enough burners to cook everything.

432
00:39:26,740 --> 00:39:30,660
And so this is also when things might start slowing down

433
00:39:30,660 --> 00:39:34,260
or maybe where your process might actually die

434
00:39:34,260 --> 00:39:37,020
because you don't have enough memory and it gets killed.

435
00:39:37,020 --> 00:39:40,600
Another last thing that I want to mention,

436
00:39:40,600 --> 00:39:45,080
that sometimes people have expectations about clusters.

437
00:39:45,080 --> 00:39:47,320
Working in a cluster doesn't necessarily means

438
00:39:47,320 --> 00:39:49,080
that it's gonna be faster.

439
00:39:49,080 --> 00:39:50,480
And here there's a nice example

440
00:39:50,480 --> 00:39:52,400
that the laptop processing unit

441
00:39:54,120 --> 00:39:56,920
might actually have more power than the stove

442
00:39:56,920 --> 00:39:59,160
that has to share all the power

443
00:39:59,160 --> 00:40:02,040
with the multiple processing units.

444
00:40:02,040 --> 00:40:05,480
So often your laptop as a single processing unit

445
00:40:05,480 --> 00:40:09,540
is much faster than let's say that the same processing unit

446
00:40:09,540 --> 00:40:12,100
in a cluster, in a server.

447
00:40:12,100 --> 00:40:14,500
But of course, it's also kind of the compromise

448
00:40:14,500 --> 00:40:17,540
that on the laptop you have only one

449
00:40:17,540 --> 00:40:19,540
or a handful of processing unit.

450
00:40:19,540 --> 00:40:22,540
In the cluster, you can actually run thousands,

451
00:40:22,540 --> 00:40:25,940
tens of thousands of processing unit in parallel.

452
00:40:25,940 --> 00:40:27,380
But then again, what you need to understand

453
00:40:27,380 --> 00:40:30,220
is that is your code written in a way

454
00:40:30,220 --> 00:40:33,100
that can actually use the tens of thousands

455
00:40:33,100 --> 00:40:34,300
of processing unit?

456
00:40:34,300 --> 00:40:36,140
Or is it that when you move it to the cluster,

457
00:40:36,140 --> 00:40:37,980
it will just use one processing unit,

458
00:40:37,980 --> 00:40:40,560
which is actually slower than the one

459
00:40:40,560 --> 00:40:43,060
that you have in your laptop.

460
00:40:43,060 --> 00:40:45,360
So all of these will be covered later

461
00:40:45,360 --> 00:40:47,260
with the example during the morning.

462
00:40:48,340 --> 00:40:51,400
And just the final picture, the GPU.

463
00:40:51,400 --> 00:40:52,420
I find it very funny.

464
00:40:52,420 --> 00:40:57,300
So where GPUs are like the burners,

465
00:40:57,300 --> 00:40:59,540
but in parallel, you can cook multiple,

466
00:40:59,540 --> 00:41:01,940
in this case, you know, chickens.

467
00:41:01,940 --> 00:41:04,760
So it's a large system that at the same time

468
00:41:04,760 --> 00:41:07,980
can do the same operation multiple times.

469
00:41:09,720 --> 00:41:13,560
So hopefully this was, how can I say,

470
00:41:13,560 --> 00:41:15,880
inspiring enough and motivating enough

471
00:41:15,880 --> 00:41:19,480
and maybe you all knew about these things.

472
00:41:19,480 --> 00:41:21,160
We don't really have time to cover this

473
00:41:21,160 --> 00:41:22,560
but you can read this page

474
00:41:22,560 --> 00:41:26,120
and there's even a video related to this page.

475
00:41:26,120 --> 00:41:28,080
But basically this is what I was just saying

476
00:41:28,080 --> 00:41:31,880
that sometimes moving the stuff to the cluster

477
00:41:31,880 --> 00:41:36,200
doesn't automatically make things faster.

478
00:41:37,120 --> 00:41:43,720
So, I'm basically ready to switch to pass the ...

479
00:41:43,720 --> 00:41:45,800
Or do you want to add anything, Suza,

480
00:41:45,800 --> 00:41:47,520
that might be good for clarifying?

481
00:41:48,720 --> 00:41:50,640
No, I think you covered most things.

482
00:41:51,400 --> 00:41:57,760
Excellent. So, I would also switch the screen

483
00:41:57,760 --> 00:41:59,280
to [name] and [name],

484
00:41:59,280 --> 00:42:01,160
but do you want me first to explain a bit

485
00:42:01,160 --> 00:42:06,600
of the geography of the cluster or will you go through, you know, what is the login node then?

486
00:42:08,040 --> 00:42:10,840
I think it's probably good if you would explain that.

487
00:42:11,480 --> 00:42:18,600
All right, so basically one thing, like you're all familiar with your own laptop or desktop, you

488
00:42:19,960 --> 00:42:26,600
log in with your username and password and basically this is where you would be, you know,

489
00:42:26,600 --> 00:42:32,520
that you have a desktop or you have a laptop it can be in the Alto network that you see here because

490
00:42:32,520 --> 00:42:40,040
it's in a it's in a it's in a office at Alto or maybe you're at home in the internet with your

491
00:42:40,040 --> 00:42:47,880
with your laptop so then we Alto uses this virtual private network and the idea is not to make your

492
00:42:47,880 --> 00:42:52,680
life more difficult the idea is that once you know that your laptop your personal laptop or

493
00:42:52,680 --> 00:42:55,440
or your computer that are part of the network,

494
00:42:55,440 --> 00:42:57,960
then other bits that are inside the network

495
00:42:57,960 --> 00:42:59,740
also becomes accessible.

496
00:42:59,740 --> 00:43:02,040
The reason, of course, is kind of confidentiality

497
00:43:02,040 --> 00:43:04,200
of the information that might be moving

498
00:43:04,200 --> 00:43:06,300
between these different elements.

499
00:43:06,300 --> 00:43:08,760
And in general, it also makes it easier

500
00:43:08,760 --> 00:43:11,420
to prevent external attacks.

501
00:43:11,420 --> 00:43:14,560
So using the VPN in the end is useful,

502
00:43:14,560 --> 00:43:18,440
but of course there are also ways to connect to this system

503
00:43:18,440 --> 00:43:21,480
without necessarily being in the VPN.

504
00:43:21,480 --> 00:43:23,080
But for simplicity, let's say that now

505
00:43:23,080 --> 00:43:24,240
you're in the Alto VPN.

506
00:43:24,240 --> 00:43:25,920
So now you actually have access

507
00:43:25,920 --> 00:43:28,560
to all these different elements that you see here.

508
00:43:28,560 --> 00:43:30,240
There are the department workstation,

509
00:43:30,240 --> 00:43:33,160
maybe you have one, or maybe that you're given a laptop.

510
00:43:33,160 --> 00:43:36,120
We also have this type of external interface,

511
00:43:36,120 --> 00:43:41,120
vdi.alto.fi, where you can basically get a virtual desktop.

512
00:43:41,120 --> 00:43:44,000
That's the VD, virtual desktop interface,

513
00:43:44,000 --> 00:43:46,680
so that you know you are, I don't know,

514
00:43:46,680 --> 00:43:49,040
out for a conference, but you don't have

515
00:43:49,040 --> 00:43:51,440
your Alto laptop with you and you need to access something,

516
00:43:51,440 --> 00:43:54,240
you can always go to this vdi.alto.fi

517
00:43:54,240 --> 00:43:55,960
and see the file system,

518
00:43:55,960 --> 00:43:58,720
the same thing that you will still see in the department.

519
00:43:58,720 --> 00:44:00,020
And then there's the Triton cluster.

520
00:44:00,020 --> 00:44:01,320
So the idea of the cluster

521
00:44:01,320 --> 00:44:04,800
is that there is another network inside the network.

522
00:44:04,800 --> 00:44:08,760
And this network between these hundreds of computers

523
00:44:08,760 --> 00:44:12,020
is actually very, very fast, extremely fast.

524
00:44:12,020 --> 00:44:13,200
It's called InfiniBand,

525
00:44:13,200 --> 00:44:15,120
and it's a type of connectivity

526
00:44:15,120 --> 00:44:18,480
between all these multiple computers that we have there

527
00:44:18,480 --> 00:44:22,300
that it allows really quick exchange of information.

528
00:44:22,300 --> 00:44:24,700
Instead, if something from the Triton cluster

529
00:44:24,700 --> 00:44:25,860
would need to talk, let's say,

530
00:44:25,860 --> 00:44:27,380
with the department or station

531
00:44:27,380 --> 00:44:30,740
or with the storage that is outside of the Triton network,

532
00:44:30,740 --> 00:44:33,300
things would already feel slower.

533
00:44:34,220 --> 00:44:37,220
The thing is that to enter the Triton cluster network,

534
00:44:37,220 --> 00:44:39,280
you need to go through the so-called login node,

535
00:44:39,280 --> 00:44:41,700
which is triton.data.fi.

536
00:44:41,700 --> 00:44:43,220
Now I put this sign there,

537
00:44:43,220 --> 00:44:45,700
which is, for those who have a driving license,

538
00:44:45,700 --> 00:44:48,220
it means that you should not stop there,

539
00:44:48,220 --> 00:44:51,340
even if you wanna stop the car for a few seconds,

540
00:44:51,340 --> 00:44:53,660
it's not good, you need to move on.

541
00:44:53,660 --> 00:44:55,140
And the idea is that the login node

542
00:44:55,140 --> 00:44:57,660
is good for connecting to the cluster,

543
00:44:57,660 --> 00:44:59,020
running simple things,

544
00:44:59,020 --> 00:45:02,540
but then what you wanna do is getting a dedicated node

545
00:45:02,540 --> 00:45:05,980
that is just for you with the resources that you need.

546
00:45:05,980 --> 00:45:09,340
Do you need a CPU, one CPU, many CPUs,

547
00:45:09,340 --> 00:45:11,660
a little RAM, lots of RAM, and so on.

548
00:45:12,520 --> 00:45:15,100
This will come clearer with the examples

549
00:45:15,100 --> 00:45:16,860
that are given in the morning

550
00:45:16,860 --> 00:45:20,740
and also later in the afternoon with the exercises.

551
00:45:20,740 --> 00:45:22,980
Then Triton has its own storage system.

552
00:45:22,980 --> 00:45:26,220
And the reason is exactly is this speed reason

553
00:45:26,220 --> 00:45:29,260
that if Triton would try to access the storage system

554
00:45:29,260 --> 00:45:31,420
that you have in other Alto computers,

555
00:45:31,420 --> 00:45:33,220
it would take the Alto network down

556
00:45:33,220 --> 00:45:36,700
because all the IO that is going on between the nodes

557
00:45:36,700 --> 00:45:39,780
and the external storage will be too much.

558
00:45:39,780 --> 00:45:41,300
So this is why we have a dedicated

559
00:45:41,300 --> 00:45:44,780
so-called scratch storage system.

560
00:45:44,780 --> 00:45:46,800
The disadvantage of that,

561
00:45:46,800 --> 00:45:49,040
the good thing is that Scratch is huge.

562
00:45:49,040 --> 00:45:52,320
We have five petabytes of Scratch space,

563
00:45:52,320 --> 00:45:54,760
and it's also very fast to read and write,

564
00:45:54,760 --> 00:45:57,520
but the problem with Scratch is that it's not backed up,

565
00:45:57,520 --> 00:45:59,120
and it's kind of the price to pay

566
00:45:59,120 --> 00:46:02,960
for having a huge and fast file system.

567
00:46:02,960 --> 00:46:04,400
So you understand that it's,

568
00:46:04,400 --> 00:46:06,480
this is the similar kind of architecture

569
00:46:06,480 --> 00:46:10,720
is also in other computing cluster like CSC.

570
00:46:10,720 --> 00:46:14,120
So you understand that it's every time you kind of feel

571
00:46:14,120 --> 00:46:15,440
that your analysis is ready,

572
00:46:15,440 --> 00:46:18,880
it's time to move it out of the scratch file system.

573
00:46:18,880 --> 00:46:21,200
Last thing that I want to mention is that we also have

574
00:46:21,200 --> 00:46:25,480
a kind of virtual desktop interface to the Triton cluster

575
00:46:25,480 --> 00:46:28,820
in this ondemand.triton.aalto.fi.

576
00:46:28,820 --> 00:46:31,960
So if, again, you are not with your computer

577
00:46:31,960 --> 00:46:36,960
or you need to visualize the files that you have generated

578
00:46:37,280 --> 00:46:40,040
or the picture or it runs on Jupyter Notebook,

579
00:46:40,040 --> 00:46:42,440
then this is the website that you want to visit.

580
00:46:42,440 --> 00:46:45,440
And I think I covered everything.

581
00:46:45,440 --> 00:46:54,440
How do you actually get, if you want to move something out from scratch, how do you get it out?

582
00:46:54,440 --> 00:47:01,440
Yeah, this will be my understanding some of the examples in the morning, but basically there are different ways.

583
00:47:01,440 --> 00:47:09,440
One way actually would be exactly this with this on demand, for example, that you can see the file system and get something out.

584
00:47:09,440 --> 00:47:12,320
But of course, there are all these other,

585
00:47:12,320 --> 00:47:15,240
in our documentation, we have, for example,

586
00:47:15,240 --> 00:47:18,240
you can actually, how can I say,

587
00:47:18,240 --> 00:47:22,080
make this file system visible in your operating system.

588
00:47:22,080 --> 00:47:24,800
So let's say that you have, I don't know,

589
00:47:24,800 --> 00:47:28,400
out the windows, you can actually make a scratch

590
00:47:28,400 --> 00:47:30,840
so that you see it with all the other letters

591
00:47:30,840 --> 00:47:33,080
of the disks that you have there.

592
00:47:33,080 --> 00:47:36,120
And then from there, you can basically copy some files out.

593
00:47:36,120 --> 00:47:37,960
So there's multiple different ways

594
00:47:37,960 --> 00:47:42,320
of getting data in and out of the Scratch file system.

595
00:47:42,320 --> 00:47:45,000
And we will show a bit of those.

596
00:47:45,000 --> 00:47:47,800
But yes, that's a very, very important question

597
00:47:47,800 --> 00:47:49,680
that we often get.

598
00:47:51,800 --> 00:47:55,920
All right, so is there something to lift up

599
00:47:55,920 --> 00:47:57,360
from the notes document

600
00:47:57,360 --> 00:47:59,360
or do you wanna take the screen share?

601
00:48:00,660 --> 00:48:03,000
There is some stuff there.

602
00:48:03,000 --> 00:48:07,800
I guess I can switch to the notes.

603
00:48:07,800 --> 00:48:09,560
Do you have the notes open on your computer

604
00:48:09,560 --> 00:48:11,440
or should I switch there?

605
00:48:11,440 --> 00:48:13,320
I should have them here.

606
00:48:13,320 --> 00:48:14,160
Okay.

607
00:48:23,640 --> 00:48:24,560
In the kitchen metaphor,

608
00:48:24,560 --> 00:48:27,560
what are the notes we define for Slurm?

609
00:48:27,560 --> 00:48:32,040
Yeah, this is a good question.

610
00:48:32,040 --> 00:48:38,800
Maybe Slurm can be seen as the chef manager that coordinates

611
00:48:38,800 --> 00:48:42,280
all the other little chefs in the multiple kitchens that

612
00:48:42,280 --> 00:48:46,720
are in this department, or in this apartment building.

613
00:48:46,720 --> 00:48:54,480
And I don't know if that's a good metaphor,

614
00:48:54,480 --> 00:48:57,000
but I see that people are answering, so that's good.

615
00:48:57,000 --> 00:48:59,420
Is there a smart way to move data between Triton, Scratch,

616
00:48:59,420 --> 00:49:00,080
and department?

617
00:49:00,080 --> 00:49:01,920
Yeah, this will be covered.

618
00:49:01,920 --> 00:49:03,400
And it's partly covered.

619
00:49:07,200 --> 00:49:14,000
All right, I don't think there's anything to mention.

620
00:49:14,000 --> 00:49:17,880
So maybe we can now switch to you, [name] and [name].

621
00:49:20,840 --> 00:49:21,340
Yes.

622
00:49:28,640 --> 00:49:30,000
Yeah, thanks for that intro.

623
00:49:30,000 --> 00:49:34,680
That puts us on the right path now.

624
00:49:34,680 --> 00:49:42,560
So yeah, as a reminder, keep asking questions.

625
00:49:42,560 --> 00:49:44,760
We'll be talking now, but there's other people

626
00:49:44,760 --> 00:49:46,080
who will be answering.

627
00:49:51,160 --> 00:49:51,760
Let's see.

628
00:49:57,200 --> 00:49:59,800
Yeah, so what do we do now?

629
00:49:59,800 --> 00:50:04,920
Now we've got an example where we go through exercises.

630
00:50:06,840 --> 00:50:14,120
Well, not really exercises. It's a demo. So we're going to go, we have this model problem

631
00:50:14,120 --> 00:50:19,960
where we analyze a bunch of public domain books from Project Gutenberg. We'll go through all

632
00:50:19,960 --> 00:50:27,720
the steps that someone might go through. So we will go through downloading data,

633
00:50:27,720 --> 00:50:32,280
copying to the cluster, getting our project set up, running things in different ways.

634
00:50:39,560 --> 00:50:45,080
And this example that we are going to be giving, it's not like, I wouldn't recommend trying to

635
00:50:45,080 --> 00:50:55,800
follow it, like type along it. It's better to watch it and try to see what is the usual

636
00:50:55,800 --> 00:51:01,640
like workflow that you might do when you're running stuff in the cluster. So what we're

637
00:51:01,640 --> 00:51:09,880
trying to show is a simple example that this is how a typical workflow might go through.

638
00:51:09,880 --> 00:51:17,240
Of course, the case here is very small, but we'll try to show a typical thing that people

639
00:51:17,240 --> 00:51:22,280
do when they're doing the cluster. And in the afternoon, we have a lot more time to actually

640
00:51:22,280 --> 00:51:27,080
replicate the same thing if you want to try it out yourself.

641
00:51:33,000 --> 00:51:40,680
Yeah, so normally we'd have this course over several days, over three days, where the first day

642
00:51:40,680 --> 00:51:48,760
is a broad intro and the second two days for four hours per day are doing exercises together.

643
00:51:48,760 --> 00:51:53,720
And now we're trying to do a similar amount of stuff in an hour and a half.

644
00:51:53,720 --> 00:52:03,000
So it really is an impossible situation we've got here that we're trying to do. But that's okay.

645
00:52:07,720 --> 00:52:15,560
Yes. So what's our example? So if you look down here in the notes, I've added a link to

646
00:52:15,560 --> 00:52:25,120
the series of things we'll be doing, but don't, this isn't something you can

647
00:52:25,120 --> 00:52:29,160
really follow because we'll be saying a lot of things that aren't in here, but

648
00:52:29,160 --> 00:52:40,640
this is sort of like the big picture thing. So our general plan is we do the

649
00:52:40,640 --> 00:52:46,400
demos now and then in the afternoon there's time you can come and work on it

650
00:52:46,400 --> 00:52:50,320
yourself by reading the material and trying to follow along in a more

651
00:52:50,320 --> 00:53:00,880
structured manner. I'm trying to give a link to the tutorials here. Okay I'm

652
00:53:00,880 --> 00:53:07,000
adding it to the notes. I think it's already used.

653
00:53:10,640 --> 00:53:21,080
Okay, yeah, so what is the example we want to do then?

654
00:53:21,080 --> 00:53:31,360
So our previous example was calculating pi, where basically we would, it's like a stochastic

655
00:53:31,360 --> 00:53:32,880
method of calculating pi.

656
00:53:32,880 --> 00:53:37,880
You pick a random point within a square and see does the point fall in a circle, and if

657
00:53:37,880 --> 00:53:45,480
do this enough, you can rearrange the fraction to be pi. But this is a more data example.

658
00:53:46,920 --> 00:53:58,120
So in this example, what we will do, we take Project Gutenberg is a project which takes

659
00:53:58,120 --> 00:54:05,480
public domain books and makes them available. So we found a data set of several thousands

660
00:54:05,480 --> 00:54:11,800
or tens of thousands of fiction books from Project Gutenberg. All of these books

661
00:54:13,400 --> 00:54:22,280
are taken, and we compute engrams in them. An engram is basically a sequence of words

662
00:54:22,280 --> 00:54:29,560
or characters that you see together. For example, th are often next to each other,

663
00:54:29,560 --> 00:54:38,840
or the words the is right before some other word and so on. So we have some simple code which can

664
00:54:38,840 --> 00:54:44,840
analyze all of these books and then compute the distribution of all n-grams within them.

665
00:54:47,960 --> 00:54:56,120
And yeah so if you want to you can take this and use it to predict the next words that might come

666
00:54:56,120 --> 00:55:05,240
up in a sequence. But we probably won't go that far. So is this an appropriate problem for a

667
00:55:05,240 --> 00:55:16,360
cluster? What would you say, [name]? Yeah, so I think this would be like, of course, if the problem

668
00:55:16,360 --> 00:55:20,520
becomes bigger, like if we are dealing with the whole Gutenberg dataset or something, like

669
00:55:20,520 --> 00:55:26,760
suddenly we have a huge amount of books, it immediately can go from like something that

670
00:55:26,760 --> 00:55:32,920
is feasible to do on your laptop to something that is only possible to do on a class.

671
00:55:33,640 --> 00:55:41,000
So this case is a good example of a case where you might want to split up the job

672
00:55:41,800 --> 00:55:48,600
among like books, like you maybe want to analyze some books with one computer and some other books

673
00:55:48,600 --> 00:55:53,720
with another computer so that you can do it faster, like you can easily split it up among

674
00:55:53,720 --> 00:56:01,400
the data. So it's very easy to get it rolling in the cluster. So it's very like a data-centric

675
00:56:01,400 --> 00:56:07,240
situation. And this can happen quite a lot. Often we are doing the same thing over and over again.

676
00:56:07,240 --> 00:56:15,240
And in this case, we are analyzing different books, but we could run different parameters

677
00:56:15,240 --> 00:56:20,120
and stuff like that. These kinds of cases are very good for the cluster because your laptop

678
00:56:21,560 --> 00:56:25,080
doesn't have to do all of those calculations itself.

679
00:56:26,600 --> 00:56:33,240
Yeah. There was this question earlier on how do you know if a problem will be well-suited

680
00:56:33,240 --> 00:56:40,760
for a cluster. In this case, like [name] said, since the data can be divided and each book can

681
00:56:40,760 --> 00:56:43,920
can be analyzed separately, then yes, this

682
00:56:43,920 --> 00:56:48,280
will probably be distributed pretty well among the cluster.

683
00:56:48,280 --> 00:56:51,160
We don't have any communication we need here.

684
00:56:51,160 --> 00:56:53,280
So we're already thinking that way.

685
00:56:53,280 --> 00:56:54,960
So of course, the data is a little bit

686
00:56:54,960 --> 00:56:56,560
too small to need the cluster.

687
00:56:56,560 --> 00:57:01,160
But well, it's an example, so that's OK.

688
00:57:01,160 --> 00:57:03,400
[name], should I switch to your screen?

689
00:57:03,400 --> 00:57:05,080
Yeah, sure.

690
00:57:05,080 --> 00:57:06,120
OK, let's see.

691
00:57:06,120 --> 00:57:18,680
Yeah, so you see here the series of exercises we'll do. We'll roughly be typing the things

692
00:57:18,680 --> 00:57:23,520
from here, although we won't be doing some of the earlier cluster from the command line

693
00:57:23,520 --> 00:57:29,240
exercises.

694
00:57:29,240 --> 00:57:33,640
Should we start with getting the data into Triton? The first thing usually what happens

695
00:57:33,640 --> 00:57:39,800
is that you have something you want to do and you need to get it to the cluster. So, in this case,

696
00:57:41,800 --> 00:57:44,680
what I would now do is download data to my own laptop.

697
00:57:45,720 --> 00:57:52,600
Yeah. So, quite often what we would have people do is try to transfer the data directly to the

698
00:57:52,600 --> 00:58:03,000
cluster and not downloading to your computer and then uploading to the cluster if the data is big.

699
00:58:03,000 --> 00:58:08,840
But we want to demonstrate how you would transfer data to a cluster because that's something that's

700
00:58:08,840 --> 00:58:14,200
really a common thing. It's something we haven't usually demonstrated.

701
00:58:15,000 --> 00:58:20,360
So, [name], you've downloaded a zip file. Yes, I see the zip file here.

702
00:58:22,360 --> 00:58:27,960
So, there's multiple ways you can do that transfer, but this time I will be using the

703
00:58:27,960 --> 00:58:34,840
ondemand that [name] brought up previously. So yeah, [name], if you explain what I'm doing.

704
00:58:34,840 --> 00:58:42,120
Okay, so ondemand is a web interface for the cluster. So you can go there with the web browser

705
00:58:42,680 --> 00:58:49,400
and then you can, so [name]'s already logged in here, you can browse different storage locations,

706
00:58:50,200 --> 00:58:57,880
you can get the shell access this way, you can run Jupyter or you can even get a graphical

707
00:58:57,880 --> 00:59:05,240
desktop here. This is nice because it's easy to use and can be used from any web browser.

708
00:59:05,960 --> 00:59:10,760
It's not the most powerful thing, but sometimes convenience is more important,

709
00:59:10,760 --> 00:59:13,240
and for this transferring data, that's the case.

710
00:59:16,120 --> 00:59:19,880
When we are talking about transferring data, where are we actually transferring the data?

711
00:59:20,920 --> 00:59:25,080
Yeah, that's a good question. Before we transfer the data, we need to stop and think,

712
00:59:25,080 --> 00:59:30,760
or do we want to put it? So, it often happens that people begin working, they throw data somewhere,

713
00:59:31,320 --> 00:59:34,520
and then it becomes a giant mess, and that's not good.

714
00:59:35,320 --> 00:59:39,400
So, this is a project. Will it be a personal project or a group project?

715
00:59:41,160 --> 00:59:43,320
Well, in this case, I would say it's a personal project.

716
00:59:45,160 --> 00:59:45,480
Let's say.

717
00:59:45,480 --> 00:59:50,600
So, we can put it in your personal Scratch directory, your personal work directory.

718
00:59:50,600 --> 00:59:57,880
So, even for personal projects, we would generally recommend that people create a shared directory

719
00:59:57,880 --> 01:00:04,120
for their group so you can share later when it comes up. But for something small, we can

720
01:00:04,120 --> 01:00:11,960
start here. So, I see [name] can browse to the work directory. It also shows the path of the cluster.

721
01:00:12,680 --> 01:00:16,840
Yeah. And because I have, of course, a lot of projects, I have a lot of

722
01:00:16,840 --> 01:00:26,680
directory is already here, so I'm going to jump into a subdirectory here so that we can keep it

723
01:00:26,680 --> 01:00:33,240
a bit clearer. For your case, your work directory might be completely empty, so you don't have to

724
01:00:33,240 --> 01:00:40,680
necessarily go into a subfolder. But it's usually a good idea to have some sort of mental separation

725
01:00:40,680 --> 01:00:45,960
between the projects and folder structure to represent that separation in the work directory

726
01:00:45,960 --> 01:00:54,040
so you can find whatever you have stored there. Yeah. Did you talk about the path here? So,

727
01:00:54,040 --> 01:01:00,360
we see it's slash scratch /work/[name]'s-username/teaching/winter-kickstart-2025/.

728
01:01:02,360 --> 01:01:09,160
Yeah. So, the main thing here is that the scratch directory, it doesn't mean that it's

729
01:01:09,160 --> 01:01:15,000
going to be scratched, like thrown away immediately. It means that it comes from the fast

730
01:01:15,000 --> 01:01:20,280
network file system, the Lustre file system that the cluster has. So Scratch is the place

731
01:01:20,280 --> 01:01:26,760
where that file system resides in the cluster. So whenever you go to Triton, to the login node,

732
01:01:26,760 --> 01:01:32,760
or to the on-demand, or to the compute nodes, the slash Scratch is the fast file system.

733
01:01:32,760 --> 01:01:37,560
There is also a home file system, which is mainly for storing authentication secrets and

734
01:01:37,560 --> 01:01:44,600
that sort of stuff. But it's not good for computing because it's small and it's not fast.

735
01:01:44,600 --> 01:01:47,320
And this is large, and it is fast.

736
01:01:50,440 --> 01:01:54,280
And underneath there, we have lots of project folders.

737
01:01:54,280 --> 01:01:58,360
Like if you have a research group and you want to collaborate among the research group,

738
01:01:58,360 --> 01:02:00,840
we can create you a project folder there.

739
01:02:01,480 --> 01:02:06,040
It's easy to get one, and you should get one if you want to do a collaborative project.

740
01:02:06,040 --> 01:02:10,120
Otherwise, you can put stuff into your own work directory,

741
01:02:10,120 --> 01:02:12,680
which is under /scratch/work/ and your username.

742
01:02:12,680 --> 01:02:21,080
Yeah. Yes. So, okay. Should we upload the data now? Yeah. I'll create a new directory called

743
01:02:21,080 --> 01:02:26,920
data so we can keep it clear and let's upload it into the data folder.

744
01:02:28,360 --> 01:02:32,680
Okay. And we can do it from the web here, which is nice.

745
01:02:34,360 --> 01:02:39,480
Let's see. Is this how you would normally transfer? Oh, nice.

746
01:02:42,680 --> 01:02:48,520
Yeah. Cool. So is this how you would normally transfer data to the cluster yourself?

747
01:02:50,200 --> 01:02:54,920
Well, I would probably use command line tools like rsync and stuff like that because, well,

748
01:02:54,920 --> 01:03:00,520
I'm familiar with those. But in the case of small files or individual files, it's very easy to

749
01:03:00,520 --> 01:03:05,000
transfer. But if you're transferring lots of files and you want to verify that they are transferred

750
01:03:05,000 --> 01:03:10,920
correctly, you might use other tools as well. Or you might mount the file system into your laptop

751
01:03:10,920 --> 01:03:17,280
so that you can straight up copy files from your laptop there.

752
01:03:17,280 --> 01:03:18,960
Yeah.

753
01:03:18,960 --> 01:03:20,360
OK.

754
01:03:20,360 --> 01:03:25,440
So now we've got our data on the cluster.

755
01:03:25,440 --> 01:03:27,960
So we also need some code there.

756
01:03:27,960 --> 01:03:30,160
And the code's all already made.

757
01:03:30,160 --> 01:03:33,960
And it's in a Git repository called hpc-examples.

758
01:03:33,960 --> 01:03:38,160
So this repository has a bunch of small sample programs

759
01:03:38,160 --> 01:03:39,520
useful for stuff.

760
01:03:39,520 --> 01:03:44,320
And so again, we're not going to talk about the way version control works in details.

761
01:03:44,880 --> 01:03:52,880
But since we have it there, we can run a command git clone and then copy it all onto the cluster.

762
01:03:54,480 --> 01:04:01,680
Yeah. So to get to the place where we previously were, in order to now run that command,

763
01:04:02,320 --> 01:04:09,200
I need to first connect to Triton. So I will use an SSH client. You could use from the

764
01:04:09,200 --> 01:04:14,880
on demand, you could open this in a terminal in the web browser as well, but because I'm more used

765
01:04:14,880 --> 01:04:22,400
to running stuff through the SSH, so I'm taking a remote connection to the cluster and taking an

766
01:04:22,400 --> 01:04:28,720
SSH, so now I'm, the name changes here, so now I'm in the login node of the cluster, and then I'm

767
01:04:28,720 --> 01:04:37,440
going to go to the folder where I previously put the data. Yeah, and it's really important to be

768
01:04:37,440 --> 01:04:41,840
able to match up the place you put data from the different interfaces.

769
01:04:44,640 --> 01:04:48,640
If you upload data by on-demand but don't know where it is in the command line, then

770
01:04:49,440 --> 01:04:53,360
you've got a bit of a problem. Okay, so here we can see that

771
01:04:55,040 --> 01:05:01,600
I use the command called `cd` to go to the folder, like change directory, and then I'm using command

772
01:05:01,600 --> 01:05:08,080
called `ls` to list the files. I can notice that the files are now there.

773
01:05:15,440 --> 01:05:19,520
Yes, so we verified it there and git clone.

774
01:05:31,600 --> 01:05:37,040
Okay, so now we got the code. [name], what should I do next?

775
01:05:37,040 --> 01:05:45,600
So let's see. Let's look at our thing. We've cloned it and you've listed it. Yes. So I

776
01:05:45,600 --> 01:05:58,200
guess first let's verify that the code works at all. So we are going to run Python on the

777
01:05:58,200 --> 01:06:06,880
relevant code, which is n-grams, so ./ngrams/count.py.

778
01:06:06,880 --> 01:06:08,800
And now we're at the point we have

779
01:06:08,800 --> 01:06:11,320
to know how the code even works.

780
01:06:11,320 --> 01:06:14,040
So this is the code that we wrote ourselves so you know.

781
01:06:14,040 --> 01:06:18,400
If you wrote your own code, you would know how it works.

782
01:06:18,400 --> 01:06:25,520
And for other code, well, you need to read about it and see.

783
01:06:25,520 --> 01:06:26,080
OK, so yeah.

784
01:06:26,080 --> 01:06:31,240
Usually codes like this have this kind of documentation inside of it.

785
01:06:31,240 --> 01:06:36,840
So there's a few conventions, such as dash dash help will usually provide output.

786
01:06:36,840 --> 01:06:43,960
So [name] has written a nice help output here that will describe how the code works.

787
01:06:43,960 --> 01:06:50,960
This applies to other commands in the Linux system, like for example, `ls` or `cd` as well.

788
01:06:50,960 --> 01:06:55,680
You can run the `--help` to view the manual for those ones as well.

789
01:06:55,680 --> 01:07:05,600
Yeah. But okay, so the way this works is we give Python, so the program that's running the code,

790
01:07:06,560 --> 01:07:14,240
the name of the Python file, and it should be `python3 ngrams/count.py`, and then we

791
01:07:14,240 --> 01:07:20,480
give a path to the data we're analyzing, which would be `../`, which means go up to the parent

792
01:07:20,480 --> 01:07:28,720
directory and then to the data directory and then to the zip file (`../data/Gutenberg-Fiction-first100.zip`). So this code will automatically

793
01:07:28,720 --> 01:07:34,960
decompress the zip file and find the text files inside of it without us needing to decompress it

794
01:07:34,960 --> 01:07:41,360
ourselves, which is a nice feature. And this what we're about to see is really significant here. So

795
01:07:41,360 --> 01:07:47,920
notice that we can run the same code on different data files without modifying the code. This is a

796
01:07:47,920 --> 01:07:54,240
command line interface that's been added to this code. So, when something's really small,

797
01:07:54,240 --> 01:07:59,120
maybe it's not important, but it really is convenient if you start adding these to your own

798
01:07:59,120 --> 01:08:08,400
code. It can let you be a lot more flexible. Yeah, often these are called arguments for the

799
01:08:08,400 --> 01:08:14,560
script. So, this is called, for example, the `ngrams/count.py` is an argument to the Python command,

800
01:08:14,560 --> 01:08:26,080
and then the `../data/Gutenberg-Fiction-first100.zip` thing is an argument for ngrams.py. So by giving these arguments,

801
01:08:26,800 --> 01:08:34,240
we can change what data we want to analyze and we can also give other things as well.

802
01:08:34,240 --> 01:08:41,680
So this is often called scripting and Code Refinery has a great course or Code Refinery

803
01:08:41,680 --> 01:08:50,800
will have in its course very useful teaching on how do you start scripting your own code

804
01:08:50,800 --> 01:08:57,760
into this sort of format. Because if everybody follows the format, everybody gets stuff done

805
01:08:58,800 --> 01:09:05,440
faster. So, I highly recommend joining that course that's coming in the spring to learn

806
01:09:05,440 --> 01:09:11,040
more about this. So, let's try it out, right? Yeah. Let's push enter.

807
01:09:12,560 --> 01:09:15,760
So it's telling us a little bit about what it's doing.

808
01:09:19,600 --> 01:09:26,640
So where this is running right now is on the login node. So yes, it's on the Triton cluster,

809
01:09:26,640 --> 01:09:32,480
but it's not really using the Triton resources. It's using just one place that everyone has

810
01:09:32,480 --> 01:09:38,240
access to. So this is okay because it only lasted 20 seconds and we're just verifying

811
01:09:38,240 --> 01:09:43,600
things are working, but sometimes people log in and run all their code here, and then they're

812
01:09:43,600 --> 01:09:49,600
not actually using the resources and are slowing things down for everyone. But yeah, let's see what

813
01:09:49,600 --> 01:09:56,160
does the output say. What do we get from this? So it seems that we got the n-grams that are

814
01:09:56,160 --> 01:10:04,000
size one, so basically like letter frequencies in this case. Yeah. So there's a lot of spaces

815
01:10:04,000 --> 01:10:12,480
Space is the most common character, and then E and T and A. Yeah, I mean, that looks about

816
01:10:12,480 --> 01:10:19,680
what I'd expect from English character frequencies. There's different Unicode characters in there,

817
01:10:19,680 --> 01:10:26,960
so there's some other languages. But yeah, so it worked. So we've transferred our data.

818
01:10:26,960 --> 01:10:39,040
gotten the code working, barely, and now we're ready for the next parts. Did we get all our

819
01:10:39,040 --> 01:10:49,200
explanations? We explained help, the actions. So, should we now modify what we previously

820
01:10:49,200 --> 01:10:53,600
run so that we can run it in the queue? So, what sort of modifications do we need to do

821
01:10:53,600 --> 01:11:01,920
for the command line call in order to run it in a queue?

822
01:11:02,640 --> 01:11:08,480
Yeah, so I guess whenever I run something in the queue, so in the queue basically means

823
01:11:08,480 --> 01:11:14,800
we prepare our order, our request for computing. It gets added to a queue with all the other

824
01:11:14,800 --> 01:11:20,720
requests on there and then gets run on some cluster node somewhere and then those results

825
01:11:20,720 --> 01:11:26,800
will come back to us. So when we say running in the queue, that's what we mean. So in practice,

826
01:11:26,800 --> 01:11:32,640
since we haven't been running much on the cluster lately, we will have first priority. So the queue

827
01:11:32,640 --> 01:11:38,720
sort of looks at how much people have run and the people that have run less have higher priority,

828
01:11:38,720 --> 01:11:44,240
and so on. So it won't look like a queue, but in reality, there is one under the hood here.

829
01:11:44,240 --> 01:11:53,920
and to test things out I'll usually do things interactively first. So that means we run it

830
01:11:53,920 --> 01:12:01,200
in the queue but we see the outputs right here. So for this we add the command `srun` to the start

831
01:12:01,200 --> 01:12:10,480
of our command. So `srun` means like "slurm run". So slurm is requesting resources and then we'll run it

832
01:12:10,480 --> 01:12:16,880
right away. We add this `--pty` option, which basically means make it interactive. So

833
01:12:16,880 --> 01:12:22,880
it will show the output as soon as it's created and not buffer it up. Do we need to request some

834
01:12:22,880 --> 01:12:31,440
resources here? Like how much resources? So I see there's... Yeah, so all of the jobs that we are

835
01:12:31,440 --> 01:12:41,600
requesting from the queue, they need to have some resource specifications of like how much

836
01:12:41,600 --> 01:12:47,920
does this job need so that the queue manager can fit them to a correct place in the, well,

837
01:12:47,920 --> 01:12:53,200
among the resources and among the other jobs. So the first ones we usually want to do is `--time`

838
01:12:53,200 --> 01:12:57,600
and we know that it doesn't take long time so I will just say 10 minutes over here (`--time 00:10:00`).

839
01:12:57,600 --> 01:13:01,440
Yeah, seems reasonable.

840
01:13:01,440 --> 01:13:03,320
And some memory amount.

841
01:13:03,320 --> 01:13:07,240
So we know from R, actually, we can look from here.

842
01:13:07,240 --> 01:13:11,240
So in the previous code, it says max RSS,

843
01:13:11,240 --> 01:13:15,840
which means resident set size or state size.

844
01:13:15,840 --> 01:13:19,000
Anyway, it basically is how much memory it's used.

845
01:13:19,000 --> 01:13:22,400
So it says it's using 44 megabytes,

846
01:13:22,400 --> 01:13:25,600
so we can give it 500 MD (`--mem=500M`).

847
01:13:25,600 --> 01:13:27,440
Yeah, I mean, anything less than a gigabyte

848
01:13:27,440 --> 01:13:32,080
is so small that it basically doesn't matter.

849
01:13:32,080 --> 01:13:34,600
Yeah, usually when you are requesting these,

850
01:13:34,600 --> 01:13:37,200
you want them to match what your code is running.

851
01:13:37,200 --> 01:13:41,000
And in this case, it's close to the ballpark.

852
01:13:41,000 --> 01:13:42,600
We just give it a bit of a leeway,

853
01:13:42,600 --> 01:13:47,280
like it has a bit more time headroom and then

854
01:13:47,280 --> 01:13:52,200
a bit more memory headroom for the code.

855
01:13:52,200 --> 01:13:55,560
OK, should we try to run this, or do we need more options?

856
01:13:55,560 --> 01:14:04,760
By default, the job gets one CPU, so I think this is good enough, so I don't think we need

857
01:14:04,760 --> 01:14:05,760
anything else.

858
01:14:05,760 --> 01:14:08,400
So what do we see now on the outputs here?

859
01:14:08,400 --> 01:14:14,320
Yes, there's this new thing, slurm job ID, something queued and waiting for allocated

860
01:14:14,320 --> 01:14:15,320
resources.

861
01:14:15,320 --> 01:14:21,000
So we see some sign that it's got added to the queue and is waiting for resources and

862
01:14:21,000 --> 01:14:23,080
it got those resources.

863
01:14:25,720 --> 01:14:29,560
And I guess we're waiting the same 20 seconds for it to run.

864
01:14:29,560 --> 01:14:31,240
And yeah, there we go.

865
01:14:34,280 --> 01:14:37,600
It looks pretty similar, maybe a little bit slower.

866
01:14:37,600 --> 01:14:43,280
But well, it had to start up and read the data and stuff

867
01:14:43,280 --> 01:14:43,800
like that.

868
01:14:43,800 --> 01:14:47,800
This is good enough.

869
01:14:47,800 --> 01:14:53,160
Should we create a JavaScript out of this

870
01:14:53,160 --> 01:14:57,800
and then have a small break after that?

871
01:14:57,800 --> 01:15:01,120
Yeah, sure.

872
01:15:01,120 --> 01:15:07,200
OK, so now we've run things the most basic way right now.

873
01:15:10,480 --> 01:15:11,440
This is interactive.

874
01:15:11,440 --> 01:15:15,200
But with this, we can only run a few things at a time

875
01:15:15,200 --> 01:15:18,080
because our own brain has to be sitting here

876
01:15:18,080 --> 01:15:20,720
and waiting for the output to come out.

877
01:15:20,720 --> 01:15:23,880
But instead, what we can do is we can basically

878
01:15:23,880 --> 01:15:27,580
write up our orders and then submit it to the queue,

879
01:15:27,580 --> 01:15:30,240
let it go process overnight or however long

880
01:15:30,240 --> 01:15:31,480
and come back later.

881
01:15:31,480 --> 01:15:33,560
So it's like walking to a restaurant and saying,

882
01:15:33,560 --> 01:15:36,040
I would like this takeaway order.

883
01:15:36,040 --> 01:15:38,880
And instead of sitting there and watching them cook,

884
01:15:38,880 --> 01:15:41,040
they prepare it while you go walk around

885
01:15:41,040 --> 01:15:44,080
and do some other shopping or whatever.

886
01:15:44,080 --> 01:15:46,760
And then you come back and your order is ready.

887
01:15:46,760 --> 01:15:51,320
So for that, we go to the realm of editing files.

888
01:15:51,320 --> 01:15:56,760
So `nano` is a simple command line based text editor.

889
01:15:56,760 --> 01:16:01,800
And there's an [script] file here called `run-ngrams.sh`.

890
01:16:01,800 --> 01:16:05,480
And this will be what we call our batch script that

891
01:16:05,480 --> 01:16:08,600
has the order of stuff.

892
01:16:08,600 --> 01:16:14,000
Yeah, the name `.sh` means that it's

893
01:16:14,000 --> 01:16:23,840
it's a shell script, so usually the ending means whatever what the script type is. In this case,

894
01:16:23,840 --> 01:16:29,840
it's shell script, so some instructions for the command, like basically terminal commands that

895
01:16:32,640 --> 01:16:38,400
should be executed whenever the job is running on the actual machine.

896
01:16:38,400 --> 01:16:45,520
Yeah. So the other things [name] are writing here are basically the magic words to make

897
01:16:45,520 --> 01:16:51,280
the shell script work. So we know this by heart because we've been doing this so many years,

898
01:16:51,280 --> 01:16:58,720
but in practice what you'll do is you'll find one of the examples and grab it and then copy and

899
01:16:58,720 --> 01:17:05,040
paste it. So don't worry. The first line says this is a shell script that should be run by Bash.

900
01:17:05,040 --> 01:17:14,240
the second and third lines, this `#SBATCH`. The hash is a comment character.

901
01:17:17,440 --> 01:17:24,640
And then `--time`. These are like the same options we gave to Slurm. So Slurm automatically

902
01:17:24,640 --> 01:17:29,360
finds them from these comments. Yeah, well, when we give this to the queue system,

903
01:17:29,360 --> 01:17:34,400
the queue system will look through the script and it will search for these kinds of statements. And

904
01:17:34,400 --> 01:17:40,720
then it will determine what are the resources needed for the job. And then when we submitted it,

905
01:17:41,360 --> 01:17:50,800
it will go to the queue and then once the job is in the queue, once it gets a suitable compute

906
01:17:50,800 --> 01:17:57,120
resource, it will use this executable, in this case the terminal itself, to run all of these

907
01:17:57,120 --> 01:18:03,920
commands. So it will basically type for us in that computer once it gets the resources needed.

908
01:18:04,400 --> 01:18:12,320
Over here, I've added a few extra options to the call that we previously had.

909
01:18:12,320 --> 01:18:15,880
So maybe [name], you can explain what these options mean.

910
01:18:15,880 --> 01:18:16,880
Yeah.

911
01:18:16,880 --> 01:18:23,760
So in the code, if you looked at the help text, the `-n 2`, means now we're taking 2-grams.

912
01:18:23,760 --> 01:18:29,760
So instead of simple character frequencies, we'll have all the frequencies of pairs of

913
01:18:29,760 --> 01:18:30,760
characters.

914
01:18:30,760 --> 01:18:33,280
`-o`, is output file.

915
01:18:33,280 --> 01:18:39,320
So it will be saving the output to `ngrams-2.out` (`-o ngrams-2.out`).

916
01:18:39,320 --> 01:18:42,920
And then we have the same data file as before.

917
01:18:42,920 --> 01:18:44,440
So we can save and exit.

918
01:18:44,440 --> 01:18:50,560
So in Nano, it's Control-X, and then Y and Enter or something

919
01:18:50,560 --> 01:18:53,800
like that to save.

920
01:18:53,800 --> 01:18:55,520
So can you run `ls`?

921
01:18:55,520 --> 01:18:57,200
And let's see.

922
01:18:57,200 --> 01:18:58,120
Yeah.

923
01:18:58,120 --> 01:19:02,000
Now we have a new script here.

924
01:19:02,000 --> 01:19:03,960
and new script run ngrams.

925
01:19:03,960 --> 01:19:06,360
And to submit this to the queue, we

926
01:19:06,360 --> 01:19:14,800
use the command `sbatch`, which means like "slurm batch" submission (`sbatch run-ngrams.sh`).

927
01:19:14,800 --> 01:19:18,840
And once [name] pushes this, it will be added to a queue,

928
01:19:18,840 --> 01:19:20,800
and it will probably run very fast.

929
01:19:20,800 --> 01:19:28,040
So [name] will very quickly try to run the command `slurm queue` to see it's still running.

930
01:19:28,040 --> 01:19:29,160
OK.

931
01:19:29,160 --> 01:19:31,160
Yes, so there we see.

932
01:19:31,160 --> 01:19:39,080
saw the submitted batch job stuff. So the command slurmq says there's job 5819061 running.

933
01:19:40,760 --> 01:19:52,440
Yeah, it says state equals running on node pe71. Yeah, so when we submitted it with the sbatch,

934
01:19:52,440 --> 01:19:59,560
we can see the queue status with the `slurm queue`. And because this is such a small job, it will basically

935
01:19:59,560 --> 01:20:05,880
go immediately to the queue. But with the Slurm queue, we can check how long does it take for

936
01:20:05,880 --> 01:20:14,600
our job to get running. And once it runs, what do we get? I'll type `ls` now in this folder here.

937
01:20:15,480 --> 01:20:25,000
Yeah, so it's done and we see two new files. One is `slurm-(somenumber).out` and that's the output

938
01:20:25,000 --> 01:20:32,120
from the script itself. The other one is `ngrams-2.out` and that's the output of the code.

939
01:20:32,120 --> 01:20:39,880
And let's look at it. So we can use this program called list which is a pager to view the file.

940
01:20:39,880 --> 01:20:45,720
So just to view the contents of the file. So I will first view the slurm output.

941
01:20:45,720 --> 01:20:56,280
Yeah. So, this is just the management stuff. We see it took 25 seconds. About the same amount

942
01:20:56,280 --> 01:21:07,240
of memory. Yeah. Okay. Looks good. Yeah. And I can quit. I'm still in the program,

943
01:21:08,360 --> 01:21:14,040
because it's an interactive program. I can use letter q to quit here. So, now I'm back in the

944
01:21:14,040 --> 01:21:23,080
command line. So, what Slurm did for us, even though we said to the program that,

945
01:21:23,080 --> 01:21:30,920
hey, put the output into this file, and it wrote the output to that file, Slurm also will capture

946
01:21:30,920 --> 01:21:36,760
whatever output the code would say to the terminal, basically. If we would run the code,

947
01:21:36,760 --> 01:21:41,960
and we would see some output in the terminal, Slurm will always capture that, and it will

948
01:21:41,960 --> 01:21:47,320
provide it into this output file. We can change the output file name by giving an sbatch command,

949
01:21:47,320 --> 01:21:52,360
but that's a different thing. But it will always capture that. So, you can always, like,

950
01:21:52,360 --> 01:21:57,160
see what is the output. So, it's, like, compared to the interactive running, it's not that

951
01:21:57,800 --> 01:22:03,400
different. We just, like, we tell it what to run, and we can always see the output.

952
01:22:03,400 --> 01:22:06,600
So, and let's look at the ngrams output now.

953
01:22:09,320 --> 01:22:18,120
Okay, this looks more interesting. ["e", space], ["t", space] ["t", "h"], ["h", "e"]. So,

954
01:22:18,120 --> 01:22:22,440
"the" is definitely the most common word there. Who would have thought?

955
01:22:23,480 --> 01:22:29,800
And then empty space and an "a" article is quite or "n" article is quite common as well.

956
01:22:29,800 --> 01:22:39,800
Yeah. Okay. So, yeah, there we ran our batch script. Anything else before we go to the

957
01:22:39,800 --> 01:22:42,520
break? Should we look at the timings?

958
01:22:42,520 --> 01:22:43,520
Yes.

959
01:22:43,520 --> 01:22:44,520
And the history?

960
01:22:44,520 --> 01:22:51,800
So, when we have run something in the queue, we can run slurm history. So, the slurm is

961
01:22:51,800 --> 01:22:59,680
this command that has various features that you can use. It's like an easier way of accessing

962
01:22:59,680 --> 01:23:08,640
the Slurm output and we can see like let's say Slurm history from one hour. I have run

963
01:23:08,640 --> 01:23:17,840
some other jobs previously so they might be here as well. We can see actually we don't

964
01:23:17,840 --> 01:23:22,760
see any other jobs. So we see here that's just the two. Yeah so here's the interactive

965
01:23:22,760 --> 01:23:29,240
one, and here's the non-interactive one, the batch job run script.

966
01:23:31,240 --> 01:23:38,600
Yeah, and we see the requested memory, the amount of memory it thinks it used, CPU time. Can we see

967
01:23:38,600 --> 01:23:45,480
the efficiency of the job? So, how much processor and memory it actually used? So, if we copy this

968
01:23:45,480 --> 01:23:54,800
Each job gets a job ID that specifies, well, it's a unique identifier that you can then

969
01:23:54,800 --> 01:23:57,120
look stuff up with.

970
01:23:57,120 --> 01:24:02,680
And we can use this command called `seff` to check the efficiency of a job.

971
01:24:02,680 --> 01:24:09,080
So if we run `seff` and then the job ID, we will see what was the efficiency.

972
01:24:09,080 --> 01:24:14,920
And we can notice here, for example, that the CPU efficiency was very good, 100%.

973
01:24:14,920 --> 01:24:20,920
memory efficiency not so much. But this was such a small job that it probably didn't even capture

974
01:24:20,920 --> 01:24:28,520
that because these are sampled values that are sampled every so often. And the job is so fast

975
01:24:28,520 --> 01:24:38,120
that it probably didn't even capture them correctly. Okay, great. So should we quickly

976
01:24:38,120 --> 01:24:47,320
look at the notes and then go to a break. I'm switching to the notes on my screen.

977
01:24:48,280 --> 01:24:55,320
So there's some good questions here. Most of them have been answered or we can talk later.

978
01:24:58,280 --> 01:25:07,080
Someone asked about the priority. So how is the priority calculated? Is this something we should

979
01:25:07,080 --> 01:25:14,360
answer now? Because it's actually pretty complicated, but maybe [name] has a quick explanation.

980
01:25:15,320 --> 01:25:22,200
So the priority is basically calculated based on your past history and the sizes of your jobs that

981
01:25:22,200 --> 01:25:29,160
you previously submitted. And the size of the job is calculated based on the number of CPUs you have

982
01:25:29,160 --> 01:25:34,920
requested or the number of memory you have requested or the GPU resources you have requested.

983
01:25:34,920 --> 01:25:43,880
so everything has basically like a price. And the size of the job, so memory request,

984
01:25:43,880 --> 01:25:49,800
CPU request, GPU request, times the time gives like, I'm going to say it's like a block,

985
01:25:51,080 --> 01:26:01,800
volume of the job basically in the cluster. So that is used to calculate your usage.

986
01:26:01,800 --> 01:26:08,440
and your priority is basically like it has a half-life of like for every job it just has a

987
01:26:08,440 --> 01:26:14,680
half-life of two weeks where like the priority goes down so basically it means it's just like

988
01:26:14,680 --> 01:26:19,800
tries to make it so that everybody has a fair share of the resources so if somebody runs

989
01:26:20,760 --> 01:26:25,960
a lot of big jobs they get less of them in the future so that other people have the chance to

990
01:26:25,960 --> 01:26:32,120
do it. So the best thing usually is to just run what you want to do and keep the resource

991
01:26:32,120 --> 01:26:41,080
requests close to what your jobs need. And there was a question of how do you choose these ones.

992
01:26:41,080 --> 01:26:49,160
So usually the good answer is to measure what your job needs and check with, for example, `seff`

993
01:26:49,160 --> 01:26:56,040
what the job needs. There's a full documentation in the SciComp documentation on how do you measure

994
01:26:56,040 --> 01:27:07,080
these. But usually you want to measure what your job actually uses so that you can choose the

995
01:27:07,080 --> 01:27:13,800
appropriate resources. So you run an example job and then you check how much it used and then you

996
01:27:13,800 --> 01:27:21,560
lower the resources closer to the actual resource needs, giving it some leeway so that if there's a

997
01:27:21,560 --> 01:27:30,840
memory spike or something like that, it doesn't go over the memory limit or if you give it a

998
01:27:30,840 --> 01:27:34,440
bit more leeway in the time department so that you know that it finishes in time.

999
01:27:34,440 --> 01:27:45,720
Yeah. The other question that I might answer now, how do you estimate the memory and time

1000
01:27:45,720 --> 01:27:52,280
needed for a task? And this is a really good one. And basically, I guess I'd say experience

1001
01:27:53,000 --> 01:28:01,160
and knowing the problem. I mean, there's no one magic answer here other than just run it and see

1002
01:28:01,160 --> 01:28:07,000
what it actually uses. So for example, if it runs on my own computer, I know it won't need more

1003
01:28:07,000 --> 01:28:17,240
memory than exists on my computer. And start with a few CPUs. So usually I'll start and I'll request

1004
01:28:17,240 --> 01:28:22,520
more memory than it needs and see how much it uses and then decrease to the amount that's used.

1005
01:28:23,080 --> 01:28:28,120
If you don't request enough, you'll get an out of memory error and then you know you need more.

1006
01:28:28,120 --> 01:28:38,120
And for CPUs, we'll talk about how to scale up the number of CPUs you use to see what the proper amount there.

1007
01:28:38,120 --> 01:28:47,120
I highly recommend looking at the guide posted also to the notes on what sort of measuring sticks you can use to measure the program size.

1008
01:28:47,120 --> 01:28:55,080
Also, there was a question of is time requested or time used, the one that is calculated using

1009
01:28:55,080 --> 01:28:56,080
the priority.

1010
01:28:56,080 --> 01:29:03,720
And it's kind of both, because when the job is in the queue, your estimate of how much

1011
01:29:03,720 --> 01:29:11,120
time it will use is used to calculate how big the job is.

1012
01:29:11,120 --> 01:29:16,480
If you say that I want the whole cluster for one month, the job is huge and you won't

1013
01:29:16,480 --> 01:29:21,360
get it ever, because it's such a big job, like it's impossible to get that much resources

1014
01:29:21,360 --> 01:29:22,560
at one time.

1015
01:29:22,560 --> 01:29:31,160
And if you like, so then the like the perceived time usage is like, or the requested time

1016
01:29:31,160 --> 01:29:33,880
usage is used to calculate the priority.

1017
01:29:33,880 --> 01:29:42,780
But once the job has finished, the time usage that it actually took is the one that is used

1018
01:29:42,780 --> 01:29:45,520
to calculate your like past priority.

1019
01:29:45,520 --> 01:29:54,180
But in any case, it's best to just try to match the request as close to the actual early

1020
01:29:54,180 --> 01:30:00,280
users as possible and to do some simple measurements to get to the right ballpark.

1021
01:30:00,280 --> 01:30:06,840
So if you know that the job finishes on your laptop in 15 minutes or maybe an hour, you

1022
01:30:06,840 --> 01:30:11,440
don't need to request a full day's time in the cluster,

1023
01:30:11,440 --> 01:30:16,480
because it's way overboard, because it

1024
01:30:16,480 --> 01:30:17,760
takes an hour on your laptop.

1025
01:30:17,760 --> 01:30:22,600
So might as well put an hour in the cluster as well.

1026
01:30:22,600 --> 01:30:24,240
But maybe we should go to a break.

1027
01:30:24,240 --> 01:30:25,080
Yeah.

1028
01:30:25,080 --> 01:30:28,840
So I guess we come back at 16 minutes past the hour

1029
01:30:28,840 --> 01:30:31,920
in whatever time zone you're in, unless you're

1030
01:30:31,920 --> 01:30:36,320
in a weird country, which is fine.

1031
01:30:38,480 --> 01:30:41,160
Yeah, you can keep answering or asking questions.

1032
01:30:41,160 --> 01:30:43,320
We'll keep answering and when we come back,

1033
01:30:43,320 --> 01:30:44,380
it's parallel stuff.

1034
01:30:44,380 --> 01:30:46,600
So see you later.

1035
01:30:47,960 --> 01:30:48,800
Bye.

1036
01:31:01,920 --> 01:31:03,980
you

1037
01:31:31,920 --> 01:31:33,980
you

1038
01:32:01,920 --> 01:32:03,980
you

1039
01:32:31,920 --> 01:32:33,980
you

1040
01:33:01,920 --> 01:33:03,980
you

1041
01:33:31,920 --> 01:33:33,980
you

1042
01:34:01,920 --> 01:34:03,980
you

1043
01:34:31,920 --> 01:34:33,980
you

1044
01:35:01,920 --> 01:35:03,980
you

1045
01:35:31,920 --> 01:35:33,980
you

1046
01:36:01,920 --> 01:36:03,980
you

1047
01:36:31,920 --> 01:36:33,980
you

1048
01:37:01,920 --> 01:37:03,980
you

1049
01:37:31,920 --> 01:37:33,980
you

1050
01:38:01,920 --> 01:38:03,980
you

1051
01:38:31,920 --> 01:38:33,980
you

1052
01:39:01,920 --> 01:39:03,980
you

1053
01:39:31,920 --> 01:39:33,980
you

1054
01:40:01,920 --> 01:40:03,980
you

1055
01:40:31,920 --> 01:41:00,920
Hello.

1056
01:41:00,920 --> 01:41:12,280
So looking through the notes, I don't see any new questions

1057
01:41:12,280 --> 01:41:13,120
we haven't answered.

1058
01:41:13,120 --> 01:41:18,080
So I guess let's continue with our task.

1059
01:41:18,080 --> 01:41:24,240
But maybe first, we're going to do parallel now.

1060
01:41:24,240 --> 01:41:29,520
So what does that mean, parallel?

1061
01:41:29,520 --> 01:41:33,040
and how are we approaching this?

1062
01:41:33,040 --> 01:41:37,920
Yeah, so this is, I would say, it's way too complex

1063
01:41:37,920 --> 01:41:44,080
a thing to have everything said in this small session,

1064
01:41:44,080 --> 01:41:48,560
but it basically means using more than one processor.

1065
01:41:48,560 --> 01:41:51,920
And there are multiple ways we can do this and

1066
01:41:51,920 --> 01:41:55,520
the most important one, I would say, that we are going to be focusing on this

1067
01:41:55,520 --> 01:41:58,000
session is this kind of embarrassingly parallel

1068
01:41:58,000 --> 01:42:05,760
where we just run the same thing with different inputs multiple times. Basically, we would

1069
01:42:05,760 --> 01:42:12,320
start the same program multiple times, and that is the easiest way. But there's other

1070
01:42:12,320 --> 01:42:17,200
paradigms as well. There's multiprocessing, there's a message-passing interface parallelism,

1071
01:42:17,840 --> 01:42:23,120
MPI parallelism. But it basically means that we use more than one processor. So you know that

1072
01:42:23,120 --> 01:42:28,400
Your laptop probably has eight to maybe four to eight CPUs already.

1073
01:42:29,440 --> 01:42:35,200
Yeah. You know, while I was making the kitchen videos, I had to very carefully research what

1074
01:42:35,200 --> 01:42:42,320
is parallelism. And I think the answer I got is that there's more than one point of execution at

1075
01:42:42,320 --> 01:42:48,720
the same time. So we have multiple processors. One processor is executing our analysis on

1076
01:42:48,720 --> 01:42:54,800
one book and another processor is on a different book. And this is what I guess we'd call data

1077
01:42:54,800 --> 01:43:03,920
parallelism. And in particular, we will use first array jobs, which is embarrassingly parallel.

1078
01:43:03,920 --> 01:43:07,680
So basically, instead of running one program that does multiple things,

1079
01:43:08,320 --> 01:43:16,480
we run 10 copies of the same program. And then these 10 different copies will all process 10

1080
01:43:16,480 --> 01:43:22,160
different books within the 100 books we have. And they'll all write out separate files,

1081
01:43:22,160 --> 01:43:27,280
which we can then combine later and hopefully see the same output.

1082
01:43:29,600 --> 01:43:35,760
Yes. So these kind of problems arise all the time. So if you have different data sets you

1083
01:43:35,760 --> 01:43:40,800
want to process, if you have different parameters you want to process, you want to do different

1084
01:43:40,800 --> 01:43:46,860
different options, different random number seeds or whatever, there's multiple different

1085
01:43:46,860 --> 01:43:52,260
ways that you encounter the situation where you do the same thing, but with a small difference.

1086
01:43:52,260 --> 01:43:59,580
And in these cases, the embarrassingly parallelization is your friend. And even though it's called

1087
01:43:59,580 --> 01:44:05,800
embarrassingly parallel, it just means that it's easy to parallelize. And in this case,

1088
01:44:05,800 --> 01:44:12,360
[name] said, the book analysis is very easy to parallelize. So, maybe we should look into it.

1089
01:44:13,480 --> 01:44:20,200
Yeah. So, I'm switching to your screen. There we are. So, we're back where we were.

1090
01:44:20,920 --> 01:44:27,960
So, we already have a working batch script, the run ngrams. So, I guess we can make a copy of

1091
01:44:27,960 --> 01:44:37,640
this with the `cp` command and call it `run-ngrams-array.sh`. Oops first argument first so first

1092
01:44:37,640 --> 01:44:45,240
what are we copying and then the other one yeah my mistake yeah no okay and now we can open the

1093
01:44:45,240 --> 01:44:57,400
new file the array running file so we need to tell this program that it should run as an array so we

1094
01:44:57,400 --> 01:45:05,240
add a new slurm option here. So the sbatch comment, and now we give `--array=0-9`.

1095
01:45:06,440 --> 01:45:14,520
And that means the same file will run 10 times, and each time there'll be one different variable

1096
01:45:14,520 --> 01:45:20,440
inside. And that variable would be set to 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. And how do we use that

1097
01:45:20,440 --> 01:45:29,720
variable. So, the program `count.py` has built in support for this. So, there's this extra argument

1098
01:45:29,720 --> 01:45:37,880
we can add in `--step=10`. So, step means it will run every 10th book. And `--start` will

1099
01:45:37,880 --> 01:45:45,960
be tell it what book to start on. And here we use the magic word $SLURM_ARRAY_TASK_ID [so `--start=$SLURM_ARRAY_TASK_ID`]. And this is

1100
01:45:45,960 --> 01:45:50,760
something you would just look up from the array examples. There's no way you would know this

1101
01:45:53,080 --> 01:45:59,080
by yourself automatically. So yeah, so now 10 times,

1102
01:46:01,560 --> 01:46:11,400
they run on 10 different books. So the first one runs book 0, 10, 20. The next one, book 1, 11,

1103
01:46:11,400 --> 01:46:17,480
21 and so on. Do we need to have them save the output to different file names?

1104
01:46:18,520 --> 01:46:23,480
Yes, so I added here to the output also the task ID because otherwise they would

1105
01:46:23,480 --> 01:46:29,400
like they would all try to write it. Can you make it newer? Yeah, yeah, let's scroll.

1106
01:46:30,760 --> 01:46:39,080
Yes, okay, so unfortunately this wraps this code [lines are scrolling off the screen] but yeah on the output (`-o`) one I added

1107
01:46:39,080 --> 01:46:46,680
this $SLURM_ARRAY_TASK_ID there as well. Because otherwise all of them would write to

1108
01:46:46,680 --> 01:46:52,760
the same file. So when we are submitting this job with the array structure, we are telling the queue

1109
01:46:53,320 --> 01:46:58,920
that, hey, I want actually 10 of these. I want 10 of these and just give me a different number

1110
01:46:58,920 --> 01:47:04,760
for each one of them. And based on what number we're getting, we do something. And there's

1111
01:47:04,760 --> 01:47:09,720
various things you can do to map this number to parameters or whatever. There's multiple examples

1112
01:47:10,440 --> 01:47:17,160
in the documentation, but this is like a simple example where we can straight up use the number

1113
01:47:17,960 --> 01:47:26,920
over here. So, should we try that? Yeah, okay. So, now we submit it with sbatch again.

1114
01:47:26,920 --> 01:47:36,680
And I'll try to be, again, fast to get the queue status.

1115
01:47:36,680 --> 01:47:38,720
Yeah, so queue.

1116
01:47:38,720 --> 01:47:42,240
OK, so we see here now there's 10 different things running.

1117
01:47:42,240 --> 01:47:44,200
0, 1, 2, 3, 9.

1118
01:47:44,200 --> 01:47:48,400
We see there's the underscore ("_") and number,

1119
01:47:48,400 --> 01:47:50,960
which is the different array tasks.

1120
01:47:50,960 --> 01:47:52,920
They're all running.

1121
01:47:52,920 --> 01:47:56,560
On the last column, we see under node list,

1122
01:47:56,560 --> 01:48:00,320
many of them are running on a node named pe32,

1123
01:48:00,320 --> 01:48:03,880
but there's a few that are running on other ones.

1124
01:48:03,880 --> 01:48:11,360
Basically, we've managed to run on different nodes here.

1125
01:48:11,360 --> 01:48:13,640
It's important to note here that all of

1126
01:48:13,640 --> 01:48:16,040
these jobs are completely independent of each other,

1127
01:48:16,040 --> 01:48:17,280
so they don't understand.

1128
01:48:17,280 --> 01:48:19,480
If you have a program that needs to

1129
01:48:19,480 --> 01:48:22,600
somehow communicate among the different things,

1130
01:48:22,600 --> 01:48:25,640
this is not an average job.

1131
01:48:25,640 --> 01:48:31,640
you need other algorithms to run that sort of program.

1132
01:48:31,640 --> 01:48:37,240
Of course, you can then run that with an ArrayJob if you want to run multiple of those kinds of

1133
01:48:37,240 --> 01:48:42,440
programs. But here, all of the programs that are running, all of the scripts that are running,

1134
01:48:42,440 --> 01:48:47,960
are completely independent of each other. So they do independent stuff independently and then they

1135
01:48:50,120 --> 01:48:54,760
give the output at the end. Should we look at the outputs?

1136
01:48:55,640 --> 01:48:56,140
Yeah.

1137
01:49:03,760 --> 01:49:09,520
So now we see there's output ngrams to array 0, 1, 2.

1138
01:49:09,520 --> 01:49:11,760
Do you want to look at one of these and see?

1139
01:49:11,760 --> 01:49:12,360
Yes.

1140
01:49:12,360 --> 01:49:14,160
Let's take, for example, these.

1141
01:49:18,200 --> 01:49:20,640
Yeah, I mean, it looks like the normal thing,

1142
01:49:20,640 --> 01:49:25,040
but about 1/10th as much data there.

1143
01:49:25,040 --> 01:49:28,080
And if we look at any of the outputs here,

1144
01:49:28,080 --> 01:49:31,040
we can notice that, well, it looks similar as well.

1145
01:49:31,040 --> 01:49:33,160
But again, the number of n-grams

1146
01:49:33,160 --> 01:49:39,360
is 1/10th of the overall amount.

1147
01:49:47,520 --> 01:49:48,880
Yeah.

1148
01:49:48,880 --> 01:49:50,240
OK.

1149
01:49:50,240 --> 01:49:54,320
So there's also a script included in the HPC examples

1150
01:49:54,320 --> 01:50:00,640
will combine all the output, because presumably we don't want 10 separate output files, but we want

1151
01:50:00,640 --> 01:50:10,240
one. So it's, I think, called `combine-counts.py`? Yeah. So it takes a series of input arguments,

1152
01:50:10,240 --> 01:50:21,680
which is the inputs. So we can use this glob syntax. So the asterisk ("*") means fill anything that

1153
01:50:24,320 --> 01:50:32,160
matches this pattern. And we can use the `-o`-argument to write it out to another place.

1154
01:50:41,760 --> 01:50:49,520
So this is often called like a map-reduce kind of a thing, where you do something over multiple

1155
01:50:49,520 --> 01:50:54,160
things. You do this mapping and then you reduce the information together. So this is quite common

1156
01:50:54,160 --> 01:50:59,760
in like data heavy stuff. You want to do stuff independently and then combine the outputs

1157
01:50:59,760 --> 01:51:06,480
together. Yeah, so now we see the new output file. Do you think it's the same as the original one?

1158
01:51:07,600 --> 01:51:14,960
So it should be sorted by amount. Should we look at the first 10 lines and see if they're the same?

1159
01:51:15,600 --> 01:51:20,800
Yeah, let's do that. So let's look at the original one first.

1160
01:51:20,800 --> 01:51:25,960
Yeah, what does the program `head` do?

1161
01:51:25,960 --> 01:51:32,560
So it prints out the first lines of a file.

1162
01:51:32,560 --> 01:51:34,680
By default, it prints 10 lines.

1163
01:51:34,680 --> 01:51:38,440
I don't remember, but we can give it a number, what we want.

1164
01:51:38,440 --> 01:51:42,160
But you can look at the start of the file, like if you want to check what the data looks

1165
01:51:42,160 --> 01:51:45,120
like or something.

1166
01:51:45,120 --> 01:51:56,120
Yeah, so if you look at the first 10 lines there, and combined.

1167
01:51:56,120 --> 01:51:59,420
So the moment of truth, is it exactly the same?

1168
01:51:59,420 --> 01:52:04,120
And those counts look pretty much the same to me.

1169
01:52:04,120 --> 01:52:08,880
Yeah, so it worked.

1170
01:52:08,880 --> 01:52:14,720
Yeah, so we didn't have to do any modifications to the code itself, like it was the same exact

1171
01:52:14,720 --> 01:52:20,720
code that we run. Of course, the combination, there had to be some sort of way of combining

1172
01:52:20,720 --> 01:52:26,960
the results after the fact. But there wasn't any major modifications to the code itself.

1173
01:52:26,960 --> 01:52:33,040
We could run it separately. Of course, you need to have some way of mapping the

1174
01:52:34,400 --> 01:52:41,040
$SLURM_ARRAY_TASK_ID to the task what you want the code to do. But once you have figured that out,

1175
01:52:41,040 --> 01:52:49,120
it's usually plain smooth sailing to get an easy way of getting lots of parallelism in the cluster.

1176
01:52:49,120 --> 01:52:56,080
And this is very good for jobs that you need to do something a lot of times.

1177
01:52:58,320 --> 01:53:03,520
Yeah. And this is your own brain power that you'll need to spend to figure out how to

1178
01:53:03,520 --> 01:53:09,520
distribute things and split it up like this. And this is what it means to be a scientific

1179
01:53:09,520 --> 01:53:18,480
computing person. But okay, there's other options. So there's also a mode of this which tries to use

1180
01:53:18,480 --> 01:53:25,440
multiple processors within the same program, something called multiprocessing, which is a

1181
01:53:25,440 --> 01:53:33,280
Python module. And would you like to give that a quick try? Yeah, let's try it out. So if we

1182
01:53:33,280 --> 01:53:44,840
So, if we first try running the previous single core version, let's try out that and let's

1183
01:53:44,840 --> 01:53:46,240
just verify what we have.

1184
01:53:46,240 --> 01:53:54,760
So, I copied from the history, so here I'm running the code.

1185
01:53:54,760 --> 01:54:04,040
only change here is that this time we are checking for words, like instead of letters,

1186
01:54:04,040 --> 01:54:12,360
we're checking for words for the n-grams. So it takes a bit more for the job to run.

1187
01:54:15,800 --> 01:54:22,760
And we see it used more memory, 500 megabytes now, about the same amount of time.

1188
01:54:22,760 --> 01:54:34,760
Okay, so we've done it with one processor with a code that isn't written to use multiprocessing.

1189
01:54:34,760 --> 01:54:41,760
But if we are starting to use multiprocessing, the first thing you must check is that does your code support it?

1190
01:54:41,760 --> 01:54:45,760
Is your code written so that it understands multiprocessing?

1191
01:54:45,760 --> 01:54:52,760
In this case, this program isn't, but [name] has written a version that does support multiprocessing,

1192
01:54:52,760 --> 01:54:53,760
right?

1193
01:54:53,760 --> 01:54:56,760
And this is called `count-multi.py`.

1194
01:54:56,760 --> 01:54:59,240
Yeah.

1195
01:54:59,240 --> 01:55:10,040
So now it basically works the same, except we will tell it it should use more processors.

1196
01:55:10,040 --> 01:55:13,320
So first we have to request the extra processor from Slurm.

1197
01:55:13,320 --> 01:55:14,320
Yeah.

1198
01:55:14,320 --> 01:55:24,720
So within the srun areas of the arguments, will request CPUs per task equals how many?

1199
01:55:24,720 --> 01:55:30,560
Four. Let's put a bit more memory because there's going to be overhead because all of

1200
01:55:30,560 --> 01:55:41,440
the processors are going to be needing memory. But we have now a requested. So in the slurm,

1201
01:55:41,440 --> 01:55:47,200
So if you look at this block of text before the Python command, so where we have the S run and

1202
01:55:47,200 --> 01:55:54,640
we tell the Slurm requests, we have now used CPUs per task equals four to request more CPUs.

1203
01:55:54,640 --> 01:56:00,400
You don't have to worry about the task. It's a different thing for MPI stuff. But CPUs per task

1204
01:56:00,400 --> 01:56:09,600
basically asks for four CPUs. But the code yet doesn't... Software updates. Nice. The code yet

1205
01:56:09,600 --> 01:56:15,760
doesn't know how to use those processes unless we tell it that, okay, you should use four

1206
01:56:15,760 --> 01:56:21,680
processors. So different programs have different ways, and it depends on the program. But usually,

1207
01:56:21,680 --> 01:56:27,920
if you have multi-process, like code that can utilize multiple processors, there's a way of

1208
01:56:27,920 --> 01:56:33,280
telling it how many processors it should use. And in this case, I think it's threads.

1209
01:56:33,280 --> 01:56:39,160
It's not right, [name].

1210
01:56:39,160 --> 01:56:40,400
Yeah, OK.

1211
01:56:40,400 --> 01:56:43,240
So I think now this has everything it needs.

1212
01:56:43,240 --> 01:56:46,640
So we're saving to the same output file.

1213
01:56:46,640 --> 01:56:47,320
That's fine.

1214
01:56:47,320 --> 01:56:50,320
Should we try running it and see what happens?

1215
01:56:50,320 --> 01:56:56,640
Yeah, let's put threads or let's put to a different file.

1216
01:56:56,640 --> 01:56:59,120
Let's see if the head is like the output.

1217
01:56:59,120 --> 01:57:00,440
OK.

1218
01:57:00,440 --> 01:57:01,760
So it's running.

1219
01:57:01,760 --> 01:57:05,560
It says it's using four processes.

1220
01:57:05,560 --> 01:57:10,440
And so while we're waiting here, do you

1221
01:57:10,440 --> 01:57:13,600
think this will be faster or slower?

1222
01:57:13,600 --> 01:57:16,280
Well, it's probably going to be a bit faster,

1223
01:57:16,280 --> 01:57:25,680
but not that much because the program probably cannot.

1224
01:57:25,680 --> 01:57:27,880
Yeah, there's multiple things that can happen there.

1225
01:57:27,880 --> 01:57:32,760
But this kind of example test case

1226
01:57:32,760 --> 01:57:35,960
probably won't parallelize that well

1227
01:57:35,960 --> 01:57:39,560
because there's lots of overhead and that sort of stuff.

1228
01:57:39,560 --> 01:57:41,960
So this is really interesting.

1229
01:57:41,960 --> 01:57:43,760
So it ran.

1230
01:57:43,760 --> 01:57:46,360
So let's look at these numbers carefully.

1231
01:57:46,360 --> 01:57:48,040
So first, there's the wall time.

1232
01:57:48,040 --> 01:57:51,480
So wall time means the clock on the wall, so the real time

1233
01:57:51,480 --> 01:57:52,520
that's passed.

1234
01:57:52,520 --> 01:57:56,200
So we've requested four times as many resources.

1235
01:57:56,200 --> 01:58:02,020
And it's run, what, 20%, 25% faster, something like that.

1236
01:58:02,020 --> 01:58:07,300
So basically, most of our extra resources

1237
01:58:07,300 --> 01:58:08,900
appear to have been wasted.

1238
01:58:08,900 --> 01:58:13,020
Ideally, it would run in 1/4th of the time.

1239
01:58:13,020 --> 01:58:16,900
But really, it ran in 3/4ths of the time,

1240
01:58:16,900 --> 01:58:20,420
or 4/5th of the time, something like that.

1241
01:58:20,420 --> 01:58:24,500
So this code really didn't work well with multiprocessing.

1242
01:58:24,500 --> 01:58:26,500
Let's look at user time.

1243
01:58:26,500 --> 01:58:29,380
So user time, and this is the amount of time

1244
01:58:29,380 --> 01:58:33,260
that the processors actually spent doing work.

1245
01:58:33,260 --> 01:58:37,260
It went up from 21 seconds to 29 seconds.

1246
01:58:37,260 --> 01:58:38,460
So this is OK.

1247
01:58:38,460 --> 01:58:41,140
You'd expect it to run a little bit slower.

1248
01:58:41,140 --> 01:58:43,220
It has to spend more time communicating

1249
01:58:43,220 --> 01:58:46,100
between the different parts.

1250
01:58:46,100 --> 01:58:50,940
But yeah, combining this with the wall time

1251
01:58:50,940 --> 01:58:52,260
not really going down.

1252
01:58:52,260 --> 01:59:00,420
it shows that our parallelization really hasn't worked. And that goes to a question which is in

1253
01:59:00,420 --> 01:59:05,540
the notes. Should we do the changes? Should someone do the changes to make their code

1254
01:59:05,540 --> 01:59:13,220
support multiprocessing? So it really depends what the code is. Is it going to be efficient?

1255
01:59:14,580 --> 01:59:22,020
[name]'s running `seff` here. Yeah, let's run quickly like `seff` and the job IDs of the jobs. So it'd be

1256
01:59:22,020 --> 01:59:27,700
take the job ideas from the output over here and look at them, you can see that the first one had

1257
01:59:27,700 --> 01:59:35,220
a CPU efficiency of 90% and the second one had a CPU efficiency of 40%. And like [name] said,

1258
01:59:39,860 --> 01:59:44,660
it depends on the case that you're running. If you're running a physics code or something,

1259
01:59:44,660 --> 01:59:51,220
the parallelism might be needed. Otherwise, you might not get the results in a reasonable time.

1260
01:59:51,220 --> 01:59:58,020
if you're running a data-hungry process that tries to run, for example, in here we are trying to go

1261
01:59:58,020 --> 02:00:03,860
through multiple files, there might be a lot of overhead with the file reading and writing

1262
02:00:03,860 --> 02:00:10,340
and that sort of stuff that doesn't really help. And in actuality, running the array job would be

1263
02:00:10,340 --> 02:00:18,260
faster. So sometimes running serial but more of them is faster than running something parallel

1264
02:00:18,260 --> 02:00:24,860
because there's these overheads that are needed to make certain that the communications work and that sort of stuff.

1265
02:00:24,860 --> 02:00:32,260
So, multiprocessing really depends on the case, and if it's low-level codes, it's usually better.

1266
02:00:32,260 --> 02:00:40,260
If it's this kind of run through something like data, it doesn't necessarily help.

1267
02:00:40,260 --> 02:00:49,460
but it's usually best to test. It's usually best to test and see how it works. But usually,

1268
02:00:50,580 --> 02:00:57,620
if you have an existing code trying to get the results done, there's a question of,

1269
02:00:57,620 --> 02:01:04,580
do you want the results done or do you want them to be done faster? If you want them to be done

1270
02:01:04,580 --> 02:01:11,460
faster, you might benefit from multi-processing because the wall time goes down, the time it

1271
02:01:11,460 --> 02:01:16,340
takes to run them. But if you want the results done, let's say you need to run a thousand

1272
02:01:16,340 --> 02:01:22,900
simulations or something, it doesn't necessarily make sense to parallelize them because there's

1273
02:01:22,900 --> 02:01:28,900
thousands of them and the overhead starts to accumulate. Instead, it might be just better to

1274
02:01:28,900 --> 02:01:35,860
run a thousand individual simulations and not parallelize them at all. Because that way,

1275
02:01:36,660 --> 02:01:44,020
you reduce the overhead time and you just get them done. So, aggregate jobs are quite often

1276
02:01:44,020 --> 02:01:52,340
the fastest way of getting bulk stuff done. But if you want something like you are waiting there

1277
02:01:52,340 --> 02:01:57,060
in the queue, waiting for it, waiting for the results to come by, then the multiprocessing

1278
02:01:57,060 --> 02:02:03,540
might make it faster to do that specific simulation. But it's like a question of

1279
02:02:03,540 --> 02:02:09,060
do you really want to go through the hassle. If your code already supports it, it might be good

1280
02:02:09,060 --> 02:02:14,100
to check if the code has support for multiprocessing and then test it out whether the

1281
02:02:14,100 --> 02:02:23,620
multiprocessing version is faster. As an example, when I was making these codes, I maybe spent

1282
02:02:23,620 --> 02:02:30,980
15 or 30 minutes getting a first version of the single core code working. It was pretty fast.

1283
02:02:30,980 --> 02:02:36,420
And then I spent many hours working on the multiprocessing version. I could make something

1284
02:02:36,420 --> 02:02:41,220
that initially worked quickly, but then understanding why it was slow and trying to

1285
02:02:41,220 --> 02:02:49,780
make it slightly better took a long time. So this might also be what you'll experience for

1286
02:02:49,780 --> 02:02:55,060
your own stuff. But should we talk about some of the speed considerations and why it's so slow?

1287
02:02:55,060 --> 02:03:01,300
There's a good question about why is the multi-processing slower? Or is there something

1288
02:03:01,300 --> 02:03:09,220
else to talk about first? Yeah, I would say that in this case there's a few considerations.

1289
02:03:09,220 --> 02:03:14,580
First off, it needs to load the data for all of those different multiple processes. So it needs

1290
02:03:14,580 --> 02:03:21,380
to open the file four times. Each one of them needs to load the file in order to get the data

1291
02:03:21,380 --> 02:03:31,060
in. So there's data slowing down. And I can say from my experience in making this,

1292
02:03:31,940 --> 02:03:37,620
the program is a little bit faster when it reads the data directly from the zip file

1293
02:03:37,620 --> 02:03:43,540
compared to uncompressing the zip file and running it on all the files separately,

1294
02:03:43,540 --> 02:03:49,940
open them independently. It really depends on the format the data is stored in and all that.

1295
02:03:49,940 --> 02:03:55,300
I could have repackaged it into a format that optimized for reading, and it would be even faster.

1296
02:03:55,940 --> 02:04:01,700
But this is a real thing that you can experience with this example if you want to give it a try.

1297
02:04:03,860 --> 02:04:08,500
And also, if you think about the word counts, it's calculating the word counts. It has to,

1298
02:04:08,500 --> 02:04:16,980
like each process that is analyzing a different file, it needs to store those words into memory,

1299
02:04:16,980 --> 02:04:22,180
into the counts, like how many counts has this word appeared or this ngram has appeared.

1300
02:04:23,140 --> 02:04:32,500
So each one of them has to house its own copy of this kind of word dictionary. And that, of course,

1301
02:04:32,500 --> 02:04:40,820
means that there's four times the memory usage. We see also the memory usage grow because of the

1302
02:04:42,180 --> 02:04:47,860
extra CPUs. So there's these overheads that happen when the individual processes have to

1303
02:04:48,420 --> 02:04:55,140
do the same stuff that the one process would do as well. And then that makes it slower.

1304
02:04:56,580 --> 02:05:01,700
And these kinds of considerations happen. In some problems, there might be a situation where

1305
02:05:01,700 --> 02:05:07,140
like you get benefit, but you only get benefit once you get over the overhead, like basically

1306
02:05:07,140 --> 02:05:13,100
like let's say we would have a thousand books or 10,000 books, then like the overhead is

1307
02:05:13,100 --> 02:05:19,840
smaller because now we can reuse the same processes most likely and do the calculation

1308
02:05:19,840 --> 02:05:29,040
like the word counts. But it depends on many factors. And yeah, like there's no one simple

1309
02:05:29,040 --> 02:05:39,040
reason why it might be faster or slower. There is the point, this moving data between processes

1310
02:05:39,040 --> 02:05:46,400
in multi-processing, that's a big thing here. So Python multi-processing isn't actually shared

1311
02:05:46,400 --> 02:05:51,280
memory. There's actual different processes. So it has to use inter-process communication to

1312
02:05:51,280 --> 02:06:00,160
share the data. And in practice, the way the program stores the data is relatively inefficient,

1313
02:06:00,160 --> 02:06:08,000
so it apparently takes a long time to do this sharing of the computed enneagrams between things.

1314
02:06:10,240 --> 02:06:14,880
But again, the question, when you're encountering these sort of

1315
02:06:14,880 --> 02:06:20,800
situations, it's usually a good idea to measure your program, profile your program,

1316
02:06:20,800 --> 02:06:28,080
and ask us, maybe, is it worth the effort of trying to parallelize something before you start

1317
02:06:28,080 --> 02:06:34,080
just putting more hardware to the problem? Because sometimes the correct solution might

1318
02:06:34,080 --> 02:06:39,680
be to look at the problem from a different point of view, instead of looking at it from the point

1319
02:06:39,680 --> 02:06:44,240
of view of, okay, what do I actually want to accomplish, instead of, okay, I just want to use

1320
02:06:44,240 --> 02:06:52,720
a fancy word for doing that. Yeah. So there's one final thing I'd like to say, and that is the input

1321
02:06:52,720 --> 02:07:01,120
and output, like someone mentioned there. So I noticed when saving this, you notice it's a plain

1322
02:07:01,120 --> 02:07:09,120
text output format, which is good for most purposes, but it has to create every line individually.

1323
02:07:09,120 --> 02:07:17,760
And every line has a JSON serialization, where it puts the words and letters into the

1324
02:07:18,400 --> 02:07:24,160
brackets and stuff like that. And I found that in practice, that's slow. It can spend a lot of the

1325
02:07:24,160 --> 02:07:29,760
time just writing this output. And when you're trying to use the data, spend a lot of time

1326
02:07:29,760 --> 02:07:35,600
reading the data in, especially when the number of books starts getting larger. So basically,

1327
02:07:35,600 --> 02:07:42,880
the processor itself for doing this kind of analysis is so fast that the format the data

1328
02:07:42,880 --> 02:07:49,040
is stored in becomes the bottleneck here. And since it has to write it all once and it writes it,

1329
02:07:49,040 --> 02:07:56,800
it's not writing it in parallel, it's writing it in serial. So that becomes a bottleneck

1330
02:07:56,800 --> 02:07:59,720
and slows things down.

1331
02:07:59,720 --> 02:08:05,600
So all of these considerations, so the data thing especially,

1332
02:08:05,600 --> 02:08:08,200
when you're doing things like machine learning training,

1333
02:08:08,200 --> 02:08:13,080
GPUs and so on are so fast that oftentimes the speed

1334
02:08:13,080 --> 02:08:17,520
of getting data to the GPU is the bottleneck here.

1335
02:08:17,520 --> 02:08:20,720
If you don't use the good data loaders that

1336
02:08:20,720 --> 02:08:23,120
operate in other threads, if your data is not

1337
02:08:23,120 --> 02:08:26,120
stored in a preprocessed format, you

1338
02:08:26,120 --> 02:08:29,520
end up taking more time with that.

1339
02:08:29,520 --> 02:08:32,000
And that's a really nice thing about this example,

1340
02:08:32,000 --> 02:08:34,600
because we can actually see the slowdowns because

1341
02:08:34,600 --> 02:08:40,800
of the data, IO, and so on.

1342
02:08:40,800 --> 02:08:43,960
Yeah, it's usually a good idea to remember

1343
02:08:43,960 --> 02:08:46,720
that when it comes to computers, let's

1344
02:08:46,720 --> 02:08:51,920
say accessing memory register is a few seconds.

1345
02:08:51,920 --> 02:08:55,040
Let's say the scale is something like it's actually

1346
02:08:55,040 --> 02:09:03,200
like nanoseconds, but let's say it would be a few seconds, then accessing the RAM memory

1347
02:09:03,200 --> 02:09:05,760
would be a few hours or something.

1348
02:09:05,760 --> 02:09:11,400
And then accessing a hard drive or a network drive or whatever, that would be years.

1349
02:09:11,400 --> 02:09:15,800
So it's like the scales are, because we're talking about milliseconds at that point,

1350
02:09:15,800 --> 02:09:24,800
so the scales are wacky when it comes to computing, so it's usually a good idea to measure stuff

1351
02:09:24,800 --> 02:09:34,720
when you're doing stuff, and think about, okay, is it worth to create more complex code

1352
02:09:34,720 --> 02:09:39,120
just to get basically nothing out of the exercise?

1353
02:09:39,120 --> 02:09:40,620
But of course, sometimes you have to do it.

1354
02:09:40,620 --> 02:09:42,920
You have to test it out to see if it happens.

1355
02:09:42,920 --> 02:09:51,080
But it's good to remember that normal, everyday life experiences don't necessarily translate

1356
02:09:51,080 --> 02:09:53,120
one-to-one to computing environments.

1357
02:09:53,120 --> 02:10:02,160
might encounter that like it's suddenly, yeah, suddenly something behaves differently.

1358
02:10:02,160 --> 02:10:07,280
But also I would say that existing codes, like nowadays, most of, a lot of existing

1359
02:10:07,280 --> 02:10:13,480
codes, scientific codes especially, are written to support multiprocessing straight out of

1360
02:10:13,480 --> 02:10:14,480
the box.

1361
02:10:14,480 --> 02:10:17,720
So multiprocessing is not bad if it's written correctly.

1362
02:10:17,720 --> 02:10:25,320
In many cases, like if you're using R or NumPy or any machine learning framework or whatever,

1363
02:10:25,320 --> 02:10:30,600
they support multiprocessing by default. So it's a good idea to check the documentation

1364
02:10:30,600 --> 02:10:35,880
of your specific case. Does it support multiple processors? And if it does,

1365
02:10:35,880 --> 02:10:39,720
then utilize them if they make your problem go faster.

1366
02:10:39,720 --> 02:10:49,960
Yeah. Do you want to show how we can use OnDemand to look at the outputs of the things to wrap up?

1367
02:10:49,960 --> 02:11:00,040
Yes. So I have here the folder so I can see it over here. But if I want to look at it in a more

1368
02:11:00,040 --> 02:11:09,160
graphical way, I could also go to the start place on the on-demand and start,

1369
02:11:09,160 --> 02:11:15,720
let's say, Triton Desktop. So, let's start one. So, this is basically like a virtual desktop that

1370
02:11:15,720 --> 02:11:22,520
is running on one of the compute nodes in the cluster. So, it's a pretty bare-bones experience,

1371
02:11:22,520 --> 02:11:27,080
but it's very good if you want to, let's say, view a plot or something and you don't want to

1372
02:11:27,080 --> 02:11:31,240
to transfer stuff to and fro from Triton.

1373
02:11:31,240 --> 02:11:33,320
So it's now running.

1374
02:11:33,320 --> 02:11:35,240
And I can launch this over here.

1375
02:11:40,000 --> 02:11:44,160
So you notice that I now have a place here.

1376
02:11:44,160 --> 02:11:47,760
And this is running on the Triton file system on Triton.

1377
02:11:47,760 --> 02:11:53,720
So can we go and access Scratch, for example?

1378
02:11:53,720 --> 02:11:55,120
Yeah.

1379
02:11:55,120 --> 02:11:57,520
However, we navigate to it with the browser.

1380
02:11:57,520 --> 02:12:00,960
Yeah, I'm typing Control-L to get this.

1381
02:12:00,960 --> 02:12:09,760
/scratch/work/[my username]/teaching/ ... to kickstart.

1382
02:12:09,760 --> 02:12:11,240
Let's go here.

1383
02:12:11,240 --> 02:12:13,960
Yeah, OK.

1384
02:12:13,960 --> 02:12:17,160
And I could even use the editor here to edit it.

1385
02:12:17,160 --> 02:12:20,160
But there's alternative editors that you can use as well.

1386
02:12:20,160 --> 02:12:22,320
But let's say you want to view one of these outputs.

1387
02:12:22,320 --> 02:12:28,480
So I can just open it up with an editor and see it up there.

1388
02:12:28,480 --> 02:12:34,000
So if you want to view a plot or something you can,

1389
02:12:34,000 --> 02:12:35,920
or you want to do some simple edits,

1390
02:12:35,920 --> 02:12:40,440
this is also a nice way of doing some interactive uses.

1391
02:12:40,440 --> 02:12:42,040
Yeah.

1392
02:12:42,040 --> 02:12:43,360
OK.

1393
02:12:43,360 --> 02:12:46,680
Maybe I'll switch back to the notes here.

1394
02:12:46,680 --> 02:12:53,840
And we can see what unanswered questions there are.

1395
02:12:53,840 --> 02:12:57,240
The other instructors can join us for the outro.

1396
02:13:00,240 --> 02:13:11,840
But yeah, this was a general, yes, OK.

1397
02:13:11,840 --> 02:13:14,920
So in the notes, now there's a feedback for the morning part.

1398
02:13:14,920 --> 02:13:18,280
So you can answer the poll here, tell us what you think.

1399
02:13:18,280 --> 02:13:21,880
So too fast, too slow, whatever, a good thing about today,

1400
02:13:21,880 --> 02:13:25,260
something to improve, any other feedback and so on.

1401
02:13:26,460 --> 02:13:28,440
In the meantime, what's our plan?

1402
02:13:28,440 --> 02:13:31,560
So we have a lunch break coming up

1403
02:13:31,560 --> 02:13:33,760
and then we'll go to Zoom.

1404
02:13:33,760 --> 02:13:38,200
And in Zoom, we will be able to answer more questions

1405
02:13:38,200 --> 02:13:42,140
and basically do all of these different examples

1406
02:13:42,140 --> 02:13:44,280
and exercises together.

1407
02:13:44,920 --> 02:13:49,920
So you have the time that you can work on it yourself.

1408
02:13:49,920 --> 02:13:51,000
Ask more questions.

1409
02:13:51,000 --> 02:13:54,800
We can look at your individual problems, and so on.

1410
02:13:54,800 --> 02:13:56,600
There'll be different breakout rooms there

1411
02:13:56,600 --> 02:13:58,000
focused on different topics.

1412
02:14:02,640 --> 02:14:04,280
Yeah.

1413
02:14:04,280 --> 02:14:07,160
Do you want to give the outro, and then we

1414
02:14:07,160 --> 02:14:11,240
can look at the notes questions and keep answering questions

1415
02:14:11,240 --> 02:14:12,720
until it's the end?

1416
02:14:12,720 --> 02:14:15,120
OK.

1417
02:14:15,120 --> 02:14:17,720
Are you placed to switch to my screen?

1418
02:14:17,720 --> 02:14:18,320
Yeah, exactly.

1419
02:14:23,120 --> 02:14:27,200
So can you stop sharing?

1420
02:14:27,200 --> 02:14:32,240
Because yes, I'm still sharing.

1421
02:14:32,240 --> 02:14:32,740
Yeah.

1422
02:14:36,480 --> 02:14:36,980
No.

1423
02:14:36,980 --> 02:14:43,980
Should I restart my sharing?

1424
02:14:43,980 --> 02:14:44,980
There.

1425
02:14:44,980 --> 02:14:46,980
Now it works.

1426
02:14:46,980 --> 02:14:47,980
Okay.

1427
02:14:47,980 --> 02:14:48,980
Yes.

1428
02:14:48,980 --> 02:14:54,980
We're getting the sharing set up properly.

1429
02:14:54,980 --> 02:15:05,980
Now we've had this nice demo, and I think, well, if I was learning here.

1430
02:15:05,980 --> 02:15:15,260
the things I would have understood hopefully and well now I know from own experience I've

1431
02:15:15,260 --> 02:15:23,020
learned it now I've heard this all this and I think I understand it but in a week or so

1432
02:15:24,300 --> 02:15:32,220
I will realize I forgot half of it and I actually didn't really understand the details of this

1433
02:15:32,220 --> 02:15:41,260
suspect. So where do I go? What can I do? I can answer to this question with our beautiful help

1434
02:15:41,260 --> 02:15:48,220
page. So in our web pages that hopefully are already familiar to you, we have a section all

1435
02:15:48,220 --> 02:15:54,220
dedicated to help. We even have a video actually there a few years ago in a similar workshop like

1436
02:15:54,220 --> 02:16:02,860
this one we had a guest [name] from Code Refinery Norway he gave a nice short video on how

1437
02:16:02,860 --> 02:16:07,500
to ask for help because often sometimes the problem you have it might not be exactly you know

1438
02:16:07,500 --> 02:16:14,780
the actual problem that you might be having and so if you know that you might have a problem or even

1439
02:16:14,780 --> 02:16:19,900
if you don't know what type of problem there are multiple ways of getting help from us maybe the

1440
02:16:19,900 --> 02:16:25,320
The one out of the many ways, the one that I can mention is the so-called Garage, which

1441
02:16:25,320 --> 02:16:29,700
is a daily Zoom session that we are hosting at 1 p.m.

1442
02:16:29,700 --> 02:16:31,900
And the barrier is extremely low.

1443
02:16:31,900 --> 02:16:35,780
You might not even know what is your question or what is your problem.

1444
02:16:35,780 --> 02:16:41,580
And it's not even limited to Triton or to parallel processing or things like that.

1445
02:16:41,580 --> 02:16:49,540
We get people that they might just need basic IT help, or we even get people with questions

1446
02:16:49,540 --> 02:16:56,060
related to privacy, ethics, security, you know, even though we are not maybe the best

1447
02:16:56,060 --> 02:17:00,500
persons at Aalto to answer this question, but we most likely know someone who is the

1448
02:17:00,500 --> 02:17:01,500
best person.

1449
02:17:01,500 --> 02:17:06,660
So the barrier is extremely low, just come there every day at 1pm.

1450
02:17:06,660 --> 02:17:09,980
And then of course, when things get a little bit more complicated, they start to become

1451
02:17:09,980 --> 02:17:11,900
more like a consultation.

1452
02:17:11,900 --> 02:17:15,940
And so for that, we have the issue tracker, where you can basically paste a bit of your

1453
02:17:15,940 --> 02:17:21,780
code and you know something that cannot be solved quickly in within the one hour of the garage

1454
02:17:21,780 --> 02:17:30,260
session and of course that's the documentation that we have here in in general also we try to

1455
02:17:30,260 --> 02:17:36,900
also host some focus days in the in the garage so now I opened the garage space and so sometimes

1456
02:17:36,900 --> 02:17:43,300
we get guests from some departments as key so the IT services from from those departments

1457
02:17:43,300 --> 02:17:46,140
And sometimes, for example, we have this special day.

1458
02:17:46,140 --> 02:17:48,540
So recently we've been running the COMSOL

1459
02:17:48,540 --> 02:17:51,140
Multiphysics Focus Day every Wednesday.

1460
02:17:51,140 --> 02:17:53,940
So if you know that you're gonna use COMSOL

1461
02:17:53,940 --> 02:17:58,740
and you're not sure if your setup is optimal with Triton,

1462
02:17:58,740 --> 02:18:02,160
then that is the place to come for with.

1463
02:18:03,820 --> 02:18:08,820
So yeah, basically this is how to get help.

1464
02:18:09,240 --> 02:18:12,660
Maybe we still have a few minutes.

1465
02:18:12,660 --> 02:18:17,540
I could talk about kind of where to go from here.

1466
02:18:17,540 --> 02:18:19,420
In this page, which is the same page

1467
02:18:19,420 --> 02:18:22,400
where there's the upcoming courses

1468
02:18:22,400 --> 02:18:25,320
that we are hosting slash co-hosting.

1469
02:18:26,360 --> 02:18:28,020
If you scroll to the bottom,

1470
02:18:28,020 --> 02:18:30,100
there's also this nice picture

1471
02:18:30,100 --> 02:18:32,340
that [name] draw a few years ago,

1472
02:18:32,340 --> 02:18:34,380
which is kind of the skills map

1473
02:18:34,380 --> 02:18:36,820
when it comes to computing in general,

1474
02:18:36,820 --> 02:18:38,620
scientific computing.

1475
02:18:38,620 --> 02:18:41,220
So most of you here, for example,

1476
02:18:41,220 --> 02:18:44,660
have the type of basic skills that I even briefly cover

1477
02:18:44,660 --> 02:18:48,420
in the morning, understanding the hardware and the software

1478
02:18:48,420 --> 02:18:49,860
that you might be using.

1479
02:18:49,860 --> 02:18:51,260
And then, of course, sometimes you

1480
02:18:51,260 --> 02:18:54,420
need something a little bit more specific to your field,

1481
02:18:54,420 --> 02:18:59,620
whether it's simulations or whatever

1482
02:18:59,620 --> 02:19:03,020
is the kind of more science-related skills.

1483
02:19:03,020 --> 02:19:05,420
And then we start going that, before going

1484
02:19:05,420 --> 02:19:10,780
to the cluster and HPC, and the more advanced uses or tools

1485
02:19:10,780 --> 02:19:13,380
that we can use along with our coding

1486
02:19:13,380 --> 02:19:15,100
and scientific computing.

1487
02:19:15,100 --> 02:19:18,140
It's important to, you know, learn the Linux shell

1488
02:19:18,980 --> 02:19:22,220
and sometimes not just type in a few commands,

1489
02:19:22,220 --> 02:19:23,420
but as you already saw today,

1490
02:19:23,420 --> 02:19:25,040
sometimes you need to write a script.

1491
02:19:25,040 --> 02:19:26,940
So those scripts that you saw today,

1492
02:19:26,940 --> 02:19:29,660
they were so-called LRM scripts,

1493
02:19:29,660 --> 02:19:31,860
but in practice they are shell scripts.

1494
02:19:31,860 --> 02:19:34,380
And then on top of that, this is where we are here today

1495
02:19:34,380 --> 02:19:37,420
in learning our cluster and HPC are working.

1496
02:19:38,300 --> 02:19:40,540
When it comes to scientific coding,

1497
02:19:40,540 --> 02:19:48,940
there are more courses that we offer and in this i'm gonna mention that exactly one month from

1498
02:19:48,940 --> 02:19:53,340
today we have the next round of the code refinery workshop you can already register at this link

1499
02:19:53,900 --> 02:20:02,300
the code refinery workshop is a half six half days that are basically covering the basics of

1500
02:20:02,300 --> 02:20:05,300
of where is the schedule?

1501
02:20:07,500 --> 02:20:08,540
I don't see it here.

1502
02:20:09,640 --> 02:20:13,080
No, this is actually the lessons, but oh yeah,

1503
02:20:13,080 --> 02:20:14,760
it was here above, sorry.

1504
02:20:14,760 --> 02:20:16,840
Yes, Code Refinery March 25.

1505
02:20:16,840 --> 02:20:21,440
So the first three days, the first week of Code Refinery

1506
02:20:21,440 --> 02:20:25,440
covers everything about Git version control.

1507
02:20:25,440 --> 02:20:28,440
And we also cover kind of how to use GitHub

1508
02:20:28,440 --> 02:20:31,160
and the features that GitHub provides

1509
02:20:31,160 --> 02:20:34,320
so that you can create issues, pull requests and so on.

1510
02:20:34,320 --> 02:20:38,020
So it's very useful for this type of collaborative coding.

1511
02:20:38,020 --> 02:20:41,480
And then the second half focuses on reproducibility,

1512
02:20:41,480 --> 02:20:45,120
specifically the so-called computational reproducibility

1513
02:20:45,120 --> 02:20:47,000
and kind of there's a little bit more kind of,

1514
02:20:47,000 --> 02:20:48,680
how could I say, best practices

1515
02:20:48,680 --> 02:20:51,200
when it comes to scientific computing.

1516
02:20:51,200 --> 02:20:56,200
So automated testing and this type of continuous integration

1517
02:20:56,800 --> 02:20:59,380
and modular code development and so on.

1518
02:20:59,380 --> 02:21:07,140
So, basically, the last thing that I want to mention before we go for lunch break is

1519
02:21:07,140 --> 02:21:13,820
also that we have been running many of these courses in the past, and almost everything

1520
02:21:13,820 --> 02:21:19,220
is available in our YouTube channel, so you can kind of retake a past course.

1521
02:21:19,220 --> 02:21:25,780
But if you feel that it would be nice that we do a rerun of a past course, or maybe if

1522
02:21:25,780 --> 02:21:29,220
if you feel that something is missing in your curriculum

1523
02:21:29,220 --> 02:21:31,540
and you would really need something new

1524
02:21:31,540 --> 02:21:33,060
that we've never been running,

1525
02:21:33,060 --> 02:21:34,820
we have this form where people,

1526
02:21:34,820 --> 02:21:39,580
where you can basically request reruns of older courses

1527
02:21:39,580 --> 02:21:41,460
or a run of new courses.

1528
02:21:41,460 --> 02:21:46,460
And so here you see a long list of GitHub, Python, Julia.

1529
02:21:48,260 --> 02:21:49,900
This is the one where we are right now,

1530
02:21:49,900 --> 02:21:53,900
introduction to HPC and so on.

1531
02:21:53,900 --> 02:21:58,900
So, I think this is all cover for today.

1532
02:21:59,980 --> 02:22:03,740
Maybe I mentioned now for the exercises,

1533
02:22:03,740 --> 02:22:06,140
the exercises will happen in Zoom.

1534
02:22:06,140 --> 02:22:09,280
And the reason is that we will not be recording

1535
02:22:09,280 --> 02:22:10,780
what happens in the exercises room.

1536
02:22:10,780 --> 02:22:14,660
So you are free to use your microphone,

1537
02:22:14,660 --> 02:22:17,420
show your screen if you're having an error

1538
02:22:17,420 --> 02:22:20,300
that you want us to look at.

1539
02:22:20,300 --> 02:22:21,960
We will split in multiple rooms,

1540
02:22:21,960 --> 02:22:25,300
depending on what you wanna test

1541
02:22:25,300 --> 02:22:26,820
or what do you wanna learn.

1542
02:22:26,820 --> 02:22:27,840
In room number one,

1543
02:22:27,840 --> 02:22:30,480
we will basically go through all the exercises

1544
02:22:30,480 --> 02:22:33,000
on the Triton tutorials one by one

1545
02:22:33,000 --> 02:22:35,240
from connection to the login node

1546
02:22:36,280 --> 02:22:40,540
up to running this array jobs and other parallel things.

1547
02:22:41,440 --> 02:22:46,440
So this is highly recommended

1548
02:22:46,760 --> 02:22:49,080
if you recently got a Triton account

1549
02:22:49,080 --> 02:22:51,440
but basically never really use Triton.

1550
02:22:51,960 --> 02:22:57,720
Room 2 is more for helps if you have issues with connecting to Triton or other issues that could

1551
02:22:57,720 --> 02:23:05,240
be related to account, Triton account. And room 3 will be a little bit more advanced where for

1552
02:23:05,240 --> 02:23:10,280
those users who already are maybe familiar with connecting to Triton and running some

1553
02:23:11,400 --> 02:23:18,920
sbatch SLURM jobs but maybe you your needs are you know you might be needing CPUs, GPUs, or more

1554
02:23:18,920 --> 02:23:26,200
advanced parallelization and then we have one room dedicated to how to use large language models

1555
02:23:26,200 --> 02:23:33,640
and on Triton we actually store already some popular open source language models and we have

1556
02:23:33,640 --> 02:23:40,840
even a little bit of examples on how to run those local models so this is you know kind of a hands-on

1557
02:23:40,840 --> 02:23:47,080
way for testing that and finally room number five is the speech-to-text which is a tool that's been

1558
02:23:47,080 --> 02:23:53,400
used a lot by Aalto. Aalto doctoral researchers where, for example, the need of this tool

1559
02:23:53,400 --> 02:23:58,120
is that you might be collecting an interview, so in the form of speech, and this is a tool

1560
02:23:58,120 --> 02:24:04,880
that transcribes the interview into text. And for security and for confidentiality,

1561
02:24:04,880 --> 02:24:10,680
this all runs on Triton, so you don't need to, you know, upload your sensitive interview

1562
02:24:10,680 --> 02:24:16,020
outside of the Aalto network. And so for those who are interested in that, you can try speech

1563
02:24:16,020 --> 02:24:24,340
the text with the demo in room number five. It's 12 o'clock. I think we are done. Is there anything

1564
02:24:24,340 --> 02:24:30,500
to bring up from the notes? I would say that please give us feedback at the end of the notes.

1565
02:24:31,300 --> 02:24:36,900
At the end of the notes, there's this quick polling and you can give us also feedback

1566
02:24:37,780 --> 02:24:41,540
at the end. So please give us feedback on how did you find the course.

1567
02:24:41,540 --> 02:24:48,340
Because this is the first time we have done this kind of like a one-day quick kickstart

1568
02:24:48,340 --> 02:24:52,380
and it's good to get feedback on how it went in your mind.

1569
02:24:52,380 --> 02:25:00,060
So please leave us good and negative feedback, both welcome, because that will make the course

1570
02:25:00,060 --> 02:25:01,060
better.

1571
02:25:01,060 --> 02:25:02,060
Yeah.

1572
02:25:02,060 --> 02:25:03,060
All right.

1573
02:25:03,060 --> 02:25:09,740
So have a good rest of the day.

1574
02:25:09,740 --> 02:25:22,500
So hopefully some of you will join us for the exercises in Zoom and yeah, great.

1575
02:25:22,500 --> 02:25:23,500
Thanks a lot.

1576
02:25:23,500 --> 02:25:24,500
See you later.

1577
02:25:24,500 --> 02:25:25,500
Bye.

1578
02:25:25,500 --> 02:25:26,500
Bye.

1579
02:25:26,500 --> 02:25:27,000
Bye.

1580
02:25:39,740 --> 02:25:41,800
you

1581
02:26:09,740 --> 02:26:11,800
you

1582
02:26:39,740 --> 02:26:41,800
you

1583
02:27:09,740 --> 02:27:11,800
you

1584
02:27:39,740 --> 02:27:41,800
you

1585
02:28:09,740 --> 02:28:11,800
you

1586
02:28:39,740 --> 02:28:41,800
you

1587
02:29:09,740 --> 02:29:11,800
you

1588
02:29:39,740 --> 02:29:41,800
you

