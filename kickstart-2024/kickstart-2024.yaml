- workshop_title: HPC/SciComp Kickstart summer 2024
- workshop_description: >
    This is part of the Aalto Scientific Computing "Getting started
    with Scientific Computing and HPC Kickstart" 2024
    workshop.  The videos are available to everyone, but may be most
    useful to the people who attended the workshop and want to review
    later.

    This course covers the basics of using HPC clusters (and day 1,
    the general background needed to do good scientific computing
    work).  It is recommended for all new researchers.

    Playlist: https://www.youtube.com/playlist?list=PLZLVmS9rf3nOeuqXNa8tS-tDtdQrES2We

    Workshop webpage: https://scicomp.aalto.fi/training/scip/kickstart-2024/

    Aalto Scientific Computing: https://scicomp.aalto.fi/


- input: raw/day1a-obs.mkv

- output: out/day1-icebreaker.mkv
  title: 1.1 Icebreaker
  description: >-
    General discussion before the workshop starts, about who we are
    and what we do.  You probably want to skip this unless you want to
    get a feeling for the course.

  editlist:
  - start: 00:06:46
  - end: 00:17:14


- output: out/day1-intro.mkv
  title: 1.2 Introduction
  description: >-
    General introduction to the workshop.

    https://scicomp.aalto.fi/training/kickstart/intro/

  editlist:
  - start: 00:17:14
  - end: 00:27:20


- output: out/day1-from-data-storage-to-your-science.mkv
  title: "1.3 From data storage to your science"
  description: >-
    Data is how most computational work starts, whether it is
    externally collected, simulation code, or generated. And these
    days, you can work on data even remotely, and these workflows
    aren't obvious. We discuss how data storage choices lead to
    computational workflows.

    https://hackmd.io/@AaltoSciComp/SciCompIntro

  editlist:
  - start: 00:27:30
  - end: 00:41:48


- output: out/day1-computational-reproducibility.mkv
  title: 1.4 (Computational) reproducibility and open science
  description: >-
    Transparency in science is one of the core principles in research
    integrity.  Did you know that half of published studies are
    actually not reproducible?  Here we give an overview of
    CodeRefinery learning materials for those who want to start
    picking up good enough practices like git version control, clear
    project folder structure, conda environments, containers.

    You can read more about CodeRefinery and its dedicated workshops
    at https://coderefinery.org/ .

    https://coderefinery.github.io/reproducible-research/


  editlist:
  - start: 00:41:48
  - end: 01:06:59


- output: out/day1-the-humans-of-scientific-computing.mkv
  title: "1.5 The humans of scientific computing"
  description: >-
    Who are we that provide these services? What makes it such a
    fascinating career?  How did we learn what we know?  Learn about
    what goes on behind the scenes and how you could join us.  Our
    guest works at CSC - The IT Center for Science (https://csc.fi)

  editlist:
    - start: 01:16:27
    - stop: 01:41:36


- output: out/day1-what-can-do-with-cluster.mkv
  title: "1.6 What can you do with a computational cluster?"
  description: >-
    A couple of real examples of how people use the cluster
    1) Multi-cpu-node computations with LAMMPS, 2) text synthesis
    with open source Large Language Models (LLMs).  This is a preview
    of what we will be learning the next two days, but it is *not*
    supposed to be enough to understand how to do it right now.

  editlist:
    - start: 01:42:08
    - 01:43:24: "First demo: LAMMPS molecular dynamics simulator using MPI"
    - 01:55:30: "Second demo: Visualizing with the Open OnDemand desktop"
    - 02:00:00: "Third example: Deep learning with LLM inference"
    - stop: 02:08:12

- output: out/day1-connecting.mkv
  title: 1.7 Connecting to the cluster
  description: >-
    How to connect to the cluster.  This is in preparation for
    tomorrow, and not needed right now.  We give various demos, but
    you need to apply this for yourself by tomorrow

    https://scicomp.aalto.fi/triton/tut/connecting/

  editlist:
    - start: 02:18:41
    - 02:20:10: What's the login node?  What are we trying to do?
    - 02:21:08: SSH connection
    - 02:28:18: Connecting via Open OnDemand (web interface)
    - 02:36:16: Q&A and other wrap-up
    - end: 02:41:00


- input: raw/day1b-obs.mkv

- output: out/day1-ask-for-help.mkv
  title: "1.8 How to ask for help with (super)computers"
  description: >-
      It’s dangerous to go alone, take us! Don’t waste time
      struggling, there are plenty of people here for you.  This talk
      gives you an insight into how to ask good questions, when to ask,
      and who would be answering and trying to help you.

      Right before this lesson, we had a technical problem (internet
      outage) and thus had to switch broadcast computers.  Thus, we
      had to change broadcaster on short notice, but it worked.  We
      are sorry for the inconvenience.

      https://zenodo.org/records/8392763

  editlist:
    - start: 00:02:03
    - -: Intro
    - 00:04:43: Begin presentation
    - 00:27:09: Summary
    - stop: 00:29:23

- input: raw/day1c-obs.mkv

- output: out/day1-vscode.mkv
  title: "1.9 VScode on HPC"
  description: >-

    VS Code can be used as an interface to a cluster via the
    Remote-SSH extension.  How does this work?  It has some advantages
    and can be a good interface, but it comes with some extra things
    you need to be careful about when connecting this way.

    https://scicomp.aalto.fi/triton/apps/vscode/

  editlist:
    - start: 00:02:20
    - end: 00:23:20

- output: out/day1-qa.mkv
  title: "1.10 Q&A and final comments, day 1"
  description: >-
    The final wrap-up / Q&A of day 1 and preparation for day 2,
    including what to do to prepare.
  editlist:
    - start: 00:23:30
    - stop: 00:30:44




- input: raw/day2-obs.mkv

- output: out/day2_01-icebreaker.mkv
  title: 2.1 Icebreakers and introduction
  description: >-
    Icebreaker discussion of day 2.  Most people will go straight to
    the other videos.
  editlist:
  - start: 00:11:27
  - end: 00:22:05

- output: out/day2_02-about-clusters.mkv
  title: 2.2 About clusters and using them
  description: >-
    What is a cluster and why would we use one?  Brief reminder about
    the previous day and comments on how to use them and ask for help.

    https://scicomp.aalto.fi/triton/tut/intro/

  editlist:
  - start: 00:22:05
  #- 00:36:04: How to get help
  - end: 00:27:49

- output: out/day2_03-slurm.mkv
  title: '2.3 Slurm: the queueing system'
  description: >-
    Slurm is the "workload manager" or queuing system which manages
    all the resources.  It takes requests for jobs (CPU, memory, time,
    etc) and schedules them among all of the rest of the cluster.
    We discuss the basics of this system and we'll see how it actually
    works soon.

    https://scicomp.aalto.fi/triton/tut/slurm/

  editlist:
  - start: 00:27:49
  - 00:28:47: "Food metaphor: the HPC Diner"
  - 00:34:40: The resources Slurm manages
  - end: 00:44:30

- output: out/day2_04-copying-code-to-cluster.mkv
  title: 2.4 Copy your code to a cluster (git clone)
  description: >-
    We describe how to copy your code to the cluster.  We use this
    later.

    https://scicomp.aalto.fi/triton/tut/cluster-shell/#triton-tut-example-repo
  editlist:
    - start: 00:44:30
    - stop: 00:45:52

- output: out/day2_05-interactive.mkv
  title: 2.5 Interactive jobs
  description: >-
    Before we get to scripted jobs (like most people use on the
    cluster), we will talk about interactive jobs.  This lets us get a
    little bit familiar with the Slurm system.  You shouldn't use this
    for running real calculations, but for testing and debugging, it is
    very useful.

    https://scicomp.aalto.fi/triton/tut/interactive/
  editlist:
  - start: 00:45:52
  - -: Why and what are interactive jobs?
  - 00:47:15: Running the jobs and looking at the history
  - 00:56:24: Interactive shells
  - 00:59:20: Checking job history
  - 01:00:03: Exercise introduction and some Q&A
  - stop: 01:02:02
  - start: 01:17:12
  - -: Post-exercise Q&A
  - 01:19:12: Exercises Interactive-1 as a demo
  - stop: 01:24:01

- output: out/day2_06-serial.mkv
  title: 2.6 Serial jobs
  description: >-
     Running jobs in simple Slurm batch scripts: this is the starting point
     of everything that comes next.  This is the most important lesson
     that everything built up to, and everything else will build upon.

     https://scicomp.aalto.fi/triton/tut/serial/
  editlist:
  - start: 01:34:37
  - 01:42:59: Demo
  - 01:56:46: Exercises
  - stop: 01:58:08
  - start: 02:31:06
  - -: Q&A and discussion
  - 02:32:18: Demo of exercises Serial-3 and Serial-5
  - stop: 02:46:21


- output: out/day2_07-monitoring.mkv
  title: 2.7 Monitoring jobs (summary)
  description: >-
    In order to use large amounts of resources, you need to be able to
    monitor how many resources you used, so that you can properly adjust
    the resources you request later.  We go over the main parts: output
    during the job, time, memory efficiency, CPU efficiency, GPU
    efficiency, and so on.

    We have already seen most of the content there, but we summarize
    everything now in one place.

    https://scicomp.aalto.fi/triton/tut/monitoring/
  editlist:
  - start: 02:46:21
  - 02:49:19: Slurm history
  - 02:51:35: seff to look at job efficiency
  - 02:54:57: Exercise introduction
  - stop: 02:56:02
  - start: 03:11:20
  - -: Post-exercise Q&A
  - 03:12:30: Monitoring examples as an exercise
  - stop: 03:22:54

- output: out/day2_08-applications.mkv
  title: '2.8 Applications, Modules, Data, Remote data'
  description: >-
    We give a lightning overview of four topics: applications (how to
    get software to run), modules (how some software is made
    available), data storage (there are many options, and each with a
    different trade-off: you do need to know these), and how to access
    data remotely and transfer it.  Each of these could easily take
    much longer time, but we only go over the high-level and then let
    you read on your own time.

    https://scicomp.aalto.fi/triton/tut/applications/

    https://scicomp.aalto.fi/triton/tut/modules/

    https://scicomp.aalto.fi/triton/tut/storage/

    https://scicomp.aalto.fi/triton/tut/remotedata/
  editlist:
    - start: 03:33:23
    - 03:35:10: Different ways of installing software on the cluster
    - 03:39:36: Software installed by admin (modules)
    - 03:42:25: Quick overview how software on cluster works
    - 03:50:47: Short overview of using modules
    - end: 03:54:42

#- output: out/day2-applications.mkv
#  title: '2.7 Applications and Modules: software on the cluster'
#  description: >-
#    Software installation is one of our most time-consuming tasks in
#    supporting cluster usage.  In "Applications", we'll talk about the
#    general principles of managing software on the cluster: can you
#    install things?  Do you need to ask us?  Do both happen at the
#    same time?  Then we look at the `module` command that lets you
#    make other pre-installed software available.
#
#    https://scicomp.aalto.fi/triton/tut/applications/
#
#    https://scicomp.aalto.fi/triton/tut/modules/
#  editlist:
#    - start: 03:39:52
#    - 03:40:48: Different ways of installing software on the cluster
#    - 03:42:17: Software installed by admin (modules)
#    - 03:45:45: Quick overview how software on cluster works
#    - 03:47:43: Short overview of using modules
#    - 03:48:24: 'Example: loading the anaconda module'
#    - end: 03:53:15
#
#    There are several things we don't go into detail about: the
#    "module" command, data storage, and remote access to data.  This
#    is the intro to these sections, and the actual videos come next.
#
#    1) "module" is the command you use to make more software available.
#    Here, we go over the idea behind it, but mainly we leave it to
#    you to read the tutorial page.
#
#    https://scicomp.aalto.fi/triton/tut/modules/
#
#    2) We go over data storage on the cluster: why it is important, main
#    considerations, where to store it, and so on.  We only give a bit of
#    discussion, and leave you to read for the details.
#
#    https://scicomp.aalto.fi/triton/tut/storage/
#
#    3) You have data on the cluster, but you need to be able to access it
#    from outside, or copy new data to the cluster.  This can be
#    surprisingly frustrating, so we discuss transferring data vs
#    mounting a remote filesystem for transparent access.
#
#    https://scicomp.aalto.fi/triton/tut/remotedata/
#
#- output: out/day2-data-storage.mkv
#  title: 2.8 Data storage and accessing it remotely
#  description: >-
#    We go over data storage on the cluster: why it is important, main
#    considerations, where to store it, and so on.  We only give a bit of
#    discussion, and leave you to read for the details.
#
#    https://scicomp.aalto.fi/triton/tut/storage/
#
#    You have data on the cluster, but you need to be able to access it
#    from outside, or copy new data to the cluster.  This can be
#    surprisingly frustrating, so we discuss transferring data vs
#    mounting a remote filesystem for transparent access.
#
#    https://scicomp.aalto.fi/triton/tut/remotedata/
#
#  editlist:
#  - start: 03:53:32
#  - -: Different places of storing data
#  - 03:58:17: Overview of options on Triton
#  - 04:02:35: Explaining storage quotas
#  - 04:02:51: 'Remote access to data: basics'
#  - 04:06:17: Remote mounting
#  - 04:07:33: Transfering data
#  - end: 4:09:26


- output: out/day2_09-outro.mkv
  title: '2.9 Q&A day 2'
  description: >-
    Q&A with anything the audience throws at us.
  editlist:
  - start: 03:54:42
  - end: 04:15:36
- output: out/day2_10-outro.mkv
  title: '2.10 Daily wrap-up, discussion, and Q&A'
  description: >-
    Wrap-up of the day, and preparing for the next day.
  editlist:
  - start: 04:15:36
  - end: 04:19:11

#- output: out/day2-modules.mkv
#  title: 2.8 Software modules
#  description: >-
#    "module" is the command you use to make more software available.
#     Here, we go over the idea behind it, but mainly we leave it to
#     you to read the tutorial page.
#
#     https://scicomp.aalto.fi/triton/tut/modules/
#  editlist:
#  - start: 3:48:40
#  - end: 3:55:00
#
#
#- output: out/day2-remote-data.mkv
#  title: 2.10 Remote data access
#  description: >-
#    You have data on the cluster, but you need to be able to access it
#    from outside, or copy new data to the cluster.  This can be
#    surprisingly frustrating, so we discuss transferring data vs
#    mounting a remote filesystem for transparent access.
#
#    https://scicomp.aalto.fi/triton/tut/remotedata/
#  editlist:
#  - start: 4:07:28
#  - end: 4:17:03





- input: raw/day3-obs.mkv

- output: out/day3_01-icebreaker.mkv
  title: 3.1 Icebreaker and intro
  description: >-
    Introduction of day 3.  Most people will go straight to the other
    videos. This segment does however contain some useful discussion
    about the goals of the course and how you should approach
    learning scientific computing, given how overwhelming this course
    can seem.
  editlist:
  - start: 00:10:57
  - end: 


- output: out/day3_02-parallel.mkv
  title: 3.2 Different methods of parallel computing
  description: >-
    Before we get to how to run parallel jobs, let's talk about the
    different forms, since a person must keep these straight in order
    to run them the right way on the cluster.  The forms are listed
    below.

    https://scicomp.aalto.fi/triton/tut/parallel/

  editlist:
  - start: 00:38:02
  - 00:40:25: How to choose your parallelization method.
  - 00:42:30: Embarassingly parallel / perfectly parallel
  - 00:44:56: Shared memory parallelism
  - 00:48:12: MPI parallelism
  - 00:52:08: GPU parallelization
  - 00:55:26: How well does your code parallelize
  - 00:57:01: Wrap-up
  - end: 00:58:01


- output: out/day3_03-array.mkv
  title: 3.3 Array jobs
  description: >-
    When there is no dependency or communication among the individual
    program runs, these individual runs can be run in parallel on
    separate Slurm jobs called array jobs.  These are very useful and
    used often, including with other types of parallelism.

    https://scicomp.aalto.fi/triton/tut/array/

  editlist:
  - start: 00:58:12
  - stop: 00:59:56
# Cuts out richard's audio issues, not sure if the jump is jarring though
  - start: 01:01:10
  - 01:01:22: Overview of array jobs
  - 01:04:50: Your first array job
  - 01:11:44: Ways to use array jobs
  - 01:12:46: Exercises introduction
  - stop: 01:15:02
  - start: 01:41:31
  - -: Going over the exercises
  - 01:42:45: 'Example: exercise 1'
  - 01:48:55: 'Audience question: How to use array jobs to train llms'
  - 01:52:10: 'Short example: exercise 5'
  - stop: 01:54:58


- output: out/day3_04-CSC-l2l.mkv
  title: 3.4 From laptops to LUMI - CSC resources for researchers, CSC
  description: >-
    What if you need more than what a university can provide?  In
    Finland, CSC (https://csc.fi, https://docs.csc.fi) have even more
    resources, and this is a tour of them.

    Slides:
    https://github.com/AaltoSciComp/scicomp-docs/raw/master/training/scip/CSC-services_062024.pdf
  editlist:
  - start: 02:26:39
  - -: About this talk, about CSC
  - 02:28:19: Introduction
  - 02:29:14: About CSC
  - 02:37:50: CSC computing services
  - 02:39:17: CSC cloud computing services
  - 02:41:04: LUMI overview
  - 02:42:37: CSC data management and storage services
  - 02:44:05: Topical trainings
  - 02:46:23: Getting access to the services
  - 02:50:52: Puhti web interface
  - 02:57:23: Q&A
  - end: 03:09:00


- output: out/day3_05-shared-memory.mkv
  title: 3.5 Shared memory parallelism (part 1)
  description: >-
    Shared memory or multiprocessing parallelism can scale to one node
    and allow communication between processors on a node.  This is run
    with `--cpus-per-task`.

    https://scicomp.aalto.fi/triton/tut/parallel-shared/
  editlist:
  - start: 01:55:26
  - -: Overview of shared memory parallelism
  - 01:56:26: 'Example: running pi.py in parallel'
  - end: 02:01:51


- output: out/day3_06-MPI.mkv
  title: 3.6 MPI overview
  description: >-
    MPI (message-passing interface) is the standard way for jobs to
    communicate across processes or nodes on a massive scale.  Here,
    we talk very briefly about how to run MPI jobs on a cluster.

    https://scicomp.aalto.fi/triton/tut/parallel-mpi/
  editlist:
  - start: 03:32:31
  - -: What is MPI?
  - 03:36:11: 'Example: Running pi in parallel using MPI'
  - end: 03:40:55

- output: out/day3_07-gpus.mkv
  title: 3.7 GPU computing
  description: >-
    GPUs, short for graphical processing unit, are massively-parallel
    processors that are optimized to perform parallel
    operations. Computations that might take days to run on CPUs, take
    substantially less time on GPUs.  We discuss how to use them with
    Slurm and what are some common pitfalls when running these
    programs, but we don't go into detail about just how they are
    programmed or anything like that.

    https://scicomp.aalto.fi/triton/tut/gpu/
  editlist:
  - start: 03:41:05
  - -: What's a GPU and why?
  - 03:45:35: 'Example: pi again but now with GPUs'
  - 03:51:30: 'Common pitfall: GPU being bottlenecked by CPUs'
  - 03:54:06: 'Common pitfall: Loading libraries incorrectly'
  - 03:55:51: 'Question: running several jobs on a single GPU'
  - 03:59:32: How to reserve specific GPUs
  - 04:00:21: Why you should maximize GPU efficiency
  - 04:03:23: Avoiding CUDA issues
  - 04:05:25: Keeping GPUs occupied when doing deep learning
  - 04:09:16: No exercises, still in queue
  - end: 04:09:41

- output: out/day3_08-outro.mkv
  title: 3.8 General Q&A and day 3 and workshop wrap-up
  description: >-
    Wrap up of the workshop, including some hints about what to do
    next, our future plans, etc.
  editlist:
  - start: 04:09:42
  - -: General Q&A
  - 04:11:18: Recommended tutorials for doing GPU calculations
  - 04:15:09: Numpy parallelization
  - 04:17:33: What are TPUs (Tensor Processing Unit)
  - 04:20:41: Is gaming GPU useful for calculations?
  - 04:25:38: Most common mistakes with GPU programs
  - 04:26:31: Going through feedback
  - end: 04:32:35
