1
00:00:00,000 --> 00:00:02,000
CodeRefinery.org

2
00:00:30,000 --> 00:00:32,060
you

3
00:01:00,000 --> 00:01:02,060
you

4
00:01:30,000 --> 00:01:32,060
you

5
00:02:00,000 --> 00:02:02,060
you

6
00:02:30,000 --> 00:02:32,060
you

7
00:03:00,000 --> 00:03:02,060
you

8
00:03:30,000 --> 00:03:32,060
you

9
00:04:00,000 --> 00:04:02,060
you

10
00:04:30,000 --> 00:04:49,040
Now, I hope you can hear us.

11
00:04:49,040 --> 00:04:54,160
Anyone out there?

12
00:04:54,160 --> 00:04:59,120
So let's scroll down in the notes,

13
00:04:59,120 --> 00:05:01,480
which if you're just joining today,

14
00:05:01,480 --> 00:05:05,360
this is the shared document we use to communicate.

15
00:05:05,360 --> 00:05:10,120
It's sent to registered participants only.

16
00:05:10,120 --> 00:05:12,640
If we scroll down, we can get to day two,

17
00:05:12,640 --> 00:05:17,760
and we already see some icebreakers here.

18
00:05:17,760 --> 00:05:21,240
So icebreaking questions are, what programming languages

19
00:05:21,240 --> 00:05:23,600
do you use?

20
00:05:23,600 --> 00:05:28,280
how long have you used computers, and favorite ice cream?

21
00:05:28,280 --> 00:05:32,360
Should we discuss these questions ourselves?

22
00:05:32,360 --> 00:05:36,720
Yeah, I guess we could.

23
00:05:36,720 --> 00:05:38,760
My favorite ice cream is already on the list.

24
00:05:38,760 --> 00:05:42,760
It would be Strassetella at the moment, at least, because you can't really get it in

25
00:05:42,760 --> 00:05:43,760
Finland.

26
00:05:43,760 --> 00:05:46,760
Well, not a lot, at least.

27
00:05:46,760 --> 00:05:47,760
Yeah.

28
00:05:47,760 --> 00:06:03,960
But, yeah. I think saying what the first computer was that I used might tell my age. Might be

29
00:06:03,960 --> 00:06:10,120
a bit embarrassing. It's been a long time.

30
00:06:10,120 --> 00:06:15,280
Back when I first used computers, I didn't even know to ask what kind of thing it was.

31
00:06:15,280 --> 00:06:23,200
was just something that was there. So, I mean, I wasn't that young. I just didn't know this was a

32
00:06:23,200 --> 00:06:30,080
thing to be interested in until a lot longer. So, yeah.

33
00:06:30,080 --> 00:06:36,640
Yeah. I think my first use of actual computers was playing Pac-Man.

34
00:06:39,520 --> 00:06:42,640
And that was at a friend's house, so it wasn't really my computer.

35
00:06:42,640 --> 00:06:43,640
Yeah.

36
00:06:43,640 --> 00:06:53,320
Computers, other computers back then were for, well, for the company, by my parents'

37
00:06:53,320 --> 00:06:54,320
dentists.

38
00:06:54,320 --> 00:07:03,560
So they had a computer system for their patients, and that's one of the first ones that was

39
00:07:03,560 --> 00:07:06,600
available back then.

40
00:07:06,600 --> 00:07:08,320
Yeah.

41
00:07:08,320 --> 00:07:10,120
What about programming languages?

42
00:07:10,120 --> 00:07:17,640
your special interest there. For me, it's probably, well, Python and Shell as the

43
00:07:19,000 --> 00:07:24,760
main ones. Probably more Python. And I've messed with C a bit.

44
00:07:27,480 --> 00:07:31,720
I mean, some are a long time ago, but not really anymore.

45
00:07:31,720 --> 00:07:45,960
Yeah. C. C is a long time ago. And C-sharp, if anyone still knows what that is.

46
00:07:45,960 --> 00:07:48,320
That was, was that a Microsoft thing?

47
00:07:48,320 --> 00:07:58,040
Yeah. Yeah. It was the C++ variant that Microsoft sort of used.

48
00:07:58,040 --> 00:08:12,480
And then, yeah, I wouldn't say I've got a special interest. I'll have their uses. I've

49
00:08:12,480 --> 00:08:25,600
I've used at least the top 1, 2, 3, 4, 5, 6, 7, 8.

50
00:08:25,600 --> 00:08:26,100
8.

51
00:08:28,880 --> 00:08:34,720
In school, I actually use basic, so yeah.

52
00:08:34,720 --> 00:08:40,040
Does using count as claiming to know anything

53
00:08:40,040 --> 00:08:44,240
or have barely made modifications to something in that language

54
00:08:44,240 --> 00:08:47,320
and managed to somehow rebuild it and run it?

55
00:08:48,960 --> 00:08:51,200
Because I've done that for a few of them.

56
00:08:51,200 --> 00:08:55,480
That was at grade six or something.

57
00:08:55,480 --> 00:09:00,480
And we had a pre-made environment

58
00:09:00,960 --> 00:09:04,140
where we could write a few instructions.

59
00:09:05,480 --> 00:09:09,000
And that's basically my knowledge of BASIC.

60
00:09:09,000 --> 00:09:16,680
Okay, yeah. Actually, yeah. So BASIC was my first language. Somehow, that's the first

61
00:09:16,680 --> 00:09:20,640
thing I was aware of. And then C.

62
00:09:20,640 --> 00:09:30,160
I actually properly started programming with Java. Well, no, actually I properly started

63
00:09:30,160 --> 00:09:37,000
programming with Dr. Scheme, which is a Lisp dialect. But I don't ever want to see that

64
00:09:37,000 --> 00:09:38,000
again.

65
00:09:38,000 --> 00:09:43,760
Yeah. So, by the way, there's a place you can ask follow-up questions from day one,

66
00:09:43,760 --> 00:09:54,960
stuff you would like us to keep responding to. Yeah, and we can talk now. But is there any

67
00:09:54,960 --> 00:10:01,120
decompression from yesterday you'd like to talk about? I guess, did you follow all the course

68
00:10:01,120 --> 00:10:08,520
yesterday for most of it. Well, I was there for the morning. I didn't have time in the

69
00:10:08,520 --> 00:10:15,680
afternoon to follow it, so I don't know much about what happened in the afternoon. I mean,

70
00:10:15,680 --> 00:10:29,040
I read the core script, but... Yeah. But overall, I mean, it was... So it was sort of trying

71
00:10:29,040 --> 00:10:35,280
to be a combination of what we did last year, which is following the written material in

72
00:10:35,280 --> 00:10:40,760
the tutorials with the pie example, and doing the new Gutenberg example like we did a few

73
00:10:40,760 --> 00:10:47,240
months ago without any materials itself. So we sort of tried to follow the page and have

74
00:10:47,240 --> 00:10:53,560
people do stuff, but most of what we were doing wasn't on there. So it was a bit chaotic

75
00:10:53,560 --> 00:11:00,600
hell. But since we know the strategy works, I guess we can improve it for next time.

76
00:11:01,560 --> 00:11:05,720
And I guess from what I noticed from yesterday is that there were

77
00:11:05,720 --> 00:11:10,520
lots and lots of discussions in the notes document, which I think was really good.

78
00:11:11,240 --> 00:11:11,960
Yeah, yeah.

79
00:11:15,560 --> 00:11:21,000
So I think it went quite nicely, what I saw.

80
00:11:23,560 --> 00:11:31,800
Yeah. Okay, that's good. I mean, the feedback, yeah, there were some things that said

81
00:11:34,200 --> 00:11:40,440
it was a bit, how would you say, chaotic or whatever, but most feedback seemed good,

82
00:11:40,440 --> 00:11:46,440
so that's good. Oh, I was thinking last night, whenever you're not happy with something,

83
00:11:46,440 --> 00:11:53,320
do tell us in the feedback preferably nicely and constructively but if even if we know

84
00:11:53,320 --> 00:11:58,760
something can be improved if we don't if we see more people saying it worked really well then it

85
00:11:59,640 --> 00:12:05,160
didn't work well or you couldn't do the exercises whatever then we'll think okay well I guess this

86
00:12:05,160 --> 00:12:12,360
is the right balance so it really is important to fill out these feedback things not for this

87
00:12:12,360 --> 00:12:22,040
year, but for the people that come next year. Yeah. So anyway, what's today? So we continue

88
00:12:22,040 --> 00:12:34,600
with these examples. So we continue with the Gutenberg example. We show how to do things

89
00:12:34,600 --> 00:12:36,160
in parallel with it.

90
00:12:39,760 --> 00:12:43,880
Yeah, Parallel Gutenberg.

91
00:12:43,880 --> 00:12:49,560
And also, actually, Parallel Gutenberg

92
00:12:49,560 --> 00:12:51,040
covers several different things.

93
00:12:54,120 --> 00:12:56,720
And then some other stuff about how

94
00:12:56,720 --> 00:13:00,280
to use different applications on the cluster,

95
00:13:00,280 --> 00:13:03,560
including Conda that lets you install Python and R

96
00:13:03,560 --> 00:13:08,280
and more types of software, and more general application

97
00:13:08,280 --> 00:13:09,680
stuff, and so on.

98
00:13:12,360 --> 00:13:18,080
So hopefully, today's not as difficult as yesterday.

99
00:13:18,080 --> 00:13:19,760
But we'll see.

100
00:13:19,760 --> 00:13:21,760
I think it won't be as bad.

101
00:13:21,760 --> 00:13:24,160
Oh, I guess I already answered this question down here.

102
00:13:24,160 --> 00:13:28,560
Yes, we continue working on Gutenberg Fiction.

103
00:13:28,560 --> 00:13:29,880
Did you like this example?

104
00:13:29,880 --> 00:13:34,880
I'm really happy with coming up with it.

105
00:13:34,960 --> 00:13:38,880
It's compared to the Pi example, which was a bit,

106
00:13:40,200 --> 00:13:45,200
yeah, it's this typical problem of tutorials

107
00:13:45,240 --> 00:13:50,240
that you have that one minimal effort example

108
00:13:51,060 --> 00:13:53,560
that works and it's easy.

109
00:13:53,560 --> 00:13:55,560
And then if you've got a real problem,

110
00:13:55,560 --> 00:13:59,960
Well, there's quite a big step up from the exam,

111
00:13:59,960 --> 00:14:03,240
so I think it's better in that respect.

112
00:14:03,240 --> 00:14:06,600
It's a bit more complex than the Pi example

113
00:14:06,600 --> 00:14:10,800
used to be in Kickstarts before.

114
00:14:10,800 --> 00:14:13,440
I guess it's like the two different sides.

115
00:14:13,440 --> 00:14:16,480
One is the Pi example was easy and you could run

116
00:14:16,480 --> 00:14:19,600
without any data there,

117
00:14:19,600 --> 00:14:21,480
but that made it not realistic.

118
00:14:21,480 --> 00:14:23,440
Now you have to transfer the data and

119
00:14:23,440 --> 00:14:25,320
the code and make them work together,

120
00:14:25,320 --> 00:14:28,000
which makes it a lot more complex

121
00:14:28,000 --> 00:14:30,360
and more things that can go wrong

122
00:14:30,360 --> 00:14:31,920
and more things that are different

123
00:14:31,920 --> 00:14:33,560
on all the different clusters

124
00:14:33,560 --> 00:14:35,700
because you have to actually care about data paths

125
00:14:35,700 --> 00:14:36,880
and stuff like that.

126
00:14:38,240 --> 00:14:39,280
But on the other hand,

127
00:14:39,280 --> 00:14:41,280
that was sort of the point to make an example

128
00:14:41,280 --> 00:14:43,600
that's like realistic.

129
00:14:43,600 --> 00:14:44,440
Yes, yes.

130
00:14:46,120 --> 00:14:49,520
Like what's the value of teaching something

131
00:14:49,520 --> 00:14:53,560
that's that simple that anyone can just read the code

132
00:14:53,560 --> 00:14:57,040
or read one page of text about it

133
00:14:57,040 --> 00:14:59,280
and then understand what it's doing and do it.

134
00:14:59,280 --> 00:15:00,200
Yeah.

135
00:15:00,200 --> 00:15:03,720
Whereas when you have a real-world problem,

136
00:15:03,720 --> 00:15:06,980
there's so many more problems

137
00:15:06,980 --> 00:15:11,140
that you never got taught in the course, basically.

138
00:15:12,440 --> 00:15:17,000
Because the course example was the most simple one

139
00:15:17,000 --> 00:15:18,680
that anyone could think of.

140
00:15:19,760 --> 00:15:22,640
Well, probably not the most simple one

141
00:15:22,640 --> 00:15:34,080
anyone can think of, but I will probably be saying Hello World, which is, well, it's been

142
00:15:34,080 --> 00:15:41,040
annoying me when reading tutorials that everyone starts with a Hello World and it's so, so simple

143
00:15:41,040 --> 00:15:50,880
all that. Yeah. What's the point? Yeah. But anyway, now it's time to begin.

144
00:15:50,880 --> 00:15:56,760
Right. Let's see, what do I do? I scroll down. So

145
00:15:56,760 --> 00:16:03,480
we already have some questions here that people are answering. So welcome to day two of the

146
00:16:03,480 --> 00:16:08,800
course. We start with something we've done for a few years, which is a quick, I guess

147
00:16:08,800 --> 00:16:13,800
I guess you could call it an interview, but it's not really.

148
00:16:13,800 --> 00:16:15,520
I guess it is, technically.

149
00:16:15,520 --> 00:16:18,640
So we talk to different people that

150
00:16:18,640 --> 00:16:20,920
work on our team or similar teams

151
00:16:20,920 --> 00:16:24,320
and hear about their careers, how they got where they are,

152
00:16:24,320 --> 00:16:29,200
and you can ask questions and see some examples.

153
00:16:29,200 --> 00:16:35,760
So today, right now, we have [name] here,

154
00:16:35,760 --> 00:16:39,600
who actually, I think, is the newest member of our team, technically?

155
00:16:40,640 --> 00:16:48,960
Yeah. It's been nearly a year now, but technically, I'm the newest member.

156
00:16:49,760 --> 00:16:59,360
Yeah. So anyway, what's your background? How did you end up here? What did you study?

157
00:16:59,360 --> 00:17:11,880
Yeah, I think it's maybe a bit of a sort of winding garden path. So I started as, well,

158
00:17:11,880 --> 00:17:21,280
I started studying, originally I started studying Japanese and computer science as a side, then

159
00:17:21,280 --> 00:17:29,280
switched that to studying bioinformatics, which is computer science with a focus on

160
00:17:30,880 --> 00:17:37,760
some biological science. And I picked neuroimaging for that. So then I, I studied

161
00:17:37,760 --> 00:17:45,920
further to do neuroimaging. And that's what I did there was mostly analyzing lots of neuroimaging

162
00:17:45,920 --> 00:17:54,560
data. And yeah, I continued doing that for a little while, did my PhD, did a postdoc.

163
00:17:56,480 --> 00:18:06,880
And yeah, I came to Aalto as a postdoc. And then at Aalto, I met, it must have been around

164
00:18:06,880 --> 00:18:19,600
the Corona time, I met people from SciComp. So did you come here in 2019? Yes, I came to Finland in

165
00:18:19,600 --> 00:18:33,360
2019, November 2019. And then, I don't know, I was in Finland like four or five months when the

166
00:18:33,360 --> 00:18:37,800
the Corona lockdown started,

167
00:18:37,800 --> 00:18:42,040
and everyone went basically working from home.

168
00:18:43,040 --> 00:18:47,960
And my research group sort of didn't really have

169
00:18:47,960 --> 00:18:52,560
a good on staying online presence.

170
00:18:52,560 --> 00:18:57,560
So the psychon chat and partly the code refinery chat

171
00:18:57,880 --> 00:19:02,880
sort of became my coworkers, my office.

172
00:19:02,880 --> 00:19:03,880
Yeah.

173
00:19:03,880 --> 00:19:14,120
And yeah, then I kept working as a postdoc for quite some time still.

174
00:19:14,120 --> 00:19:15,120
Yeah.

175
00:19:15,120 --> 00:19:16,120
Yeah.

176
00:19:16,120 --> 00:19:17,120
Right.

177
00:19:17,120 --> 00:19:20,120
For, I guess, five-ish years.

178
00:19:20,120 --> 00:19:21,120
Yeah.

179
00:19:21,120 --> 00:19:22,120
Ish.

180
00:19:22,120 --> 00:19:23,120
Okay.

181
00:19:23,120 --> 00:19:31,640
And then in the meantime, my husband had gotten to work as an RSE, and then at some point

182
00:19:31,640 --> 00:19:40,680
I applied and got a position here. Okay, nice. Yeah. So was there, well, the next question I

183
00:19:40,680 --> 00:19:48,600
have written, what led for the transition from science, like the direct academic science to

184
00:19:49,160 --> 00:19:55,240
research support? And I guess the obvious answer is it was a job, but is there anything?

185
00:19:55,240 --> 00:20:07,160
No, actually, it's not so much it was a job. Because for me, I've been always more interested

186
00:20:07,160 --> 00:20:13,460
in doing the computation and not so much in getting the results and not so much in interpreting

187
00:20:13,460 --> 00:20:22,060
them and writing them up. So to be honest, if I were on an academic career path still,

188
00:20:22,060 --> 00:20:32,260
I would probably be failing right now because I'm rubbish at writing papers. So that's

189
00:20:32,260 --> 00:20:42,740
one reason. And then there was also, so when I was still a postdoc, I started actually

190
00:20:42,740 --> 00:20:50,100
trying to chat with a colleague who's also sort of into computing a lot, talking about

191
00:20:50,100 --> 00:21:01,460
about that in NeuroImaging, there's a lot of code being written, but many people don't

192
00:21:01,460 --> 00:21:11,780
know how to structure code, what to look for to make code reusable and readable in 10 years

193
00:21:11,780 --> 00:21:16,580
time or even in two years time.

194
00:21:16,580 --> 00:21:22,820
So we then decided we're going to do a little workshop, just for newer ending.

195
00:21:22,820 --> 00:21:35,100
And that was something that I really, really liked, teaching people about how to do programming

196
00:21:35,100 --> 00:21:36,100
really.

197
00:21:36,100 --> 00:21:43,980
And yeah, that was one more reason why I wanted to do more of the teaching to code and less

198
00:21:43,980 --> 00:21:47,660
of the actual science interpretation.

199
00:21:47,660 --> 00:21:52,540
Yeah, yeah. Okay, well, then that's perfect, then. Yeah.

200
00:21:52,540 --> 00:22:00,380
That's where I really wanted, I really, really wanted to go get that kind of position.

201
00:22:00,380 --> 00:22:03,580
And would you say that's what you're doing now?

202
00:22:03,580 --> 00:22:13,940
Yeah, I guess. I mean, there's the kickstart. And there's also a lot of other sort of

203
00:22:13,940 --> 00:22:19,100
of small things. When people come to the garage and they've got a problem with their code,

204
00:22:19,100 --> 00:22:27,660
we had a few people coming just lately that said, oh, it's running so slowly, we need

205
00:22:27,660 --> 00:22:35,860
some help here. And then that sort of turned into a slightly bigger, let's help you restructure

206
00:22:35,860 --> 00:22:41,900
the project and get it into a bit better shape so we can actually get started with improving

207
00:22:41,900 --> 00:22:51,660
the how fast it runs. And that kind of thing. And then there's lots of other projects that

208
00:22:52,220 --> 00:22:58,300
aren't really teaching that are more like trying to get the code done, but that's fine as well.

209
00:22:58,860 --> 00:23:05,260
I do like coding. So I'm quite happy, actually.

210
00:23:05,260 --> 00:23:12,140
Okay. So before, let's say when you were offered the job, were you worried about making the

211
00:23:12,140 --> 00:23:17,420
transition anyhow, and how did it turn out?

212
00:23:17,420 --> 00:23:25,300
Well, I wasn't so worried because I knew the team quite well. I've been in contact with

213
00:23:25,300 --> 00:23:36,020
it through, well, since 2020, I guess, with the one or the other person. So I kind of

214
00:23:36,020 --> 00:23:46,900
knew what I was getting into, and I'm still sort of on a retainer for my old postdoc project.

215
00:23:46,900 --> 00:23:51,620
So I do still work a little bit on the science side.

216
00:23:51,620 --> 00:23:58,620
Yeah. Okay. Right. Yeah. Yeah. So it's like a slow transition.

217
00:23:58,620 --> 00:23:59,620
It is really.

218
00:23:59,620 --> 00:24:07,620
I also had the same, like, I kept working into other things for a while.

219
00:24:07,620 --> 00:24:17,620
What do you know now that you wish someone else had taught you when you first started as a researcher or like your first

220
00:24:17,620 --> 00:24:29,780
I wish I had known when I started my PhD that use version control and use it regularly.

221
00:24:29,780 --> 00:24:35,860
Like, it doesn't really matter whether it's Git, which is the thing that people use most at the

222
00:24:35,860 --> 00:24:44,100
moment now, or I had come into contact with Subversion before that, which is a bit

223
00:24:44,100 --> 00:24:54,940
bit more complicated and less featured, I would say, than Git, but it works. Anything

224
00:24:54,940 --> 00:25:09,500
is better than having files by date with the code or having final, final.1, final.2, and

225
00:25:09,500 --> 00:25:15,100
kind of thing is because it's a mess. Any sort of version control is better

226
00:25:17,020 --> 00:25:21,980
than what you can come up on your own. And you will need it.

227
00:25:23,900 --> 00:25:28,860
How often have you had something where you've edited some code and it's somehow broken and

228
00:25:28,860 --> 00:25:33,580
you've spent days trying to undo the breakage because you can't figure out what it was?

229
00:25:33,580 --> 00:25:35,820
Because that's happened to me many times.

230
00:25:35,820 --> 00:25:47,020
Yeah, well, I don't know how many times, I remember a few, I mean, it's always something

231
00:25:47,020 --> 00:25:53,060
breaks and then there's the, especially in science, if you've already sort of written

232
00:25:53,060 --> 00:26:00,500
up a paper or presented a poster, and then you notice there's a mistake in the code,

233
00:26:00,500 --> 00:26:09,860
you don't know, has it, does it affect my results? That's, I think, the worst kind of thing

234
00:26:10,420 --> 00:26:17,940
that you can ever, that happens and it happens. Yeah, yeah. I know the feeling.

235
00:26:19,380 --> 00:26:25,940
Okay, so next up, what would you say to someone who might be interested in careers outside of

236
00:26:25,940 --> 00:26:38,420
tenure track. Well, already it's great that you're thinking out of the box, basically,

237
00:26:38,420 --> 00:26:46,900
and interested in this. For me, it was mostly sort of talking to people to get to know what

238
00:26:46,900 --> 00:27:00,660
is out there and it doesn't even have to be someone outside academia. A lot of the stuff

239
00:27:03,460 --> 00:27:10,660
how I got into the RSE bit was talking to my colleagues who had heard about this and who

240
00:27:10,660 --> 00:27:19,460
had heard about that. And then there was the CodeRefinery Coffee Hour. Actually, that's

241
00:27:19,460 --> 00:27:26,580
quite a friendly place to go to, or it was when I was going there. And you can just chat to people.

242
00:27:27,220 --> 00:27:33,220
No one bites. Even if it looks a bit intimidating, no one's going to bite you.

243
00:27:35,220 --> 00:27:38,820
And I guess you could say like all the people at Aalto that are helping you,

244
00:27:38,820 --> 00:27:45,700
if you ever want to chat about other stuff. Yeah, I mean, we're here for that. You can

245
00:27:45,700 --> 00:27:53,220
chat in the process of other stuff or whatever. Actually, I think a few times I just went to

246
00:27:53,220 --> 00:28:03,780
Garage because I didn't really have a problem, but I wanted some company of people who

247
00:28:03,780 --> 00:28:14,100
know how to code, I guess, and have a similar mindset.

248
00:28:14,100 --> 00:28:18,900
Your department here was Neuroscience and Biomedical Engineering, so were you sort of

249
00:28:18,900 --> 00:28:23,860
the coder, computer person of the research group?

250
00:28:23,860 --> 00:28:30,380
Well, strictly speaking, that would have been [name], because I wasn't the only one. I was

251
00:28:30,380 --> 00:28:44,500
more or less the junior one. But yes, I was one of the people who knew how to code in

252
00:28:44,500 --> 00:28:46,980
a field where not everyone knows how to code.

253
00:28:46,980 --> 00:28:55,940
Yeah, yeah. And I guess that sort of leads to the next question. So what would you recommend

254
00:28:55,940 --> 00:29:02,180
or what do you think someone could do to prepare for, you know, some more diversity of careers

255
00:29:02,180 --> 00:29:07,220
after they're done with their degrees or postdocs or whatever?

256
00:29:09,140 --> 00:29:16,900
Well, I think just realize that it's not as clean cut as it sometimes sounds.

257
00:29:16,900 --> 00:29:28,820
And to not stress about, if something doesn't go, you do your bachelor, you do your master,

258
00:29:28,820 --> 00:29:34,420
you do your PhD, and then you get a postdoc, and then after two years you get a professorship

259
00:29:34,420 --> 00:29:35,420
or whatever.

260
00:29:35,420 --> 00:29:37,940
That's not how it goes.

261
00:29:37,940 --> 00:29:52,380
When I was still a student, I met a postdoc at the Max Planck Institute, which is a very

262
00:29:52,380 --> 00:29:58,220
high-profile research organization in Germany, if people don't know.

263
00:29:58,220 --> 00:30:06,880
And he, I think he started out as a gardener, and he said, yeah, don't bother.

264
00:30:06,880 --> 00:30:11,240
Don't bother with the pre-set path.

265
00:30:11,240 --> 00:30:13,240
Don't worry about it.

266
00:30:13,240 --> 00:30:18,720
Everyone finds their niche.

267
00:30:18,720 --> 00:30:22,980
If you just want to find something, you will.

268
00:30:22,980 --> 00:30:24,080
It might take a while.

269
00:30:24,080 --> 00:30:31,440
It might be frustrating, and yeah, it's going to be frustrating, but don't stop believing,

270
00:30:31,440 --> 00:30:32,440
basically.

271
00:30:32,440 --> 00:30:33,440
Yeah, okay.

272
00:30:33,440 --> 00:30:39,800
And that sort of, yeah, that gave me some, I guess it gave me some peace of mind, because

273
00:30:39,800 --> 00:30:43,280
my path isn't the straightest of them all.

274
00:30:43,280 --> 00:30:44,280
Yeah.

275
00:30:44,280 --> 00:30:49,920
And it hadn't been back then already, because I had changed degrees and changed universities

276
00:30:49,920 --> 00:30:50,920
a few times.

277
00:30:50,920 --> 00:30:51,920
Yeah.

278
00:30:51,920 --> 00:30:52,920
Okay.

279
00:30:52,920 --> 00:30:53,920
So, last question, and we can...

280
00:30:53,920 --> 00:30:54,920
Yeah.

281
00:30:54,920 --> 00:30:55,920
Yeah.

282
00:30:55,920 --> 00:30:56,920
Go ahead.

283
00:30:56,920 --> 00:30:57,920
Last question.

284
00:30:57,920 --> 00:30:58,920
We can look at some of the notes.

285
00:30:58,920 --> 00:31:03,600
you want to continue learning and what comes next?

286
00:31:03,600 --> 00:31:10,320
I continue learning all the time about things that I didn't know about. So I can't say

287
00:31:10,320 --> 00:31:15,760
what I'm going to be learning next time. I don't know who's going to come into Garage

288
00:31:15,760 --> 00:31:20,920
tomorrow and say, hey, I've got a problem with this and then I'm going to learn about

289
00:31:20,920 --> 00:31:30,040
it. Because that's something that happens quite often that I don't really know in-depth,

290
00:31:30,040 --> 00:31:31,960
but I know where to look.

291
00:31:31,960 --> 00:31:43,400
Yeah. Okay. So there's some interesting questions in the notes. Do you use ChatGPT or similar?

292
00:31:43,400 --> 00:31:52,240
Well, me personally, I do not, at least not really regularly. I've used it a few times

293
00:31:52,240 --> 00:32:00,640
to just get like a bit of a code snippet or just an answer that I didn't want to Google

294
00:32:00,640 --> 00:32:09,840
about, or just to try it out. I could have just as well Googled it and found it out myself.

295
00:32:09,840 --> 00:32:18,380
And I'm a bit, well, I'm a bit worried about everyone using ChatGPT because people then

296
00:32:18,380 --> 00:32:27,340
tend to forget that it has a lot of downfalls and it starts hallucinating things.

297
00:32:27,340 --> 00:32:31,200
You can't actually really trust it.

298
00:32:31,200 --> 00:32:36,340
So you need to check it anyway and then some other source.

299
00:32:36,340 --> 00:32:37,340
Yeah.

300
00:32:37,340 --> 00:32:38,340
Okay.

301
00:32:38,340 --> 00:32:47,500
But I know that a few people use it for things that are easy to check and you can see the

302
00:32:47,500 --> 00:32:48,500
answers there.

303
00:32:48,500 --> 00:32:53,740
Yeah, we can see what people have written there.

304
00:32:53,740 --> 00:32:57,260
What's the most exciting thing you've worked on?

305
00:32:57,260 --> 00:33:04,460
Well, the most exciting for me is the teaching.

306
00:33:04,460 --> 00:33:08,980
I guess you're relatively don't have that many projects yet, but yeah.

307
00:33:08,980 --> 00:33:14,020
I don't have that many projects, but yeah, I think for me, the teaching is the most exciting

308
00:33:14,020 --> 00:33:15,020
thing.

309
00:33:15,020 --> 00:33:16,020
Yeah.

310
00:33:16,020 --> 00:33:22,500
The thing that I'm nervous about before and then sort of elected after.

311
00:33:22,500 --> 00:33:32,060
Yeah, next one, what's the most important skill you look for when hiring RSEs like people

312
00:33:32,060 --> 00:33:33,060
for our team?

313
00:33:33,060 --> 00:33:37,700
Yeah, I guess that would be your question to answer.

314
00:33:37,700 --> 00:33:43,260
That's more, yeah. But my answer is there, like, it's easy to find people that have good

315
00:33:43,260 --> 00:33:49,940
technical skills, but harder to find the people that want to use those skills to help other

316
00:33:49,940 --> 00:33:59,660
people instead of just only developing the skills for themselves. And that's sort of

317
00:33:59,660 --> 00:34:13,180
main thing there, if you ask me. There's a question recommendation for someone in neuroscience,

318
00:34:13,180 --> 00:34:21,420
but maybe you can answer that by writing afterwards. Here's an interesting one.

319
00:34:21,420 --> 00:34:26,860
Most common easy-to-learn fixed mistake people work with high-performance computing make?

320
00:34:26,860 --> 00:34:34,540
what's the most challenging part. This is a good one. We should actually discuss this all

321
00:34:34,540 --> 00:34:40,860
as instructors at the end of the day or end of the course. Do you have any thoughts now?

322
00:34:43,420 --> 00:34:48,140
Or should I try to answer? I think you've got much more experience than I do.

323
00:34:49,820 --> 00:34:55,740
So once someone was talking about how hard it is to learn, how to teach people how to use a cluster,

324
00:34:55,740 --> 00:35:02,140
And my comment was, if you know sort of the Linux operating system, like command line,

325
00:35:02,140 --> 00:35:09,420
how files are stored, the Linux fire hierarchy, and stuff like that, then it's relatively easy

326
00:35:09,420 --> 00:35:14,860
to add in the extra bit to the cluster. But when you're learning to cluster, most people tend to

327
00:35:14,860 --> 00:35:20,380
be learning how to submit jobs. At the same time, they're learning how to write shell scripts,

328
00:35:20,380 --> 00:35:26,700
how to ssh there, how to use the command line. All these things at the same time,

329
00:35:26,700 --> 00:35:34,060
everything depends on everything else. So it's quite overwhelming, even though if you

330
00:35:34,060 --> 00:35:40,780
knew everything except one thing, that one thing would be relatively easy and make sense.

331
00:35:40,780 --> 00:35:43,780
So that's my take on it.

332
00:35:43,780 --> 00:35:53,780
I think the first bit of the first comment is quite something important there.

333
00:35:53,780 --> 00:35:59,780
How to look for parallelism, because if you really want to use the power of the cluster,

334
00:35:59,780 --> 00:36:02,780
you want to run things in parallel.

335
00:36:02,780 --> 00:36:11,780
And getting into that sort of mindset of identifying what can I run while I'm doing something else

336
00:36:11,780 --> 00:36:19,780
and not doing it step by step by step.

337
00:36:19,780 --> 00:36:26,780
Like usually when we're teaching, a lot of the time it's like you do this first and then you do this

338
00:36:26,780 --> 00:36:28,780
and then you do this and then you do this.

339
00:36:28,780 --> 00:36:39,180
this, and then taking this, what you've learned about the flow, and then trying to think what

340
00:36:39,180 --> 00:36:53,020
can I actually do out of order? That's something that's somewhat hard to grasp, I guess.

341
00:36:53,020 --> 00:36:57,060
So unfortunately, it's time to go on. I guess we can keep answering questions about this

342
00:36:57,060 --> 00:37:05,620
later or find us, talk to us later. Next up is a session that's about Conda. I guess the

343
00:37:05,620 --> 00:37:17,380
instructors seem like they're here in the room, so you can start appearing. So this session,

344
00:37:17,380 --> 00:37:25,960
So, you may know of Conda as a way to install Python packages.

345
00:37:25,960 --> 00:37:27,380
But it's a lot more than that.

346
00:37:27,380 --> 00:37:35,260
It's also a way to install R packages and other compiled code kind of stuff.

347
00:37:35,260 --> 00:37:40,220
And we have a running joke in our Garage session.

348
00:37:40,220 --> 00:37:41,220
It's day's-

349
00:37:41,220 --> 00:37:42,220
Okay, now you're just doing my intro.

350
00:37:42,220 --> 00:37:43,220
Okay.

351
00:37:43,220 --> 00:37:44,220
Go ahead.

352
00:37:44,220 --> 00:37:45,220
I'll let you do your intro to that.

353
00:37:45,220 --> 00:37:52,420
I mean, yeah, we have the running joke. Days since there was a Conda question in the garage.

354
00:37:54,340 --> 00:37:58,660
Okay, how was I going to go? Yeah, it is always zero.

355
00:38:00,660 --> 00:38:06,500
But that means two things. One, Conda's pretty important for installing software because it's

356
00:38:06,500 --> 00:38:14,260
the best way to manage Python and compile the scientific software on a cluster.

357
00:38:14,260 --> 00:38:17,900
And two, it's harder than it should be.

358
00:38:17,900 --> 00:38:20,300
Or maybe it's as hard as it needs to be.

359
00:38:20,300 --> 00:38:23,500
It's just that it's actually a hard problem.

360
00:38:23,500 --> 00:38:31,540
So us as cluster admins before the RSE things started,

361
00:38:31,540 --> 00:38:33,340
the software installation probably

362
00:38:33,340 --> 00:38:36,100
took up most of our time.

363
00:38:36,100 --> 00:38:38,100
Took up most of our time.

364
00:38:38,100 --> 00:38:43,940
And yeah, so where was this going?

365
00:38:43,940 --> 00:38:49,380
Yeah, software installation is quite a difficult thing.

366
00:38:49,380 --> 00:38:54,620
And now, lucky you, you get to learn one way of handling it.

367
00:38:54,620 --> 00:38:57,260
So maybe I'll just go and let Jarno and you

368
00:38:57,260 --> 00:38:58,220
do their introduction.

369
00:38:58,220 --> 00:39:00,460
So see you later.

370
00:39:00,460 --> 00:39:01,540
All right.

371
00:39:01,540 --> 00:39:03,140
Bye.

372
00:39:03,140 --> 00:39:04,140
Yeah.

373
00:39:04,140 --> 00:39:08,100
So I mean, my starting intro was going

374
00:39:08,100 --> 00:39:10,340
to be that joke specifically.

375
00:39:10,340 --> 00:39:14,620
So yeah, day since we've had a question about Conda

376
00:39:14,620 --> 00:39:18,620
is always zero because Conda is very useful

377
00:39:18,620 --> 00:39:22,660
and you also run into complicated problems.

378
00:39:22,660 --> 00:39:27,660
But if you then include the kinds of questions

379
00:39:28,420 --> 00:39:32,900
where it's about installing some software

380
00:39:32,900 --> 00:39:34,900
or problems installing some software

381
00:39:34,900 --> 00:39:37,420
and the solution is Conda,

382
00:39:37,420 --> 00:39:39,060
well, you get even more of those questions.

383
00:39:39,060 --> 00:39:43,140
It's basically like a half of the questions

384
00:39:43,140 --> 00:39:44,300
or something like that.

385
00:39:46,060 --> 00:39:50,020
So yeah, what is Conda?

386
00:39:50,020 --> 00:39:51,400
I can be honest.

387
00:39:51,400 --> 00:39:54,060
The name of this page that I'm sharing

388
00:39:54,060 --> 00:39:56,020
is Python environments with Conda.

389
00:39:56,020 --> 00:39:59,480
And that's also linked to in the notes page.

390
00:40:00,380 --> 00:40:02,940
But Conda is not just about Python installations.

391
00:40:02,940 --> 00:40:06,820
It's a very general dependency manager.

392
00:40:06,820 --> 00:40:11,500
So to install a specific piece of software,

393
00:40:11,500 --> 00:40:13,660
you have a bunch of dependencies

394
00:40:13,660 --> 00:40:14,860
that need to be installed as well.

395
00:40:14,860 --> 00:40:17,380
So this could be a system,

396
00:40:17,380 --> 00:40:20,220
or what would normally on your own desktop laptop

397
00:40:20,220 --> 00:40:21,860
be system libraries

398
00:40:21,860 --> 00:40:24,900
and specific versions of those system libraries.

399
00:40:24,900 --> 00:40:26,300
You can install those with Conda

400
00:40:26,300 --> 00:40:28,500
and then get the software to work.

401
00:40:28,500 --> 00:40:32,660
And it's also useful for separating between projects

402
00:40:32,660 --> 00:40:33,780
because different projects

403
00:40:33,780 --> 00:40:40,500
might need a different version of some library. Often they're not designed to exist at the same

404
00:40:40,500 --> 00:40:47,700
time, but Conda takes care of that as well. So it is very useful. It also does have some problems,

405
00:40:47,700 --> 00:40:52,340
especially when used with Python on some HPC systems. So we'll come to that later.

406
00:40:53,140 --> 00:41:00,580
But yeah, I guess one important point about HPC specifically is that it's always a shared system.

407
00:41:00,580 --> 00:41:13,580
So installing all the software that everybody using it needs on the system level would get very complicated very quickly.

408
00:41:13,580 --> 00:41:26,580
And that's where conda helps. It allows you to install software that you need that maybe not everybody else needs.

409
00:41:26,580 --> 00:41:34,580
Okay. I mean, I did not introduce myself or you. Do you want to introduce yourself?

410
00:41:38,580 --> 00:41:45,580
Yeah, my name is [name]. I'm also one of the RSEs. I'm very happy to be here today.

411
00:41:46,580 --> 00:41:51,580
And I'm [name]. I'm also an RSE here in Aalto.

412
00:41:51,580 --> 00:42:04,700
Okay. So, let's get started. So, yeah, I mean, Conda is actually language agnostic. There's

413
00:42:04,700 --> 00:42:11,180
nothing specific to Python. We use it often to handle Python environments. An environment

414
00:42:11,180 --> 00:42:19,860
is, so an environment is when you have this certain set of dependencies for a specific

415
00:42:19,860 --> 00:42:23,860
project and you can have a different environment for a different project.

416
00:42:23,860 --> 00:42:29,220
So you can have a completely different set of libraries for a different project.

417
00:42:30,180 --> 00:42:34,980
So it's a very general solution for handling software environments.

418
00:42:36,580 --> 00:42:42,900
And actually yeah we use Mamba most of the time. Mamba is a replacement for Conda that's just

419
00:42:42,900 --> 00:42:50,420
faster. It uses a different algorithm on the background. But it's essentially the same thing,

420
00:42:50,420 --> 00:43:00,740
a very small difference. So let's actually go to the terminal and get started. And there's some,

421
00:43:02,420 --> 00:43:11,220
well, we load a module called Mamba. Module is its own kind of, it's a system level way of handling

422
00:43:11,220 --> 00:43:17,140
the fact that people need different software. There will be a separate section on the module

423
00:43:17,140 --> 00:43:23,220
system later in this course, so I will not explain that much of it, except that I will show you.

424
00:43:25,060 --> 00:43:30,260
If I try to run Mamba, it does not exist. I am on Triton, we do have Mamba,

425
00:43:30,260 --> 00:43:34,100
but I do need to run module load Mamba in order to get access to it.

426
00:43:35,460 --> 00:43:40,260
And now I have Mamba. Oh, it printed a long, long list of commands you can run.

427
00:43:41,220 --> 00:43:44,500
but it did work, so the command is found.

428
00:43:46,020 --> 00:43:49,060
And then we have this initial setup.

429
00:43:49,060 --> 00:43:51,220
This is very much Aalto-specific.

430
00:43:51,220 --> 00:43:56,220
It's something you probably should not run on other systems,

431
00:43:58,020 --> 00:43:59,840
but it's here in the documentation.

432
00:43:59,840 --> 00:44:02,420
And if you are on Triton, you should run it.

433
00:44:02,420 --> 00:44:05,280
So if you're not on Triton, ask,

434
00:44:06,300 --> 00:44:09,140
and probably don't just take our Aldo instruction

435
00:44:09,140 --> 00:44:10,980
or Triton instructions directly.

436
00:44:11,220 --> 00:44:16,220
Okay, and that's the first time set up.

437
00:44:17,220 --> 00:44:19,780
Oh, there was one thing I was going to talk about

438
00:44:19,780 --> 00:44:23,480
before going to an example here.

439
00:44:23,480 --> 00:44:25,660
So about conda channels.

440
00:44:25,660 --> 00:44:30,060
Channels are where conda pulls the software.

441
00:44:30,060 --> 00:44:35,060
So they store a bunch of these libraries, binary packages,

442
00:44:36,500 --> 00:44:40,420
and allow you to install them into your environment.

443
00:44:40,420 --> 00:44:44,380
So there are many options.

444
00:44:44,380 --> 00:44:46,900
conda-forge is probably the biggest one

445
00:44:46,900 --> 00:44:50,020
and you almost always want to include it.

446
00:44:50,020 --> 00:44:52,580
It has a lot of packages and it's,

447
00:44:55,780 --> 00:45:00,780
well, the licensing is good for research.

448
00:45:01,280 --> 00:45:02,700
It's mostly open source

449
00:45:04,380 --> 00:45:06,700
and the channel itself is open source.

450
00:45:06,700 --> 00:45:09,100
So it's very useful.

451
00:45:10,420 --> 00:45:21,420
There's also the default channel, which is maintained by Anaconda Inc., who also maintains the conda command itself.

452
00:45:21,420 --> 00:45:30,420
There's licensing issues though, so you mostly want to exclude it.

453
00:45:30,420 --> 00:45:37,420
And if you do want to include it, it's a specific case and you know what you're doing.

454
00:45:37,420 --> 00:45:45,860
Okay, there's also Bioconda, for example, okay, Bioconda has specifically bioinformatics

455
00:45:45,860 --> 00:45:46,860
packages.

456
00:45:46,860 --> 00:45:54,380
It's a separate place for those and if you are in bioinformatics, then you will often

457
00:45:54,380 --> 00:45:55,700
end up using it.

458
00:45:55,700 --> 00:46:00,980
PyTorch, the channel doesn't exist anymore and I should have deleted that line, but I

459
00:46:00,980 --> 00:46:02,460
didn't notice that it was there.

460
00:46:02,460 --> 00:46:11,340
So we will demonstrate installing PyTorch for machine learning later from CondaForge.

461
00:46:11,340 --> 00:46:16,540
Okay.

462
00:46:16,540 --> 00:46:27,060
So I will do a quick example of creating an environment with R. This page is about Python,

463
00:46:27,060 --> 00:46:31,380
but you can also install R and R packages there.

464
00:46:34,300 --> 00:46:37,180
Or any questions?

465
00:46:37,180 --> 00:46:38,920
Anything before we delve in?

466
00:46:40,900 --> 00:46:42,700
I have a question, actually.

467
00:46:42,700 --> 00:46:43,820
Yeah.

468
00:46:43,820 --> 00:46:47,300
How to exclude the defaults from the channel,

469
00:46:47,300 --> 00:46:52,300
from the conda config or from the YAML file?

470
00:46:53,580 --> 00:46:55,940
I always use the YAML files,

471
00:46:55,940 --> 00:47:00,940
And I guess, well, let's make a YAML file.

472
00:47:00,940 --> 00:47:03,500
I mean, so yeah, I always use the YAML files instead

473
00:47:03,500 --> 00:47:08,660
of the config, because the file, essentially,

474
00:47:08,660 --> 00:47:13,260
you can have it with the code and with the whatever version

475
00:47:13,260 --> 00:47:17,060
that you've been running that has produced a specific result,

476
00:47:17,060 --> 00:47:18,300
specific.

477
00:47:18,300 --> 00:47:20,720
You can include it with your paper, basically.

478
00:47:20,720 --> 00:47:25,380
So everybody can reproduce the same thing.

479
00:47:25,380 --> 00:47:28,980
So if you push it to a GitHub repo, it will be there?

480
00:47:29,700 --> 00:47:29,860
Yeah.

481
00:47:29,860 --> 00:47:31,700
Then everyone can reproduce?

482
00:47:31,700 --> 00:47:32,020
Yeah.

483
00:47:32,020 --> 00:47:32,500
That's good.

484
00:47:35,860 --> 00:47:36,260
Yeah.

485
00:47:36,260 --> 00:47:47,140
Was there anything else about environments and managing software in general?

486
00:47:47,140 --> 00:47:50,020
I guess we can come back to any questions if there's there.

487
00:47:50,020 --> 00:47:58,260
there. Left side of my terminal is slightly off screen. So now it should be on the screen,

488
00:47:58,260 --> 00:48:09,980
I think. Okay. Okay. So in order to create an environment, my workflow and workflow I

489
00:48:09,980 --> 00:48:17,020
generally recommend is to create a YAML file. So let's make, I use a Vim to edit the file.

490
00:48:17,020 --> 00:48:30,140
can use nano or whichever you want. I'm creating a file called tidyverse.yml or yaml and this will

491
00:48:30,140 --> 00:48:36,140
describe the entire software environment for my project. So first name for the environment

492
00:48:36,860 --> 00:48:44,140
and I will call it tidyverse. Tidyverse is an R package or an R, well it is a single package

493
00:48:44,140 --> 00:48:49,020
but it contains a lot of useful things.

494
00:48:49,740 --> 00:48:54,300
Then I will describe the channels. So this is a list of channels that

495
00:48:54,300 --> 00:48:59,260
Mamba or Conda is allowed to use to construct this environment.

496
00:48:59,260 --> 00:49:06,860
I will say Conda Forge. That's the only one I need for this one.

497
00:49:06,860 --> 00:49:12,220
Okay and then dependencies. So this is the list of software we actually need

498
00:49:12,220 --> 00:49:22,060
and I will only specify one, r-tidyverse. So because this r-tidyverse depends on r,

499
00:49:22,060 --> 00:49:30,300
we will also get r, the entire programming language ecosystem, into this environment

500
00:49:30,300 --> 00:49:35,260
and it will automatically have a version that supports whatever version of r-tidyverse it

501
00:49:36,300 --> 00:49:41,900
pulls up. You could specify a specific version. I don't actually know what versions

502
00:49:41,900 --> 00:49:46,460
exist though so let me not just do that.

503
00:49:46,860 --> 00:49:53,580
Okay and then I'm saving the file so have it on the screen. Let's cat it.

504
00:49:53,580 --> 00:49:58,060
So this is what the file looks like although very quickly

505
00:49:58,060 --> 00:50:01,420
it will actually disappear off the screen when I run

506
00:50:01,420 --> 00:50:06,700
the next command. So we can do mamba. I actually did not write down the

507
00:50:06,700 --> 00:50:13,900
command. So let's see if I get it right. Mamba env for environment, create,

508
00:50:15,500 --> 00:50:25,340
minus f, f stands for file, and tidyverse. Okay, so now it's looking for first tidyverse

509
00:50:26,140 --> 00:50:32,380
in ContaForge and then it looks for possible dependencies. It's

510
00:50:32,380 --> 00:50:35,500
It's taking a while before printing again.

511
00:50:35,500 --> 00:50:36,780
OK, here we go.

512
00:50:36,780 --> 00:50:38,180
So it found a bunch of stuff.

513
00:50:41,540 --> 00:50:46,660
If I had one more character width on the display,

514
00:50:46,660 --> 00:50:50,620
it wouldn't break the lines, but that's fine.

515
00:50:50,620 --> 00:50:53,380
So yeah, it takes a while to download all of this.

516
00:50:53,380 --> 00:50:56,460
Tidyverse is relatively small, so it doesn't take that long.

517
00:50:56,460 --> 00:50:57,380
That's why I chose it.

518
00:50:57,380 --> 00:51:01,340
But it takes a while to get all of the system libraries,

519
00:51:01,340 --> 00:51:07,420
like X-Org, the window manager, graphics manager,

520
00:51:07,420 --> 00:51:11,820
display manager for Linux, and a lot of other stuff.

521
00:51:15,460 --> 00:51:21,820
FontConfig and GNU, C libraries, all sorts of stuff.

522
00:51:21,820 --> 00:51:22,320
OK.

523
00:51:25,140 --> 00:51:28,260
So it is essentially constructing an entire software

524
00:51:28,260 --> 00:51:31,180
environment.

525
00:51:31,180 --> 00:51:40,140
me oh okay it's done then i will not yet take a look at the um the chat uh the notes

526
00:51:40,780 --> 00:51:47,260
okay yeah there's a question uh asking us to clean the terminal so that they can see the

527
00:51:47,260 --> 00:51:55,660
commands on top so maybe move the terminal a bit upper or clean the terminal so um i guess

528
00:51:55,660 --> 00:52:02,140
does it mean that they cannot see the lowest line? Yes, I think that's the problem. Okay,

529
00:52:02,140 --> 00:52:07,740
you can move it up a little bit. Maybe that's it. Maybe run clear.

530
00:52:09,900 --> 00:52:16,220
So, I want to comment on the text that is showing here. So, because in a lot of systems,

531
00:52:16,220 --> 00:52:22,380
you actually do not want to run this command. On Triton, you do not want to run this command.

532
00:52:22,380 --> 00:52:34,540
So, instead, we use source activate tidyverse.

533
00:52:34,540 --> 00:52:37,080
But okay, let me clear the terminal first.

534
00:52:37,080 --> 00:52:42,880
The reason that we don't want to run this command is that it requires you to modify

535
00:52:42,880 --> 00:52:45,760
the shell environment in some way.

536
00:52:45,760 --> 00:52:48,560
You need to run this mamba init command.

537
00:52:48,560 --> 00:52:56,400
will tell you to run it if you run this mamba activate. So we want to avoid that to avoid

538
00:52:57,040 --> 00:53:09,360
complicating things even more. So instead we run not mamba activate but source activate tidyverse.

539
00:53:09,360 --> 00:53:20,360
Okay, so now it's showing that this particular environment is active and since I have it

540
00:53:20,360 --> 00:53:28,880
active now, I have for example the R script command.

541
00:53:28,880 --> 00:53:35,920
So let's make a HelloTidy.r, an R script.

542
00:53:40,320 --> 00:53:44,240
If I was using a graphical system,

543
00:53:44,240 --> 00:53:47,840
I could also run RStudio, for example.

544
00:53:47,840 --> 00:53:50,840
OK, I'm not going to explain that much about what

545
00:53:50,840 --> 00:53:52,000
is happening in this script.

546
00:53:52,000 --> 00:53:54,360
But maybe I should say it will check

547
00:53:54,360 --> 00:53:57,520
if I actually have Tidyverse.

548
00:53:57,520 --> 00:54:05,120
and then it will tell me and it will say tidyverse could not be loaded or dplyr could not be loaded.

549
00:54:08,080 --> 00:54:12,480
So I can use our script to run hello tidy

550
00:54:13,520 --> 00:54:17,040
and it should report that the tidyverse library is available.

551
00:54:17,040 --> 00:54:24,040
Okay, and there were some conflicts that became errors.

552
00:54:24,040 --> 00:54:28,040
It loaded successfully, though.

553
00:54:28,040 --> 00:54:33,040
I do not know enough about R to actually know if this is a problem or not.

554
00:54:33,040 --> 00:54:37,040
Probably not a huge problem.

555
00:54:37,040 --> 00:54:40,040
Okay.

556
00:54:40,040 --> 00:54:45,040
So, yeah, that's the point of this demonstration, though, is to show you how to

557
00:54:45,040 --> 00:54:49,280
to record the dependencies in a YAML file,

558
00:54:49,280 --> 00:54:58,800
and also to show you that this is not just for Python,

559
00:54:58,800 --> 00:55:02,880
that you can install a lot of other things as well.

560
00:55:02,880 --> 00:55:04,500
The next thing, though, will be Python,

561
00:55:04,500 --> 00:55:08,120
because it will be how to set up an environment

562
00:55:08,120 --> 00:55:09,320
for a large language model.

563
00:55:12,120 --> 00:55:13,440
How are we doing on time?

564
00:55:15,040 --> 00:55:17,040
Not bad.

565
00:55:19,040 --> 00:55:21,040
Okay, so

566
00:55:23,040 --> 00:55:25,040
next

567
00:55:25,040 --> 00:55:27,040
I have a section

568
00:55:27,040 --> 00:55:29,040
about why you should track

569
00:55:29,040 --> 00:55:31,040
dependencies, which we actually

570
00:55:31,040 --> 00:55:33,040
did touch on a little bit.

571
00:55:33,040 --> 00:55:35,040
So maybe

572
00:55:35,040 --> 00:55:37,040
at this point, do we have any questions

573
00:55:37,040 --> 00:55:39,040
in the notes?

574
00:55:41,040 --> 00:55:43,040
Or do you have

575
00:55:43,040 --> 00:55:49,680
have other questions just in general? There's a question about how do I exit the environment

576
00:55:49,680 --> 00:55:58,480
tab? I think that's asking about the deactivation. Yes, so now I still have the tidyverse environment

577
00:55:58,480 --> 00:56:09,440
active and that means I do have for example rscript. Version of rscript is yes. So to exit I

578
00:56:09,440 --> 00:56:13,840
could run source deactivate.

579
00:56:15,600 --> 00:56:21,120
Okay. It will complain about the source activate, source deactivate

580
00:56:21,120 --> 00:56:27,520
thing but I do not want to like change the environment to run mamba

581
00:56:27,520 --> 00:56:30,960
activate and mamba deactivate so this is fine.

582
00:56:30,960 --> 00:56:35,200
Now if I try to run our script

583
00:56:35,200 --> 00:56:43,920
version. It will not find R script. So now I'm outside the environment. I don't have

584
00:56:43,920 --> 00:56:51,600
R anymore and I don't have the libraries. Okay.

585
00:56:51,600 --> 00:57:06,800
Okay, there's another question about, it's kind of like a Python 3.0, I suppose it's

586
00:57:06,800 --> 00:57:14,040
asking the Python's own virtualenv and how it's different from Conda.

587
00:57:14,040 --> 00:57:21,680
Yeah, so, oh, so I guess like venv or venv comes with Python 3.

588
00:57:21,680 --> 00:57:22,680
Yeah.

589
00:57:22,680 --> 00:57:26,800
So, yeah, there's plenty of different environment managers.

590
00:57:26,800 --> 00:57:31,640
The Python 3 venv thing is designed for Python specifically.

591
00:57:31,640 --> 00:57:37,240
It can install Python packages.

592
00:57:37,240 --> 00:57:42,200
So it cannot install system level packages.

593
00:57:42,200 --> 00:57:44,000
it cannot install R for you.

594
00:57:44,000 --> 00:57:48,080
So Conda is more general.

595
00:57:48,080 --> 00:57:50,440
It's not just for Python, and it can install

596
00:57:50,440 --> 00:57:55,400
some system-level things.

597
00:57:55,400 --> 00:57:58,640
So for example, we'll soon install an environment

598
00:57:58,640 --> 00:58:02,920
that has CUDA in it without you needing

599
00:58:02,920 --> 00:58:06,360
to set it up for your system in the same way.

600
00:58:06,360 --> 00:58:14,520
Yeah, I think maybe it's the time to go to the next question.

601
00:58:14,520 --> 00:58:21,080
But there is also a question about the CSC thing.

602
00:58:21,080 --> 00:58:26,400
The background of this is that Conda creates a lot of files in the environment, especially

603
00:58:26,400 --> 00:58:29,860
if you install Python packages, it can be millions of files.

604
00:58:29,860 --> 00:58:34,420
And this is often bad on an HPC system.

605
00:58:34,420 --> 00:58:41,700
So if you want to use Conda to manage environments,

606
00:58:41,700 --> 00:58:44,980
there is this solution from CSC called

607
00:58:44,980 --> 00:58:48,540
Tykky, the container wrapper.

608
00:58:48,540 --> 00:58:51,920
So it can create something very much like a Conda environment

609
00:58:51,920 --> 00:58:52,420
for you.

610
00:58:52,420 --> 00:58:54,100
It is actually a Conda environment,

611
00:58:54,100 --> 00:58:58,660
but wrapped into a single file that is a container.

612
00:58:58,660 --> 00:59:04,060
So you can read up about it in here.

613
00:59:04,060 --> 00:59:08,700
And yes, there is a link to it already in the notes.

614
00:59:08,700 --> 00:59:11,700
So most of the things I say apply,

615
00:59:11,700 --> 00:59:14,980
but the commands are different.

616
00:59:14,980 --> 00:59:17,260
And this is probably true on a lot of systems.

617
00:59:17,260 --> 00:59:21,820
So yeah, if you're using a different system,

618
00:59:21,820 --> 00:59:26,100
you do need to figure out how to do this in your system.

619
00:59:26,100 --> 00:59:29,940
Maybe there is even a different manager.

620
00:59:29,940 --> 00:59:31,700
OK.

621
00:59:31,700 --> 00:59:33,580
But yeah, so let's move on.

622
00:59:35,460 --> 00:59:40,460
Okay, so we already mentioned,

623
00:59:44,540 --> 00:59:47,940
talked about how using a Conda environment,

624
00:59:47,940 --> 00:59:51,940
so using a file like this inside your code

625
00:59:51,940 --> 00:59:56,940
makes your code and your research more reproducible.

626
00:59:56,940 --> 01:00:04,220
reproducible. So you can track the entire environment, your entire coding environment,

627
01:00:04,220 --> 01:00:15,580
in a single file. And then you can include it either with your code or with your data,

628
01:00:15,580 --> 01:00:20,700
for example. So if you publish a bunch of data, you can include some software to

629
01:00:20,700 --> 01:00:28,580
to analyze the data and you can include a file that describes the entire environment

630
01:00:28,580 --> 01:00:34,700
that you use to analyze the data so that it is way more reproducible.

631
01:00:34,700 --> 01:00:42,900
People can install your environment and run your code and get the results from your data.

632
01:00:42,900 --> 01:00:48,180
It also helps with debugging, so you will get a lot less of the it works on my machine

633
01:00:48,180 --> 01:00:54,500
problem when other people can reproduce the same environment that you have and it allows version

634
01:00:54,500 --> 01:01:01,300
controlling so if you are doing some heavy software development you are probably hopefully

635
01:01:01,300 --> 01:01:08,420
using version control with your software and you can also conversion your environments so you can

636
01:01:08,420 --> 01:01:15,300
create different versions for different versions of the software so it is it's very useful in for

637
01:01:15,300 --> 01:01:23,620
yourself it also it is very useful for helping your teammates your people in your research group

638
01:01:24,180 --> 01:01:30,420
set up the same environment and run the same code so you can give them the file and give them these

639
01:01:30,420 --> 01:01:36,180
two three commands and they will be able to they will have the same software environment as you do

640
01:01:36,180 --> 01:01:38,740
it also works across different operating systems

641
01:01:38,740 --> 01:01:43,320
with some caveats.

642
01:01:43,320 --> 01:01:45,840
So Windows might require different versions

643
01:01:45,840 --> 01:01:46,760
of system libraries,

644
01:01:46,760 --> 01:01:49,360
but if you don't specify exact versions,

645
01:01:49,360 --> 01:01:51,400
they will mostly figure out to you

646
01:01:51,400 --> 01:01:52,800
how to use the correct ones.

647
01:01:58,440 --> 01:01:59,320
Yes.

648
01:01:59,320 --> 01:02:03,600
So it also helps with a lot of this Python dependency

649
01:02:03,600 --> 01:02:05,200
problems and especially problems

650
01:02:05,200 --> 01:02:07,080
where you need multiple different versions

651
01:02:07,080 --> 01:02:09,680
of the same package for different versions

652
01:02:09,680 --> 01:02:12,080
of your software, different projects.

653
01:02:12,080 --> 01:02:14,360
So those are the main points

654
01:02:14,360 --> 01:02:16,680
for why to use conda in general,

655
01:02:16,680 --> 01:02:21,080
or why to use software environments in general.

656
01:02:21,080 --> 01:02:22,880
It becomes very,

657
01:02:25,860 --> 01:02:27,660
it becomes an especially useful thing

658
01:02:27,660 --> 01:02:30,040
if you have multiple projects running

659
01:02:30,040 --> 01:02:31,880
at the same time with different code.

660
01:02:34,400 --> 01:02:35,560
Okay.

661
01:02:35,560 --> 01:02:41,240
So there's one more thing that I want to mention about practically how to use this.

662
01:02:44,200 --> 01:02:47,000
So we have it somewhere. There are some

663
01:02:48,760 --> 01:02:51,880
a list of useful commands that I could also demonstrate while we go.

664
01:02:52,520 --> 01:02:57,800
So I still have mamba and now that I have an environment I can run.

665
01:02:57,800 --> 01:03:07,040
one more. I was not in an environment. I exited the main. So, okay. If you're in an environment,

666
01:03:07,040 --> 01:03:14,560
you can list. So, let's activate the environment. High diverse. Source activate high diverse.

667
01:03:14,560 --> 01:03:23,640
And let's try. So, you can list all of the packages that are in the environment for additional

668
01:03:23,640 --> 01:03:26,120
reproducibility to make it extra clear what's in,

669
01:03:26,120 --> 01:03:27,760
and then to check to do some debugging

670
01:03:27,760 --> 01:03:30,640
on what is installed in your system, in your environment.

671
01:03:31,920 --> 01:03:34,760
Okay, you can also remove an environment,

672
01:03:34,760 --> 01:03:39,440
but really with this,

673
01:03:39,440 --> 01:03:41,920
which is necessary and useful occasionally,

674
01:03:41,920 --> 01:03:43,840
cleaning the cache is necessary

675
01:03:43,840 --> 01:03:45,960
if you run out of disk space.

676
01:03:45,960 --> 01:03:48,640
But the main thing that I want to highlight

677
01:03:48,640 --> 01:03:50,760
is how to update an environment.

678
01:03:50,760 --> 01:03:56,840
So you can install a package directly into the environment that already exists,

679
01:03:56,840 --> 01:04:03,480
but what I would do essentially always is I have this idverse.yaml file

680
01:04:04,920 --> 01:04:07,320
is to edit the file. So what should I add?

681
01:04:11,320 --> 01:04:15,800
I have R already but I can add it explicitly as a dependency and I could specify a version

682
01:04:15,800 --> 01:04:24,920
for example. So let's see. So now I can run mamba-env-update and then use

683
01:04:25,880 --> 01:04:30,120
minus-f or minus-minus-file and the environment file.

684
01:04:33,240 --> 01:04:39,640
So let's see if it works when I specify the R. I did not specify a R version, I just specified

685
01:04:39,640 --> 01:04:45,080
that I want R. It did install some new packages, which is interesting. Maybe I didn't have the

686
01:04:45,080 --> 01:04:48,600
R command specifically before I just had R script.

687
01:04:48,600 --> 01:04:55,320
Okay, so you can update the environment,

688
01:04:55,320 --> 01:04:58,520
you can add new packages to the environment

689
01:04:58,520 --> 01:05:02,360
and keep track of them in the file as you go, which makes it

690
01:05:02,360 --> 01:05:06,120
makes the file more useful in the long run.

691
01:05:06,120 --> 01:05:11,480
Okay, so here's about setting default channels and like I said I

692
01:05:11,480 --> 01:05:17,640
always use the yaml file to track the channels but you can set default channels in your

693
01:05:19,320 --> 01:05:25,400
conda rc file or in your conda configuration and that can also be useful

694
01:05:28,040 --> 01:05:32,040
okay and that's the motivation for using conda section which essentially we already talked about

695
01:05:32,040 --> 01:05:41,800
So yes. And a section about how to set up environment with CUDA, which we'll be talking

696
01:05:41,800 --> 01:05:50,840
about next. But essentially, I will do this by not that much looking at the documentation,

697
01:05:50,840 --> 01:05:56,920
which you can read yourself, but rather by just creating a new environment. So let's see how it

698
01:05:56,920 --> 01:06:03,800
goes. So, let's create a new environment file. And this time, I want to develop some

699
01:06:05,080 --> 01:06:10,840
language models, large language models with Python and PyTorch.

700
01:06:11,560 --> 01:06:19,000
So, to do that, I will create a new environment. Let's call it PyTorch.yml.

701
01:06:21,720 --> 01:06:24,760
And, again, the environment needs a name.

702
01:06:26,920 --> 01:06:35,800
So I'll call it PyTorch and we'll need to list some channels.

703
01:06:35,800 --> 01:06:44,160
So now we want NVIDIA as one of the channels because this environment will depend on CUDA

704
01:06:44,160 --> 01:06:50,680
and that comes from the NVIDIA channel or some CUDA-related packages come from there.

705
01:06:50,680 --> 01:06:55,560
We'll also want to use CoinderForge. That is almost always there.

706
01:06:57,000 --> 01:07:05,080
And then list the dependencies. Dependencies. It is correct, I think. Yes. Okay.

707
01:07:08,840 --> 01:07:13,240
We will definitely need Python, and I want to specify the version of Python,

708
01:07:13,240 --> 01:07:19,000
because if you – it's actually missing a dash here, a minus sign there.

709
01:07:20,760 --> 01:07:25,960
So if you don't specify, it will probably – well, it will first of all try to check all different

710
01:07:25,960 --> 01:07:34,760
Python versions or possible PyTorch packages. And that will take a long time. Not as long as

711
01:07:34,760 --> 01:07:41,480
installing PyTorch, but still. So that's one reason. But also, it will probably actually try

712
01:07:41,480 --> 01:07:50,120
Python 3.13 and then just fail because I think some of the packages don't exist for Python 3.13.

713
01:07:51,160 --> 01:07:56,200
I'm not sure why it doesn't figure it out before it tries to install, but there's something there,

714
01:07:57,880 --> 01:08:01,160
some configuration issue somewhere there in the packages.

715
01:08:03,320 --> 01:08:07,320
Might actually be useful to just demonstrate what a failure looks like, right?

716
01:08:07,320 --> 01:08:15,420
Okay, well, actually, that will come, so let's see.

717
01:08:15,420 --> 01:08:26,520
So we want PyTorch GPU, and I'll just specify larger than 2.6, less than 2.7, mostly just

718
01:08:26,520 --> 01:08:31,920
to show the syntax, but also because I don't remember the exact version.

719
01:08:31,920 --> 01:08:34,680
I didn't write it down in the notes on purpose.

720
01:08:34,680 --> 01:08:43,800
So TorchVision, this is often useful if you are dealing with image models.

721
01:08:43,800 --> 01:08:47,680
Let's do TorchAudio as well.

722
01:08:47,680 --> 01:08:52,780
Just commonly installed in the PyTorch environment, although if I'm using large language models,

723
01:08:52,780 --> 01:08:54,440
maybe I don't need them.

724
01:08:54,440 --> 01:08:57,640
But I do need definitely these transformers.

725
01:08:57,640 --> 01:08:59,080
Okay.

726
01:08:59,080 --> 01:09:05,560
So there's some useful packages for machine learning stuff.

727
01:09:05,560 --> 01:09:11,080
And let's save this file and show what's in there.

728
01:09:11,080 --> 01:09:12,300
Okay.

729
01:09:12,300 --> 01:09:17,940
And then let's see how long it takes to construct the environment.

730
01:09:17,940 --> 01:09:26,060
So mambaenv create and use the PyTorch file.

731
01:09:26,060 --> 01:09:31,740
The first thing it does is it recognizes that I'm on a Linux system. It can also use no-arch

732
01:09:32,380 --> 01:09:40,060
version, so no architecture or system-independent packages, and then it's looking for specifically

733
01:09:40,940 --> 01:09:47,580
system packages and dependencies that work on Linux to get all of these dependencies.

734
01:09:47,580 --> 01:09:57,580
Okay, so we have a critical issue.

735
01:09:57,580 --> 01:10:01,580
I almost transitioned to the nodes, but not quite.

736
01:10:01,580 --> 01:10:08,580
So the problem here is that it doesn't find CUDA.

737
01:10:08,580 --> 01:10:13,580
And it doesn't find CUDA because we don't actually have any GPUs

738
01:10:13,580 --> 01:10:18,420
on the login node.

739
01:10:18,420 --> 01:10:21,900
So there are nodes on Triton that have GPUs,

740
01:10:21,900 --> 01:10:23,900
but on almost any HPC system,

741
01:10:23,900 --> 01:10:26,460
you're not gonna have GPUs on the login node.

742
01:10:26,460 --> 01:10:31,460
So that is confusing, Mamba, yeah.

743
01:10:33,700 --> 01:10:35,860
And it's thinking that you're trying to install

744
01:10:35,860 --> 01:10:38,940
some GPU dependent stuff on a system that doesn't have them.

745
01:10:38,940 --> 01:10:41,540
I mean, technically it is correct about that,

746
01:10:41,540 --> 01:10:44,180
But I still do want to install this environment that

747
01:10:44,180 --> 01:10:48,340
depends on GPUs existing in the system.

748
01:10:48,340 --> 01:10:54,380
So we can override the CUDA version

749
01:10:54,380 --> 01:10:58,020
and just tell it that we have CUDA 12.6.

750
01:10:58,020 --> 01:11:06,740
So that is also mentioned here in the notes here.

751
01:11:06,740 --> 01:11:09,620
So we export that, and then we try again.

752
01:11:09,620 --> 01:11:12,740
So mamba and create pytorch.yaml.

753
01:11:12,740 --> 01:11:15,740
Okay, so this version of the command worked yesterday,

754
01:11:15,740 --> 01:11:16,580
so we'll see.

755
01:11:19,740 --> 01:11:22,260
It's always possible that some library got updated

756
01:11:22,260 --> 01:11:23,620
and broken somehow.

757
01:11:25,020 --> 01:11:28,220
But while we wait, let's see if there's any

758
01:11:28,220 --> 01:11:30,660
other interesting questions in the notes

759
01:11:31,860 --> 01:11:33,820
or important questions.

760
01:11:33,820 --> 01:11:35,300
What are the channels?

761
01:11:35,300 --> 01:11:38,900
So yeah, I guess we went over this maybe a bit too quickly.

762
01:11:39,620 --> 01:11:44,220
But yeah, channels are repositories of packages.

763
01:11:44,220 --> 01:11:47,420
So they are servers somewhere that store all the packages

764
01:11:47,420 --> 01:11:48,460
that you might need.

765
01:11:48,460 --> 01:11:51,760
Well, all the packages that somebody has added to them.

766
01:11:51,760 --> 01:11:53,840
So conda-forge is one of them.

767
01:11:53,840 --> 01:11:58,840
And it says, it contains a lot of different packages

768
01:11:58,900 --> 01:12:02,860
that most things depend on.

769
01:12:02,860 --> 01:12:05,980
So conda-forge includes torch-vision here.

770
01:12:05,980 --> 01:12:10,420
I think `transformers` also comes from conda-forge.

771
01:12:10,420 --> 01:12:12,340
Does anything actually, there's also

772
01:12:12,340 --> 01:12:14,860
the NVIDIA channel that we included.

773
01:12:14,860 --> 01:12:17,180
Does anything actually come from there?

774
01:12:17,180 --> 01:12:23,220
Yes. Some libraries that have to do with CUDA and

775
01:12:23,220 --> 01:12:32,100
with NVIDIA GPU specifically are coming from the NVIDIA channel.

776
01:12:32,100 --> 01:12:43,140
So conda-forge is the big channel that has a lot of open source packages and most stuff comes from

777
01:12:43,140 --> 01:12:49,860
there. But Nvidia has things that Nvidia maintains. So this is a channel where Nvidia provides a

778
01:12:49,860 --> 01:12:55,940
bunch of packages and it's necessary for this environment. Okay, so let's run this to install

779
01:12:55,940 --> 01:13:05,300
the environment and this will take a while. It should succeed but the main point though is how

780
01:13:05,300 --> 01:13:14,500
to create the environment and how to use it and not actually finishing this download process

781
01:13:14,500 --> 01:13:20,580
where it gets all of the PyTorch and all of the system stuff. But yeah so it is actually now

782
01:13:20,580 --> 01:13:26,020
downloading this from the

783
01:13:26,020 --> 01:13:30,980
channel is where it's actually pulling all of these dependencies.

784
01:13:33,380 --> 01:13:37,780
If you have something cached, will it be faster?

785
01:13:37,780 --> 01:13:41,300
Yes, definitely. If you have a similar environment

786
01:13:41,300 --> 01:13:44,580
installed before, then it will be faster, right?

787
01:13:44,580 --> 01:13:51,380
And I think it will even slightly prefer cached versions if they exist, but also

788
01:13:53,860 --> 01:13:58,260
quite often when you create one environment and then you create another one with almost the same

789
01:13:58,260 --> 01:14:02,420
requirement, it will still end up using slightly different versions and redownload stuff.

790
01:14:03,300 --> 01:14:06,180
But yeah, in principle it does cache the packages.

791
01:14:06,180 --> 01:14:19,980
I think it also done some fancy system or fancy linking where it actually uses the same

792
01:14:19,980 --> 01:14:32,420
files in different environments if it just has the same exact same version of the package.

793
01:14:32,420 --> 01:14:45,860
Okay. I think it's almost done. And so is also our time. So, unless there's anything

794
01:14:45,860 --> 01:14:53,540
else, I guess we could move on to a break. I mean, showing that it works is kind of fun,

795
01:14:53,540 --> 01:15:02,340
but not necessarily worth the wait. So, what is next on the schedule?

796
01:15:02,340 --> 01:15:04,900
I think it's a break, or?

797
01:15:04,900 --> 01:15:05,400
Yes.

798
01:15:10,540 --> 01:15:14,500
Yeah, we have a short break.

799
01:15:14,500 --> 01:15:18,660
And then we get back to hands-on with, I think,

800
01:15:18,660 --> 01:15:23,740
it's Array Jobs, which is the start of Parallelism

801
01:15:23,740 --> 01:15:26,220
and the Power of the Cluster.

802
01:15:26,220 --> 01:15:32,300
OK, so I'll stick around and answer questions, of course.

803
01:15:32,300 --> 01:15:39,100
There's a number of questions coming up, so just keep them coming.

804
01:15:39,100 --> 01:15:45,260
So I guess, I guess we have a break until two minutes past the hour.

805
01:15:45,260 --> 01:15:56,180
So yes, there it is.

806
01:15:56,180 --> 01:15:57,180
See you later.

807
01:15:57,180 --> 01:15:58,180
Bye.

808
01:15:58,180 --> 01:15:59,180
See you.

809
01:15:59,180 --> 01:15:59,680
Bye.

810
01:16:02,300 --> 01:16:04,360
you

811
01:16:32,300 --> 01:16:34,360
you

812
01:17:02,300 --> 01:17:04,360
you

813
01:17:32,300 --> 01:17:34,360
you

814
01:18:02,300 --> 01:18:04,360
you

815
01:18:32,300 --> 01:18:34,360
you

816
01:19:02,300 --> 01:19:04,360
you

817
01:19:32,300 --> 01:19:34,360
you

818
01:20:02,300 --> 01:20:04,360
you

819
01:20:32,300 --> 01:20:34,360
you

820
01:21:02,300 --> 01:21:04,360
you

821
01:21:32,300 --> 01:21:34,360
you

822
01:22:02,300 --> 01:22:04,360
you

823
01:22:32,300 --> 01:22:34,360
you

824
01:23:02,300 --> 01:23:04,360
you

825
01:23:32,300 --> 01:23:34,360
you

826
01:24:02,300 --> 01:24:04,360
you

827
01:24:32,300 --> 01:24:34,360
you

828
01:25:02,300 --> 01:25:04,360
you

829
01:25:32,300 --> 01:25:34,360
you

830
01:26:02,300 --> 01:26:04,360
you

831
01:26:32,300 --> 01:26:34,360
you

832
01:27:02,300 --> 01:27:15,300
Hello.

833
01:27:15,300 --> 01:27:16,300
Welcome back.

834
01:27:16,300 --> 01:27:19,300
I hope you can hear us out there.

835
01:27:19,300 --> 01:27:21,300
Hello, hello.

836
01:27:21,300 --> 01:27:23,300
So, where are we now?

837
01:27:23,300 --> 01:27:24,300
What's going on?

838
01:27:24,300 --> 01:27:30,300
So, [name], can you let us know what's upcoming?

839
01:27:30,300 --> 01:27:40,580
Yeah, so we had great talks in the morning with [name] and [name] and [name], and now we

840
01:27:40,580 --> 01:27:44,700
are jumping back to where we left off yesterday.

841
01:27:44,700 --> 01:27:52,620
So yesterday we were writing stuff, we were running stuff in the queue, like we were testing

842
01:27:52,620 --> 01:28:06,540
stuff in the queue and we were testing out the submission scripts. So, we were trying out

843
01:28:06,540 --> 01:28:15,340
how we can write scripts that can be run in the queue. So, they can be run like we can submit

844
01:28:15,340 --> 01:28:20,140
them to the queue and the queue will run them later on. So, that was the thing that we were

845
01:28:20,140 --> 01:28:28,780
doing yesterday. And now we are going to get further in our users of the cluster because

846
01:28:28,780 --> 01:28:34,460
we don't only want to do one thing usually, we want to do a lot of things. So that's why we want

847
01:28:36,940 --> 01:28:43,180
to make it so that we can run a lot of stuff. So that involves parallelism. And the parallel

848
01:28:43,180 --> 01:28:47,100
is like the whole thing about this day.

849
01:28:47,100 --> 01:28:49,740
So we'll first talk a bit about different ways

850
01:28:49,740 --> 01:28:51,940
of doing stuff in parallel in cluster,

851
01:28:51,940 --> 01:28:54,300
because we have a lot of computers in the cluster

852
01:28:54,300 --> 01:28:58,180
and we want to use as much as we can

853
01:28:58,180 --> 01:29:00,420
to get all of our stuff done.

854
01:29:00,420 --> 01:29:03,300
And we'll talk about the different ways you can do it.

855
01:29:03,300 --> 01:29:08,300
And then we'll tackle three of those four ways today.

856
01:29:10,140 --> 01:29:12,100
So we'll talk about array jobs,

857
01:29:12,100 --> 01:29:15,980
then we'll talk about a shared memory parallelism and then

858
01:29:15,980 --> 01:29:17,900
MPI jobs.

859
01:29:17,900 --> 01:29:18,940
And that's about it.

860
01:29:18,940 --> 01:29:22,780
And we'll do some exercises on those.

861
01:29:22,780 --> 01:29:24,860
OK, great.

862
01:29:24,860 --> 01:29:28,500
So I guess I'll switch to my screen.

863
01:29:28,500 --> 01:29:36,660
And so what now?

864
01:29:36,660 --> 01:29:38,220
Where do we start?

865
01:29:38,220 --> 01:29:40,820
So let's first look at, if you want

866
01:29:40,820 --> 01:29:43,860
Let's just show the serial jobs, what we were doing previously.

867
01:29:43,860 --> 01:29:48,940
Let's look at a diagram that might refresh us.

868
01:29:48,940 --> 01:29:56,500
So previously, we were writing these scripts, and we were doing also interactive runs, where

869
01:29:56,500 --> 01:30:00,020
we were running something in the compute nodes.

870
01:30:00,020 --> 01:30:06,260
And we were currently using only one computer, only one processor.

871
01:30:06,260 --> 01:30:10,260
And these are called serial jobs, because they do the commands in order.

872
01:30:10,260 --> 01:30:16,100
They run like a series of commands.

873
01:30:16,100 --> 01:30:21,820
Like we write one script and then we execute that in the cluster and it executes everything

874
01:30:21,820 --> 01:30:24,060
in order, like it does everything.

875
01:30:24,060 --> 01:30:25,940
And it uses one CPU currently.

876
01:30:25,940 --> 01:30:28,900
So we're taking only a small slice of the whole cluster.

877
01:30:28,900 --> 01:30:33,980
Like we are taking one CPU in one node and the whole cluster is a big thing.

878
01:30:33,980 --> 01:30:36,420
So we want to use more.

879
01:30:36,420 --> 01:30:43,100
And the first and the easiest way of doing this is usually to split up your job, what

880
01:30:43,100 --> 01:30:46,820
you're basically doing, split up what you're doing and do an array job.

881
01:30:46,820 --> 01:30:54,340
So maybe we could talk about the different parallelism modes and let's, we could maybe

882
01:30:54,340 --> 01:30:56,940
show a picture of an array job.

883
01:30:56,940 --> 01:30:57,940
Yeah.

884
01:30:57,940 --> 01:31:03,420
So I'm opening this, the parallel one from the schedule.

885
01:31:03,420 --> 01:31:05,480
I guess we're looking at these things.

886
01:31:05,480 --> 01:31:07,140
So let's go down.

887
01:31:07,140 --> 01:31:08,900
This is an Array Job.

888
01:31:08,900 --> 01:31:11,740
So what's the characteristic here?

889
01:31:11,740 --> 01:31:17,100
So the idea behind Array Job is basically like, let's say you have a script that describes

890
01:31:17,100 --> 01:31:22,380
what you want to do, but you want to do it with multiple data sets, or you want to do

891
01:31:22,380 --> 01:31:30,200
it with multiple different random numbers, or you want to do it with different options,

892
01:31:30,200 --> 01:31:31,380
different startup options.

893
01:31:31,380 --> 01:31:35,140
You want to have different parameters for your model or something.

894
01:31:35,140 --> 01:31:40,300
But they're basically the same thing, but there's something that changes.

895
01:31:40,300 --> 01:31:43,340
And you want to do the same thing.

896
01:31:43,340 --> 01:31:47,620
So we take the big problem, you make it a bunch of small problems, and each small problem

897
01:31:47,620 --> 01:31:49,660
is only slightly different.

898
01:31:49,660 --> 01:31:57,260
And you can basically load up every small available place on the cluster.

899
01:31:57,260 --> 01:32:02,660
You get independent jobs, and it's often called embarrassingly parallel, not because it's

900
01:32:02,660 --> 01:32:06,260
not embarrassing to use it, but it's because it's so easy to parallelize.

901
01:32:08,660 --> 01:32:15,540
Previously, we had the HPC kitchen metaphor, and we talked about CPUs being like stove top

902
01:32:15,540 --> 01:32:20,260
burners. So if you put two kettles in two different burners, they're independent of each

903
01:32:20,260 --> 01:32:28,580
other. They're not interacting, but you can cook two pasta varieties in different pots,

904
01:32:28,580 --> 01:32:34,820
And they work independently of each other in independent learners. So this is basically

905
01:32:34,820 --> 01:32:41,380
the idea. So the array jobs are spread out throughout the cluster. And there's this nice

906
01:32:41,380 --> 01:32:49,620
syntax that you can use to easily create even a large array job of, let's say, 100 jobs running

907
01:32:49,620 --> 01:32:57,380
at the same time. And each of them works independently. Okay. So we're not doing it now,

908
01:32:57,380 --> 01:33:01,060
but should we preview the things we'll do? Is it the end of the day?

909
01:33:01,940 --> 01:33:08,900
Yes. So the other methods that we're going to be talking about are a bit more involved. And the

910
01:33:08,900 --> 01:33:13,780
first one of these is shared memory parallelism. And this is basically what your laptop is doing

911
01:33:13,780 --> 01:33:22,580
right now, or your computer. You have multiple processors in your computer, but it's all inside

912
01:33:22,580 --> 01:33:29,380
this one computer, right? Like you don't have other computer there like connected to that.

913
01:33:29,380 --> 01:33:35,620
You only have one computer, but it has multiple processors. So you can, if you have a problem

914
01:33:35,620 --> 01:33:43,140
that way, it suits the problem. You can use multiple processors in the same machine

915
01:33:43,140 --> 01:33:49,540
to calculate something faster. So this is like, this just usually makes calculations faster if

916
01:33:49,540 --> 01:33:51,380
if your program supports it.

917
01:33:51,380 --> 01:33:56,380
Yeah, and I guess this is relatively easy to do.

918
01:33:56,820 --> 01:34:00,840
Yeah, so your job ends up in one of the computers

919
01:34:00,840 --> 01:34:04,940
and then you can have multiple processors

920
01:34:04,940 --> 01:34:08,100
working together to solve a bigger problem.

921
01:34:08,100 --> 01:34:11,340
And this is like, it's of course limited

922
01:34:11,340 --> 01:34:13,060
by the size of the computer

923
01:34:13,060 --> 01:34:15,340
that you're going to be using or getting,

924
01:34:15,340 --> 01:34:17,980
but this is something that we'll be talking

925
01:34:17,980 --> 01:34:19,740
in more detail later on.

926
01:34:19,740 --> 01:34:20,580
Yeah.

927
01:34:20,580 --> 01:34:21,540
Okay.

928
01:34:21,540 --> 01:34:26,540
And finally we have the shared or

929
01:34:27,740 --> 01:34:29,140
We have MPI jobs.

930
01:34:29,140 --> 01:34:30,540
Message passing.

931
01:34:30,540 --> 01:34:32,100
Yeah. So message passing jobs.

932
01:34:32,100 --> 01:34:35,140
So, so this is like the traditional

933
01:34:35,140 --> 01:34:37,540
high performance computing, like supercomputing.

934
01:34:37,540 --> 01:34:40,360
If you think about like big weather models or whatever

935
01:34:40,360 --> 01:34:42,940
they often use, or most often use

936
01:34:42,940 --> 01:34:44,860
this message passing interface,

937
01:34:44,860 --> 01:34:48,900
which is like this standard that has been created

938
01:34:48,900 --> 01:34:51,300
since the 90s or something like that,

939
01:34:51,300 --> 01:34:55,780
that makes it possible for a lot of different processors

940
01:34:55,780 --> 01:34:59,140
in different computers to know about each other

941
01:34:59,140 --> 01:35:01,980
and talk with each other to solve a really big problem.

942
01:35:01,980 --> 01:35:05,020
So it can, you can utilize multiple computers

943
01:35:05,020 --> 01:35:09,300
at the same time, and you need to, you can, you can,

944
01:35:09,300 --> 01:35:11,820
like each of these can communicate with each other,

945
01:35:11,820 --> 01:35:14,100
but this is a bit more involved

946
01:35:14,100 --> 01:35:17,200
and it's specific for programs that use this.

947
01:35:17,200 --> 01:35:19,100
So we'll talk about this later,

948
01:35:19,100 --> 01:35:22,380
but nowadays I think vast majority of problems

949
01:35:22,380 --> 01:35:27,380
are Array Jobs or like vast majority of parallelism

950
01:35:28,500 --> 01:35:31,140
is nowadays Array Jobs or shared memory,

951
01:35:31,140 --> 01:35:35,680
but in the big clusters, the MPI is still a very big thing.

952
01:35:35,680 --> 01:35:36,820
Right, yeah.

953
01:35:36,820 --> 01:35:40,240
Okay, so should we get started with Array Jobs then?

954
01:35:40,240 --> 01:35:41,080
Yeah.

955
01:35:41,080 --> 01:35:46,800
I'll close this window and let's go pin array jobs.

956
01:35:46,800 --> 01:35:54,900
Yes. We're going to be demoing few of the array jobs,

957
01:35:54,900 --> 01:35:57,080
and we're going to contrast them

958
01:35:57,080 --> 01:36:01,420
with the serial job that we did yesterday.

959
01:36:01,420 --> 01:36:07,540
If you didn't manage to do it yesterday or if you weren't here,

960
01:36:07,540 --> 01:36:12,820
There's instructions in the notes on how you can bring yourself up to speed.

961
01:36:12,820 --> 01:36:18,420
So basically how you can download the example data set and the examples repository.

962
01:36:18,420 --> 01:36:25,260
And there's an example like solution script for the CDL job script, so that we can like

963
01:36:25,260 --> 01:36:27,620
then compare the results.

964
01:36:27,620 --> 01:36:28,620
Yeah.

965
01:36:28,620 --> 01:36:29,620
Okay.

966
01:36:29,620 --> 01:36:35,780
So, since I didn't do the typing yesterday, I've set up where I've walked into the cluster

967
01:36:35,780 --> 01:36:40,240
and I've copied the data to my personal work directory

968
01:36:40,240 --> 01:36:43,560
in a Gutenberg Fiction folder, just like before.

969
01:36:43,560 --> 01:36:47,120
So hopefully, it will be pretty similar to what

970
01:36:47,120 --> 01:36:50,520
we did yesterday.

971
01:36:50,520 --> 01:36:52,840
We're in a fairly similar place.

972
01:36:55,840 --> 01:36:58,960
Yeah, so I guess the first thing I'll do when I've logged in,

973
01:36:58,960 --> 01:37:00,440
I want to see where we are.

974
01:37:00,440 --> 01:37:04,600
So I type `pwd`, and I'm in my home directory.

975
01:37:04,600 --> 01:37:08,040
And I know I need to go to the same place I was yesterday,

976
01:37:08,040 --> 01:37:11,160
which is the HPC examples directory. So I'll change there.

977
01:37:13,160 --> 01:37:18,200
Yeah. It's always a good idea to go to the work directory whenever you go to the cluster.

978
01:37:18,200 --> 01:37:23,320
Yeah. And verify where you are before you start running commands.

979
01:37:23,320 --> 01:37:26,280
Yeah. It's a small but important thing.

980
01:37:26,280 --> 01:37:28,520
OK, so here we are.

981
01:37:28,520 --> 01:37:35,080
So do we have the do you have the previous script there?

982
01:37:35,080 --> 01:37:36,080
The previous?

983
01:37:36,080 --> 01:37:37,080
No.

984
01:37:37,080 --> 01:37:38,080
Maybe let's go over.

985
01:37:38,080 --> 01:37:39,080
Well, let's.

986
01:37:39,080 --> 01:37:40,080
Well, then.

987
01:37:40,080 --> 01:37:41,080
Yeah, let's.

988
01:37:41,080 --> 01:37:42,080
We can.

989
01:37:42,080 --> 01:37:43,840
I can copy it from the notes here.

990
01:37:43,840 --> 01:37:44,840
If you'd like.

991
01:37:44,840 --> 01:37:45,840
Yeah, let's.

992
01:37:45,840 --> 01:37:47,320
Yeah, let's do that.

993
01:37:47,320 --> 01:37:49,640
So nano.

994
01:37:49,640 --> 01:37:50,640
What was it called?

995
01:37:50,640 --> 01:37:53,640
count-ngrams-2.sh

996
01:37:53,640 --> 01:37:54,640
Yes.

997
01:37:54,640 --> 01:37:57,840
Yes. And I'll just put it in this directory, I guess.

998
01:37:58,720 --> 01:38:03,120
So, do you want to remind us what these things are as I type them?

999
01:38:03,120 --> 01:38:12,640
Yes. So, there's the first line is the is the shebang or that tells which like it's the magic

1000
01:38:12,640 --> 01:38:21,280
that runs everything with the terminal. I think our pictures are a bit cutting off the terminals.

1001
01:38:21,280 --> 01:38:32,400
Yes, and then we need to tell the queue system what were the requirements that we want, what

1002
01:38:32,400 --> 01:38:39,960
memory we want, what time we want, and then we need to tell what we want to actually run.

1003
01:38:39,960 --> 01:38:42,000
In this case, it was the n-grams.

1004
01:38:42,000 --> 01:38:53,780
We took the two grams, so every two-word pair, and we wanted to get those calculated.

1005
01:38:53,780 --> 01:39:07,600
And we gave it the folder of where we had the dataset downloaded and part of the dataset

1006
01:39:07,600 --> 01:39:11,000
that we wanted to analyze.

1007
01:39:11,000 --> 01:39:17,520
And you can use, [name] is using this backslash syntax.

1008
01:39:17,520 --> 01:39:23,120
So if you put, as the last character, you put this backslash, you can continue from

1009
01:39:23,120 --> 01:39:24,120
the next line.

1010
01:39:24,120 --> 01:39:31,000
So basically, it means that just continue, combine these together so that you can fit

1011
01:39:31,000 --> 01:39:34,480
more stuff into the, without wrapping.

1012
01:39:34,480 --> 01:39:37,840
And make sure it's the very last line.

1013
01:39:37,840 --> 01:39:40,840
Should I run this just to make sure that it actually works?

1014
01:39:40,840 --> 01:39:41,840
Yeah, let's do that.

1015
01:39:41,840 --> 01:39:44,840
So I do Control-X to exit.

1016
01:39:44,840 --> 01:39:47,840
Y, yes.

1017
01:39:47,840 --> 01:39:49,840
Yeah.

1018
01:39:49,840 --> 01:39:54,840
So now [name] is checking that it's in the queue.

1019
01:39:54,840 --> 01:39:56,840
So it is running.

1020
01:39:56,840 --> 01:39:58,840
It's the last one over there.

1021
01:39:58,840 --> 01:39:59,840
Yeah.

1022
01:39:59,840 --> 01:40:04,840
So it is running, and then it probably finishes quite quickly.

1023
01:40:04,840 --> 01:40:06,840
Yeah, it takes a minute to run.

1024
01:40:06,840 --> 01:40:13,960
But now the question is that, okay, like this is quite a simple program, but let's imagine

1025
01:40:13,960 --> 01:40:16,720
that our data would be a lot bigger.

1026
01:40:16,720 --> 01:40:22,500
So let's imagine that we would have a lot bigger of a data set.

1027
01:40:22,500 --> 01:40:30,980
So in that case, we might want to do these calculations of these n-grams in, or like

1028
01:40:30,980 --> 01:40:34,200
we would want to do it in pieces, right?

1029
01:40:34,200 --> 01:40:39,000
Like, we don't necessarily want to have one job that does everything.

1030
01:40:39,000 --> 01:40:46,760
We could do it so that, like, every job, like, we could split it up, the program, so that

1031
01:40:46,760 --> 01:40:55,720
every, we could split it up to, let's say, ten programs, that each program would do

1032
01:40:55,720 --> 01:40:59,040
one-tenth of the analysis.

1033
01:40:59,040 --> 01:41:03,560
So are you roughly saying we have 100 books in this sample data?

1034
01:41:03,560 --> 01:41:10,080
So we'll have one program do 10 books, the next do 10 more books, and so on.

1035
01:41:10,080 --> 01:41:15,780
We can run 10 things at the same time, and then I guess that means we get 10 different

1036
01:41:15,780 --> 01:41:16,780
output files?

1037
01:41:16,780 --> 01:41:17,780
Yes.

1038
01:41:17,780 --> 01:41:18,780
That have to be combined?

1039
01:41:18,780 --> 01:41:23,240
But it can in theory run 10 times as fast.

1040
01:41:23,240 --> 01:41:24,240
Yes.

1041
01:41:24,240 --> 01:41:27,820
And that's very, very well put.

1042
01:41:27,820 --> 01:41:35,900
And for this, we can use like the program, the ngrams program, it supports these start

1043
01:41:35,900 --> 01:41:38,260
and step functions.

1044
01:41:38,260 --> 01:41:44,320
So you can decide, you can tell it that, hey, I want you to take every 10th book.

1045
01:41:44,320 --> 01:41:48,100
I want you to start from a certain number.

1046
01:41:48,100 --> 01:41:51,180
So we can modify the count ngrams to code.

1047
01:41:51,180 --> 01:41:59,780
So if we make a copy of it into, let's call it an array, count n-grams, and not the output,

1048
01:41:59,780 --> 01:42:00,780
but the count n-grams.

1049
01:42:00,780 --> 01:42:01,780
Oh, yeah, not the output.

1050
01:42:01,780 --> 01:42:02,780
SH.

1051
01:42:02,780 --> 01:42:03,780
So this is not good.

1052
01:42:03,780 --> 01:42:04,780
Oh, yeah.

1053
01:42:04,780 --> 01:42:05,780
Wait.

1054
01:42:05,780 --> 01:42:06,780
Yeah, yeah.

1055
01:42:06,780 --> 01:42:07,780
Yes.

1056
01:42:07,780 --> 01:42:19,340
So let's modify the code a bit, and let's try to like split it up, split it up the work

1057
01:42:19,340 --> 01:42:23,740
to multiple workers.

1058
01:42:23,740 --> 01:42:27,420
So if you look at now the array script.

1059
01:42:27,420 --> 01:42:29,140
Yeah, OK.

1060
01:42:29,140 --> 01:42:32,260
So we can do small additions here.

1061
01:42:32,260 --> 01:42:34,540
Yeah, so we can do small additions here

1062
01:42:34,540 --> 01:42:41,740
that make it so that we can split it up.

1063
01:42:41,740 --> 01:42:45,780
So the first important thing about the array thing

1064
01:42:45,780 --> 01:42:48,900
is that when you want to submit an array job,

1065
01:42:48,900 --> 01:43:00,740
you add this `sbatch` and then `--array`, and then let's say it's from zero to nine [`--array=0-9`].

1066
01:43:02,260 --> 01:43:07,540
And what this syntax, this looks a bit interesting, but what this syntax tells

1067
01:43:07,540 --> 01:43:12,260
the queue system, like the queue system will read this comment and it will recognize that,

1068
01:43:12,260 --> 01:43:17,420
Hey, the user wants me to create 10 copies basically from zero to nine.

1069
01:43:17,420 --> 01:43:17,700
Right.

1070
01:43:18,180 --> 01:43:22,340
And it wants me to create 10 copies of the same job.

1071
01:43:22,980 --> 01:43:26,940
All of those jobs are independent and all of those get the same requirements.

1072
01:43:26,980 --> 01:43:30,660
So it's not like additive, you don't get like 10 gigabytes, so you don't need

1073
01:43:30,660 --> 01:43:33,660
to modify the requirements in a way.

1074
01:43:33,660 --> 01:43:38,380
Of course, like in this case, like, like some of, like if we split up a big

1075
01:43:38,380 --> 01:43:45,980
program. Each of those might have less requirements to do, but that's not necessarily

1076
01:43:45,980 --> 01:43:48,700
something we need to think about. We're not thinking about that now.

1077
01:43:50,220 --> 01:43:55,580
Basically, we're running 10 identical copies here, but if we don't do any modifications to the

1078
01:43:55,580 --> 01:44:01,980
running part of the code, like the Python call, we are going to be running the same thing 10 times,

1079
01:44:01,980 --> 01:44:08,860
and that's no fun. That's a waste of resources. Hopefully it's exactly the same ten times. Yes.

1080
01:44:10,460 --> 01:44:17,580
But instead what we can do is we can like this program supports a different starting point.

1081
01:44:17,580 --> 01:44:24,780
So we can use a different starting point for like which book we want to analyze.

1082
01:44:24,780 --> 01:44:36,500
So, if we add here, that's the start, and then we put there a magical environment variable.

1083
01:44:36,500 --> 01:44:41,980
So, in Terminal, you can have these environment variables that are like something that will

1084
01:44:41,980 --> 01:44:42,980
be filled later.

1085
01:44:42,980 --> 01:44:45,860
It's just a variable that will be filled later.

1086
01:44:45,860 --> 01:44:53,140
And for the array, it's called `$SLURM_ARRAY_TASK_ID` with underscores and all capital letters.

1087
01:44:53,140 --> 01:44:55,940
So it's very important that it's written correctly.

1088
01:44:55,940 --> 01:44:57,540
Exactly like this, I guess.

1089
01:44:57,540 --> 01:44:58,660
Yeah, exactly like that.

1090
01:44:58,660 --> 01:45:02,820
But once you have written it out loud a few times,

1091
01:45:02,820 --> 01:45:09,940
you will remember it and it will become more natural.

1092
01:45:09,940 --> 01:45:10,740
And what this...

1093
01:45:10,740 --> 01:45:13,140
Like for me, even every time I do that,

1094
01:45:13,140 --> 01:45:15,380
I almost always look at a reference

1095
01:45:15,380 --> 01:45:17,140
just to make sure I'm spelling it right.

1096
01:45:17,140 --> 01:45:19,940
So don't be afraid there.

1097
01:45:19,940 --> 01:45:29,060
Okay, so this means it starts and `$SLURM_ARRAY_TASK_ID` becomes the numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, 9,

1098
01:45:29,060 --> 01:45:42,820
I guess. Yes. So, when we submit the array job, we will get a number for each of these

1099
01:45:42,820 --> 01:45:51,540
these array tasks. So, we get a number. So, the number, well, that's a task ID running

1100
01:45:51,540 --> 01:45:58,700
based on what are the numbers we are giving in the array, like lying over there, the Sbatch

1101
01:45:58,700 --> 01:46:05,420
array. And each of them gets a different one. So, what we do with those numbers is

1102
01:46:05,420 --> 01:46:12,060
up to us. And that's the beauty and the complexity of the array jobs, that we can map this number

1103
01:46:12,060 --> 01:46:18,860
to any sort of like parameter values, we can map it into datasets. You can do whatever you want

1104
01:46:18,860 --> 01:46:24,140
with this number, as long as you map it to something different for each job. There's many

1105
01:46:24,140 --> 01:46:31,660
examples in the ArrayJobs tutorial page of different kinds of structures you can use

1106
01:46:31,660 --> 01:46:38,540
to map this into different things. Yeah, and I guess if the program didn't support the start

1107
01:46:38,540 --> 01:46:43,660
option, it wouldn't be easy to do this with arrays. You'd have to somehow add it yourself.

1108
01:46:44,780 --> 01:46:50,380
Yes, quite often you want to implement this sort of functionality in your code. Like,

1109
01:46:50,380 --> 01:46:55,900
if you know that you are planning on using the code for, let's say, running a hundred different

1110
01:46:55,900 --> 01:47:03,420
things, you might want to implement in your code functionality where it can take a number and,

1111
01:47:03,420 --> 01:47:09,340
based on that number do something different. Yeah, but so is there anything else we need to do

1112
01:47:09,340 --> 01:47:15,740
for this then? So we need to like currently we are setting up a starting point but we are not

1113
01:47:15,740 --> 01:47:23,500
setting up a stepping like stride. So if we would only have the starting point we would

1114
01:47:23,500 --> 01:47:27,900
like everyone would start at a different number that but then they would analyze all of the rest

1115
01:47:27,900 --> 01:47:36,940
as normal. So, we need to set this step over here to be 10. So, everyone takes, or in every 10th

1116
01:47:36,940 --> 01:47:45,020
book. So, zero, yeah, like Riks is writing, we get numbers like that. And then 1, 11.

1117
01:47:45,020 --> 01:47:55,980
1, 11, 21, and so forth, 91, I guess.

1118
01:47:55,980 --> 01:47:56,500
Yes.

1119
01:47:56,500 --> 01:47:59,460
And this, so when we made this program,

1120
01:47:59,460 --> 01:48:02,780
this is basically like the Python array slicing.

1121
01:48:02,780 --> 01:48:04,700
So you give a start and a step.

1122
01:48:04,700 --> 01:48:07,620
And I think you could also give a stop there.

1123
01:48:07,620 --> 01:48:12,660
So it's, well, if you know the Python syntax,

1124
01:48:12,660 --> 01:48:13,900
it looks familiar.

1125
01:48:13,900 --> 01:48:19,120
If not, well, that doesn't really matter.

1126
01:48:19,120 --> 01:48:26,360
And yeah, but we could try out submitting this

1127
01:48:26,360 --> 01:48:28,680
and see what happens.

1128
01:48:28,680 --> 01:48:30,760
Should we adjust the output?

1129
01:48:30,760 --> 01:48:33,720
Because it looks like it will be writing.

1130
01:48:33,720 --> 01:48:35,360
Yes, great point.

1131
01:48:35,360 --> 01:48:36,400
I almost forgot.

1132
01:48:36,400 --> 01:48:41,440
So if we wouldn't change the output,

1133
01:48:41,440 --> 01:48:51,440
everyone would be writing into the same file. So, instead, let's call it `ngrams2` and then

1134
01:48:51,440 --> 01:49:04,440
then `-array` and then `_$SLURM_ARRAY_TASK_ID` [so `ngrams2-array_$SLURM_ARRAY_TASK_ID`].

1135
01:49:04,440 --> 01:49:13,160
So now, because all of these programs will run independently, all of them need to have

1136
01:49:13,160 --> 01:49:15,840
an independent output as well.

1137
01:49:15,840 --> 01:49:19,360
So yes, we want them to write to different files.

1138
01:49:19,360 --> 01:49:24,840
And again, the SlurmArrayTaskID will be filled when the code is actually running.

1139
01:49:24,840 --> 01:49:30,400
So it's based on the array number that it gets.

1140
01:49:30,400 --> 01:49:32,680
Now I think we are ready.

1141
01:49:32,680 --> 01:49:33,680
Okay.

1142
01:49:33,680 --> 01:49:34,680
Yeah.

1143
01:49:34,680 --> 01:49:36,720
So I exit and save.

1144
01:49:36,720 --> 01:49:38,600
Do we trust it works?

1145
01:49:38,600 --> 01:49:42,600
I think it's going to be fine.

1146
01:49:42,600 --> 01:49:43,600
It looks good to me.

1147
01:49:43,600 --> 01:49:44,600
So let's hope.

1148
01:49:44,600 --> 01:49:52,920
Yeah, `sbatch count-ngams-2-array.sh. And if you now look at the queue, what does this queue say?

1149
01:49:54,600 --> 01:50:04,200
So, we see, yeah, we see that we have now this weird job ID for the job. So, what that means

1150
01:50:06,040 --> 01:50:14,200
is that, maybe you can try running it again and trying it again with the scheme.

1151
01:50:14,600 --> 01:50:25,600
But this structure means that we get the same job, but with basically 10 copies of it.

1152
01:50:25,600 --> 01:50:34,920
And we have only one ID for the whole average.

1153
01:50:34,920 --> 01:50:40,000
And this makes it easier for the queue system to also understand, okay, now we have the

1154
01:50:40,000 --> 01:50:42,120
same thing, but 10 times.

1155
01:50:42,120 --> 01:50:45,960
And now we see like how it looks actually in the queue.

1156
01:50:45,960 --> 01:50:54,640
So once the resources are, yeah, once the resources are reserved, we get these array

1157
01:50:54,640 --> 01:50:59,400
jobs running and each one gets a different ID.

1158
01:50:59,400 --> 01:51:04,340
And you notice that some of them are running in completely different machines, or most

1159
01:51:04,340 --> 01:51:09,560
of them are running in completely different machines because they are independent, right?

1160
01:51:09,560 --> 01:51:14,840
all of these are independent and they would be running independently of each other. So let's

1161
01:51:14,840 --> 01:51:22,200
look at the output. Did it crash or did we get anything in the output files? Oh, there's a lot

1162
01:51:22,200 --> 01:51:31,480
of output. I see this output is doubled here. Should we look at what should we look at? Let's

1163
01:51:31,480 --> 01:51:37,560
look at the ngrams output first. Let's verify that it worked correctly. So we get a lot of

1164
01:51:37,560 --> 01:51:49,240
output over here. Yeah, and it looks 7000. So, that's about one tenth of what was there before,

1165
01:51:49,240 --> 01:52:00,120
I think. If we look at number one. Sure. Yeah, okay. Yeah. So, what we get is we get independent

1166
01:52:00,120 --> 01:52:06,600
outputs from all of these, but we also get this slurm outputs as well. And by default, when you have

1167
01:52:06,600 --> 01:52:15,880
this array structure, you have the slurm, it's called slurm, and then you have the job ID and

1168
01:52:15,880 --> 01:52:22,520
the array task ID after that. And again, it captures all of the output from each array job.

1169
01:52:22,520 --> 01:52:27,720
So let's say you need to do some analysis a hundred times, and each one takes an hour or

1170
01:52:27,720 --> 01:52:34,040
something, and one of them crashes. You can look at the outputs and see that, okay, that one crashed,

1171
01:52:34,040 --> 01:52:38,120
what was the problem with that one, and then you can figure out that, okay, maybe there's

1172
01:52:38,120 --> 01:52:44,280
like a corrupted data or something. But each one is independent, and each one gets an independent

1173
01:52:44,280 --> 01:52:54,360
output. Yeah. Maybe we should almost go to an exercise. Yes. Let's look at one of the outputs,

1174
01:52:54,360 --> 01:52:59,960
and let's then check the combined data, like what did we actually get what we wanted. So,

1175
01:52:59,960 --> 01:53:03,040
So if we look at one of the SLAM outputs.

1176
01:53:03,040 --> 01:53:06,240
The output of 0.

1177
01:53:06,240 --> 01:53:07,960
It says it found 100 files.

1178
01:53:07,960 --> 01:53:09,960
It didn't say which files it's processing.

1179
01:53:09,960 --> 01:53:10,560
Yeah.

1180
01:53:10,560 --> 01:53:13,160
Yes.

1181
01:53:13,160 --> 01:53:17,360
But it looks like it ran in about three seconds.

1182
01:53:17,360 --> 01:53:20,800
So each of these was very fast because now we're

1183
01:53:20,800 --> 01:53:23,320
splitting it into 10 parts.

1184
01:53:23,320 --> 01:53:28,880
But let's try combining the data together.

1185
01:53:28,880 --> 01:53:30,920
How do we do that?

1186
01:53:30,920 --> 01:53:36,760
So we do it by running combine counts.

1187
01:53:36,760 --> 01:53:37,840
Yes.

1188
01:53:37,840 --> 01:53:40,200
I'll run help first, and let's see what it says.

1189
01:53:40,200 --> 01:53:42,320
Yes.

1190
01:53:42,320 --> 01:53:45,560
So it needs the output count files,

1191
01:53:45,560 --> 01:53:47,560
and then it has an output file.

1192
01:53:47,560 --> 01:53:48,060
Yeah.

1193
01:53:51,160 --> 01:53:52,440
So we combine counts.

1194
01:53:52,440 --> 01:54:02,440
And don't worry, we'll post all of the commands that we're going to be running into the notes

1195
01:54:02,440 --> 01:54:07,880
in a second, so that you can try them out in the exercise.

1196
01:54:07,880 --> 01:54:12,800
So I guess this is how I'll run it, Python 3, the program name, and I can use an asterisk

1197
01:54:12,800 --> 01:54:20,120
to glob and capture everything that starts with this, which I know will be the 10 files

1198
01:54:20,120 --> 01:54:21,120
that are needed.

1199
01:54:21,120 --> 01:54:22,120
Yes.

1200
01:54:22,120 --> 01:54:23,520
And then you specify the output.

1201
01:54:23,520 --> 01:54:25,400
I saved it somewhere.

1202
01:54:25,400 --> 01:54:28,440
Yeah, you have the out and the ngrams.

1203
01:54:28,440 --> 01:54:30,280
Yeah, to array out.

1204
01:54:30,280 --> 01:54:33,600
That looks good.

1205
01:54:33,600 --> 01:54:34,280
Dot out.

1206
01:54:34,280 --> 01:54:35,480
Yeah, OK.

1207
01:54:35,480 --> 01:54:36,200
Dot out.

1208
01:54:42,440 --> 01:54:45,040
Takes a while to combine them.

1209
01:54:45,040 --> 01:54:45,540
Yeah.

1210
01:54:45,540 --> 01:54:52,380
So this is kind of like, yeah, this

1211
01:54:52,380 --> 01:54:55,260
is the kind of map-reduce kind of situation

1212
01:54:55,260 --> 01:54:59,900
where we map a lot of map the same functionality

1213
01:54:59,900 --> 01:55:03,340
onto different data, and then we reduce the results

1214
01:55:03,340 --> 01:55:05,580
into together.

1215
01:55:05,580 --> 01:55:08,340
So if you look at the output.

1216
01:55:08,340 --> 01:55:10,580
I can look.

1217
01:55:10,580 --> 01:55:14,340
Should we see if it looks the same as the non-array one?

1218
01:55:14,340 --> 01:55:16,140
So like 62,000.

1219
01:55:16,140 --> 01:55:19,820
Top number is 62,3.

1220
01:55:19,820 --> 01:55:25,180
And if we do array ngrams2.out, exactly the same,

1221
01:55:25,180 --> 01:55:27,940
at least the first number.

1222
01:55:27,940 --> 01:55:31,580
So this is a bit of, again, like a toy example.

1223
01:55:31,580 --> 01:55:34,980
But if we would have, let's say, the data would be a lot bigger,

1224
01:55:34,980 --> 01:55:40,180
then this would really speed up the execution.

1225
01:55:40,180 --> 01:55:42,940
And to use an imaging example, if we

1226
01:55:42,940 --> 01:55:51,020
have 100 brain images to process and they each take a few hours to do, we can do them in

1227
01:55:51,660 --> 01:56:00,780
parallel, even 100 times in parallel. Okay. And now let's go to exercises. So the exercises,

1228
01:56:01,340 --> 01:56:08,780
we'll post the commands that we just ran into the notes and you can create your own

1229
01:56:08,780 --> 01:56:17,260
ArrayScript, or you can already start writing it if you feel like doing that. And after that,

1230
01:56:17,820 --> 01:56:27,740
in the array examples, there are many examples. They use this py example, but there's many

1231
01:56:27,740 --> 01:56:36,940
examples of different ways you can choose the different array IDs in different ways.

1232
01:56:36,940 --> 01:56:40,420
And if you have more time, check out a few of those

1233
01:56:40,420 --> 01:56:45,100
and run a few of those examples and see what they do.

1234
01:56:45,100 --> 01:56:48,020
But yeah, let's go to the exercises.

1235
01:56:48,020 --> 01:56:52,180
And should we have about 20 minutes?

1236
01:56:52,180 --> 01:56:55,380
I guess that will start getting into the lunchtime a little

1237
01:56:55,380 --> 01:56:57,020
bit.

1238
01:56:57,020 --> 01:56:57,540
OK.

1239
01:56:57,540 --> 01:57:01,700
I guess we can go some people.

1240
01:57:01,700 --> 01:57:06,060
Or should we just combine the exercises with lunchtime

1241
01:57:06,060 --> 01:57:12,300
And then people can beat the cues of the places or whatever.

1242
01:57:12,300 --> 01:57:16,140
Maybe we'll have 50 minutes of exercise,

1243
01:57:16,140 --> 01:57:18,900
and then we'll talk about a few of the questions,

1244
01:57:18,900 --> 01:57:21,260
and then we'll return to it after lunch.

1245
01:57:21,260 --> 01:57:22,140
OK.

1246
01:57:22,140 --> 01:57:26,100
So 40, no, 50.

1247
01:57:26,100 --> 01:57:28,100
Well, yeah.

1248
01:57:28,100 --> 01:57:30,020
Let's go 55.

1249
01:57:30,020 --> 01:57:31,420
55, yeah.

1250
01:57:31,420 --> 01:57:34,060
And you can try some Ask Questions,

1251
01:57:34,060 --> 01:57:36,140
And there's more time during the lunch break.

1252
01:57:36,140 --> 01:57:37,820
So yeah.

1253
01:57:37,820 --> 01:57:38,580
OK.

1254
01:57:38,580 --> 01:57:41,900
And the task of people will be to do basically

1255
01:57:41,900 --> 01:57:44,820
what we've done here.

1256
01:57:44,820 --> 01:57:45,340
Yeah.

1257
01:57:45,340 --> 01:57:46,420
Is that the case?

1258
01:57:46,420 --> 01:57:46,940
OK.

1259
01:57:46,940 --> 01:57:50,500
And I think Sima will be pasting in commands and more detailed

1260
01:57:50,500 --> 01:57:53,180
instructions to the notes.

1261
01:57:53,180 --> 01:57:54,660
OK, great.

1262
01:57:54,660 --> 01:58:01,660
So see you in about 11 or 12 minutes.

1263
01:58:01,660 --> 01:58:02,740
OK, bye.

1264
01:58:02,740 --> 01:58:04,100
Yep. Bye.

1265
01:58:32,740 --> 01:58:34,800
you

1266
01:59:02,740 --> 01:59:04,800
you

1267
01:59:32,740 --> 01:59:34,800
you

1268
02:00:02,740 --> 02:00:04,800
you

1269
02:00:32,740 --> 02:00:34,800
you

1270
02:01:02,740 --> 02:01:04,800
you

1271
02:01:32,740 --> 02:01:34,800
you

1272
02:02:02,740 --> 02:02:04,800
you

1273
02:02:32,740 --> 02:02:34,800
you

1274
02:03:02,740 --> 02:03:04,800
you

1275
02:03:32,740 --> 02:03:34,800
you

1276
02:04:02,740 --> 02:04:04,800
you

1277
02:04:32,740 --> 02:04:34,800
you

1278
02:05:02,740 --> 02:05:04,800
you

1279
02:05:32,740 --> 02:05:34,800
you

1280
02:06:02,740 --> 02:06:04,800
you

1281
02:06:32,740 --> 02:06:34,800
you

1282
02:07:02,740 --> 02:07:04,800
you

1283
02:07:32,740 --> 02:07:34,800
you

1284
02:08:02,740 --> 02:08:04,800
you

1285
02:08:32,740 --> 02:08:34,800
you

1286
02:09:02,740 --> 02:09:04,800
you

1287
02:09:32,740 --> 02:09:34,800
you

1288
02:10:02,740 --> 02:10:31,740
Hello, we are back.

1289
02:10:31,740 --> 02:10:41,140
So, our plan now, I believe, is to go over some of the questions and stuff and then we

1290
02:10:41,140 --> 02:10:45,780
go to the lunch break and we can do one more array example after lunch.

1291
02:10:45,780 --> 02:10:57,780
So, which questions were most relevant here? There's some on best practices, like, oh,

1292
02:10:57,780 --> 02:11:01,940
Oh, yes, please, even for a reference or a future,

1293
02:11:01,940 --> 02:11:04,980
please let us know if you did the exercise,

1294
02:11:04,980 --> 02:11:09,300
weren't trying, or had some problems,

1295
02:11:09,300 --> 02:11:12,900
because this will help us plan for future years.

1296
02:11:12,900 --> 02:11:16,900
So yeah, so this is a good question here.

1297
02:11:16,900 --> 02:11:23,060
So if someone goes and makes an array job,

1298
02:11:23,060 --> 02:11:27,760
Like you run 1 million array jobs that each take 10 seconds.

1299
02:11:27,760 --> 02:11:30,520
That's not a very good thing, because it's

1300
02:11:30,520 --> 02:11:33,080
a lot of scheduling overhead to constantly be

1301
02:11:33,080 --> 02:11:36,560
finding these spaces, planning it, running it, stopping it,

1302
02:11:36,560 --> 02:11:38,040
and restarting it.

1303
02:11:38,040 --> 02:11:40,400
So that's sort of an extreme example.

1304
02:11:40,400 --> 02:11:43,080
But what's our rule of thumb?

1305
02:11:43,080 --> 02:11:46,840
Try to make the jobs at least 15 minutes, but if it can be longer.

1306
02:11:46,840 --> 02:11:50,320
Yeah, like usually we talk about half an hour or an hour

1307
02:11:50,320 --> 02:11:51,240
is better.

1308
02:11:51,240 --> 02:11:55,560
But yeah, it depends how in a hurry are you.

1309
02:11:55,560 --> 02:11:59,560
If you want to get most done, you usually want it to be, let's say, an hour.

1310
02:11:59,560 --> 02:12:03,240
If you want the results now, less than 15 minutes is fine.

1311
02:12:03,240 --> 02:12:08,840
But if you do, let's say, 100 jobs in less than 15 minutes, that's going to...

1312
02:12:09,560 --> 02:12:13,720
At some point, somebody will send you a mail of like, why like this?

1313
02:12:14,280 --> 02:12:17,240
Because it's not good for the queue.

1314
02:12:17,240 --> 02:12:25,920
The queue system doesn't like if there's a huge number of jobs happening that are very

1315
02:12:25,920 --> 02:12:26,920
small.

1316
02:12:26,920 --> 02:12:29,840
It doesn't usually like that.

1317
02:12:29,840 --> 02:12:35,880
And there was also a question in the chat, why not just use a bash script that submits

1318
02:12:35,880 --> 02:12:38,680
jobs or something like that.

1319
02:12:38,680 --> 02:12:45,560
And the reason behind that is the array structure is much better handled by the queue.

1320
02:12:45,560 --> 02:12:52,440
been designed for this sort of workflow. If you have a bash script that just submits stuff,

1321
02:12:52,440 --> 02:12:59,320
then each of these are independent and the queue cannot reuse the same information it gets from

1322
02:12:59,320 --> 02:13:06,200
all of the array types. So, it's not as good. So, please use the array structure instead.

1323
02:13:06,200 --> 02:13:13,480
And a good benefit with the array structure is that it's reproducible because you then know what

1324
02:13:13,480 --> 02:13:18,040
is the mapping between the array indices and the different things. And it's very easy to then look

1325
02:13:18,040 --> 02:13:24,920
at it later on and see that, okay, I run it with these array indices, so I get these results.

1326
02:13:26,280 --> 02:13:27,480
And there was also a question...

1327
02:13:27,480 --> 02:13:30,520
One of them fails, they don't all fail or something.

1328
02:13:30,520 --> 02:13:36,760
Yeah, yeah. There's also questions of more complex parameters. So after the lunch,

1329
02:13:36,760 --> 02:13:43,000
we'll talk about an example of how you can map out different combinations of

1330
02:13:43,000 --> 02:13:51,000
parameters. If you have multiple parameters you want to do, you can use array to map to those.

1331
02:13:52,200 --> 02:13:58,200
You can map one number to multiple things. That's possible. And if you have a situation

1332
02:13:58,200 --> 02:14:04,680
where you have very small things that you need to do a lot, what you can do is you can have an

1333
02:14:04,680 --> 02:14:12,840
array job where inside each job you have a for loop that does 10 things or 20 things. If you

1334
02:14:12,840 --> 02:14:18,400
If you have something that only takes 10 seconds, but you need to do it like 100,000 times,

1335
02:14:18,400 --> 02:14:25,520
you can split it up so that you have, let's say, 10,000 or 1,000 10-second things running

1336
02:14:25,520 --> 02:14:28,040
in each average job.

1337
02:14:28,040 --> 02:14:34,920
And then you can set up what is the run time, basically how many iterations you want inside

1338
02:14:34,920 --> 02:14:36,640
one job.

1339
02:14:36,640 --> 02:14:41,640
But usually it's this kind of like, okay, you can think of it a bit like you can have

1340
02:14:41,640 --> 02:14:49,480
either like a really thin rectangle with the same surface area as like a very wide one.

1341
02:14:49,480 --> 02:14:55,880
And as long as you keep the number of things that aren't needed to be done the same, you

1342
02:14:55,880 --> 02:15:02,880
can rearrange it in a way that you can do it in like, you can do a small number of jobs

1343
02:15:02,880 --> 02:15:07,680
that do a lot of things, or you can have a large number of jobs that do a few things.

1344
02:15:08,720 --> 02:15:14,000
Yeah. So I guess most of the people asking these questions, like, can I do x with array jobs,

1345
02:15:14,000 --> 02:15:22,240
the answer is always yes, if you write the code, whether it's in Python or Shell or whatever else,

1346
02:15:22,240 --> 02:15:29,600
to do the splitting up, and if it doesn't make it too short. And this is why we have other courses

1347
02:15:29,600 --> 02:15:34,560
on shell scripting and stuff like that. Knowing a little bit of bash can save you a lot of time

1348
02:15:35,200 --> 02:15:42,400
doing other stuff. Yeah, and if you have problems figuring out, okay, that's my program. Can I

1349
02:15:42,400 --> 02:15:48,320
split it up? How do I split it up? What would be the best way? Again, asking for help is a

1350
02:15:48,320 --> 02:15:54,880
good thing because for different projects, you might have a different thing you want to split

1351
02:15:54,880 --> 02:16:07,760
it up by, and all tasks are individual. So it depends on the task at hand. How do you want to

1352
02:16:07,760 --> 02:16:13,760
split it up? But yeah, maybe we should go. Anyway, I guess it's lunchtime. So should we

1353
02:16:16,160 --> 02:16:22,480
head there? See you in an hour.

1354
02:16:24,880 --> 02:16:26,380
Yeah, and when we come back, we'll

1355
02:16:26,380 --> 02:16:29,740
talk a bit more about arrays, about more complex array

1356
02:16:29,740 --> 02:16:34,460
things, and then we'll jump into applications and other things

1357
02:16:34,460 --> 02:16:39,100
in the cluster, monitoring jobs and that sort of stuff.

1358
02:16:39,100 --> 02:16:43,740
So a little example and some more philosophical stuff

1359
02:16:43,740 --> 02:16:45,500
before parallel.

1360
02:16:45,500 --> 02:16:46,060
OK.

1361
02:16:46,060 --> 02:16:47,420
Yeah.

1362
02:16:47,420 --> 02:16:48,780
Great.

1363
02:16:48,780 --> 02:16:51,060
As always, you can keep asking questions.

1364
02:16:51,060 --> 02:16:54,740
So talk to you later then.

1365
02:16:54,880 --> 02:16:56,880
Bye

1366
02:17:24,880 --> 02:17:26,940
you

1367
02:17:54,880 --> 02:17:56,940
you

1368
02:18:24,880 --> 02:18:26,940
you

1369
02:18:54,880 --> 02:18:56,940
you

1370
02:19:24,880 --> 02:19:26,940
you

1371
02:19:54,880 --> 02:19:56,940
you

1372
02:20:24,880 --> 02:20:26,940
you

1373
02:20:54,880 --> 02:20:56,940
you

1374
02:21:24,880 --> 02:21:26,940
you

1375
02:21:54,880 --> 02:21:56,940
you

1376
02:22:24,880 --> 02:22:26,940
you

1377
02:22:54,880 --> 02:22:56,940
you

1378
02:23:24,880 --> 02:23:26,940
you

1379
02:23:54,880 --> 02:23:56,940
you

1380
02:24:24,880 --> 02:24:26,940
you

1381
02:24:54,880 --> 02:24:56,940
you

1382
02:25:24,880 --> 02:25:26,940
you

1383
02:25:54,880 --> 02:25:56,940
you

1384
02:26:24,880 --> 02:26:26,940
you

1385
02:26:54,880 --> 02:26:56,940
you

1386
02:27:24,880 --> 02:27:26,940
you

1387
02:27:54,880 --> 02:27:56,940
you

1388
02:28:24,880 --> 02:28:26,940
you

1389
02:28:54,880 --> 02:28:56,940
you

1390
02:29:24,880 --> 02:29:26,940
you

1391
02:29:54,880 --> 02:29:56,940
you

1392
02:30:24,880 --> 02:30:26,940
you

1393
02:30:54,880 --> 02:30:56,940
you

1394
02:31:24,880 --> 02:31:26,940
you

1395
02:31:54,880 --> 02:31:56,940
you

1396
02:32:24,880 --> 02:32:26,940
you

1397
02:32:54,880 --> 02:32:56,940
you

1398
02:33:24,880 --> 02:33:26,940
you

1399
02:33:54,880 --> 02:33:56,940
you

1400
02:34:24,880 --> 02:34:26,940
you

1401
02:34:54,880 --> 02:34:56,940
you

1402
02:35:24,880 --> 02:35:26,940
you

1403
02:35:54,880 --> 02:35:56,940
you

1404
02:36:24,880 --> 02:36:26,940
you

1405
02:36:54,880 --> 02:36:56,940
you

1406
02:37:24,880 --> 02:37:26,940
you

1407
02:37:54,880 --> 02:37:56,940
you

1408
02:38:24,880 --> 02:38:26,940
you

1409
02:38:54,880 --> 02:38:56,940
you

1410
02:39:24,880 --> 02:39:26,940
you

1411
02:39:54,880 --> 02:39:56,940
you

1412
02:40:24,880 --> 02:40:26,940
you

1413
02:40:54,880 --> 02:40:56,940
you

1414
02:41:24,880 --> 02:41:26,940
you

1415
02:41:54,880 --> 02:41:56,940
you

1416
02:42:24,880 --> 02:42:26,940
you

1417
02:42:54,880 --> 02:42:56,940
you

1418
02:43:24,880 --> 02:43:26,940
you

1419
02:43:54,880 --> 02:43:56,940
you

1420
02:44:24,880 --> 02:44:26,940
you

1421
02:44:54,880 --> 02:44:56,940
you

1422
02:45:24,880 --> 02:45:26,940
you

1423
02:45:54,880 --> 02:45:56,940
you

1424
02:46:24,880 --> 02:46:26,940
you

1425
02:46:54,880 --> 02:46:56,940
you

1426
02:47:24,880 --> 02:47:26,940
you

1427
02:47:54,880 --> 02:47:56,940
you

1428
02:48:24,880 --> 02:48:26,940
you

1429
02:48:54,880 --> 02:48:56,940
you

1430
02:49:24,880 --> 02:49:26,940
you

1431
02:49:54,880 --> 02:49:56,940
you

1432
02:50:24,880 --> 02:50:26,940
you

1433
02:50:54,880 --> 02:50:56,940
you

1434
02:51:24,880 --> 02:51:26,940
you

1435
02:51:54,880 --> 02:51:56,940
you

1436
02:52:24,880 --> 02:52:26,940
you

1437
02:52:54,880 --> 02:52:56,940
you

1438
02:53:24,880 --> 02:53:26,940
you

1439
02:53:54,880 --> 02:53:56,940
you

1440
02:54:24,880 --> 02:54:26,940
you

1441
02:54:54,880 --> 02:54:56,940
you

1442
02:55:24,880 --> 02:55:26,940
you

1443
02:55:54,880 --> 02:55:56,940
you

1444
02:56:24,880 --> 02:56:26,940
you

1445
02:56:54,880 --> 02:56:56,940
you

1446
02:57:24,880 --> 02:57:26,940
you

1447
02:57:54,880 --> 02:57:56,940
you

1448
02:58:24,880 --> 02:58:26,940
you

1449
02:58:54,880 --> 02:58:56,940
you

1450
02:59:24,880 --> 02:59:26,940
you

1451
02:59:54,880 --> 02:59:56,940
you

1452
03:00:24,880 --> 03:00:26,940
you

1453
03:00:54,880 --> 03:00:56,940
you

1454
03:01:24,880 --> 03:01:26,940
you

1455
03:01:54,880 --> 03:01:56,940
you

1456
03:02:24,880 --> 03:02:26,940
you

1457
03:02:54,880 --> 03:02:56,940
you

1458
03:03:24,880 --> 03:03:26,940
you

1459
03:03:54,880 --> 03:03:56,940
you

1460
03:04:24,880 --> 03:04:26,940
you

1461
03:04:54,880 --> 03:04:56,940
you

1462
03:05:24,880 --> 03:05:26,940
you

1463
03:05:54,880 --> 03:05:56,940
you

1464
03:06:24,880 --> 03:06:26,940
you

1465
03:06:54,880 --> 03:06:56,940
you

1466
03:07:24,880 --> 03:07:26,940
you

1467
03:07:54,880 --> 03:07:56,940
you

1468
03:08:24,880 --> 03:08:26,940
you

1469
03:08:54,880 --> 03:08:56,940
you

1470
03:09:24,880 --> 03:09:26,940
you

1471
03:09:54,880 --> 03:09:56,940
you

1472
03:10:24,880 --> 03:10:26,940
you

1473
03:10:54,880 --> 03:10:56,940
you

1474
03:11:24,880 --> 03:11:26,940
you

1475
03:11:54,880 --> 03:11:56,940
you

1476
03:12:24,880 --> 03:12:26,940
you

1477
03:12:54,880 --> 03:12:56,940
you

1478
03:13:24,880 --> 03:13:26,940
you

1479
03:13:54,880 --> 03:13:56,940
you

1480
03:14:24,880 --> 03:14:33,000
Hello, are we back?

1481
03:14:33,000 --> 03:14:36,240
I think so.

1482
03:14:36,240 --> 03:14:38,680
I hope you had a good lunch break.

1483
03:14:38,680 --> 03:14:42,080
I think we did here.

1484
03:14:42,080 --> 03:14:43,440
So what comes next?

1485
03:14:43,440 --> 03:14:48,880
So my understanding, we have another quick demo

1486
03:14:48,880 --> 03:14:53,800
of Array Jobs, and we talk about monitoring and applications.

1487
03:14:53,800 --> 03:15:00,120
Any other notes and stuff to review from, or questions from the notes to review?

1488
03:15:02,040 --> 03:15:09,320
I think, yeah, there's plenty of good discussion there. And I recommend reading up on it later on

1489
03:15:09,320 --> 03:15:16,040
if you feel like it. But I think we can move forward. And let's do, like, many of the topics

1490
03:15:16,040 --> 03:15:21,960
in there touched the subject of, okay, what is, like, what can you do with the array jobs? And

1491
03:15:21,960 --> 03:15:27,720
Let's look at one of the more complex examples. Let's run one of these from the

1492
03:15:28,760 --> 03:15:38,520
examples in the course material. [name], if you want to run the case example.

1493
03:15:38,520 --> 03:15:53,320
Yes. So, what do I type? So, this is a new thing. This is with calculating pi.

1494
03:15:54,680 --> 03:16:00,600
So, in the parallel part, when we are going to switch into another example, which is much more

1495
03:16:00,600 --> 03:16:06,760
like computational example, and it was already mentioned in the beginning of the day, and it's

1496
03:16:06,760 --> 03:16:13,480
a bit of a toy example, where it calculates or estimates the number of Pi using a stochastic

1497
03:16:14,120 --> 03:16:20,760
test. Basically, it's like throwing a dart at a dartboard and whether it hits the dartboard,

1498
03:16:20,760 --> 03:16:31,160
it will calculate how many hits do you get and estimate Pi by that. It's very like a toy model,

1499
03:16:31,160 --> 03:16:39,160
but it's very easy to pack analyze for multiple CPUs and stuff like that, or relatively easy to

1500
03:16:40,200 --> 03:16:49,480
optimize for that. And here I see we have five array tasks, 0, 1, 2, 3, 4, 5.

1501
03:16:50,840 --> 03:16:59,960
Yes. And for that, we want to test out a different kind of way of

1502
03:17:01,160 --> 03:17:04,280
of choosing the parameters.

1503
03:17:04,280 --> 03:17:08,680
In this case, we might want to choose a seed number

1504
03:17:08,680 --> 03:17:12,760
for the random process that we're going to be doing,

1505
03:17:12,760 --> 03:17:17,000
so we can decide which number we want to use.

1506
03:17:17,000 --> 03:17:22,200
And in Bash, it's a whole programming language,

1507
03:17:22,200 --> 03:17:24,840
the terminal, so you can do, for example,

1508
03:17:24,840 --> 03:17:29,080
this case statement that [name] has written.

1509
03:17:29,080 --> 03:17:35,160
So, basically, based on the number of the Slurm array – it's mistyped, actually.

1510
03:17:37,480 --> 03:17:42,280
So, based on the number in the Slurm array task ID,

1511
03:17:44,600 --> 03:17:51,960
a different value will be set to this variable seed. So, let's say you want to test different

1512
03:17:51,960 --> 03:17:57,920
If a parameter is out, it's very easy to test it with this kind of like a syntax.

1513
03:17:57,920 --> 03:18:01,660
Then there's more complex syntax that you can use in the other examples.

1514
03:18:01,660 --> 03:18:05,940
You can take the parameters from a file or you can do all sorts of things.

1515
03:18:05,940 --> 03:18:10,580
But this is like very easy way of testing out.

1516
03:18:10,580 --> 03:18:12,300
So over here, we try...

1517
03:18:12,300 --> 03:18:16,500
So I guess, yeah, there's the seed.

1518
03:18:16,500 --> 03:18:17,500
Yes.

1519
03:18:17,500 --> 03:18:22,500
we try out what we get from the slurm/pi.py.

1520
03:18:23,360 --> 03:18:27,440
And you notice also in the #SBATCH statement,

1521
03:18:27,440 --> 03:18:30,240
we have changed the output file name

1522
03:18:30,240 --> 03:18:33,500
of where the output of the,

1523
03:18:36,840 --> 03:18:39,800
up in the top, like in the #SBATCH statements,

1524
03:18:39,800 --> 03:18:41,920
we have changed the output file name.

1525
03:18:41,920 --> 03:18:44,040
And you can use these test wildcards.

1526
03:18:44,040 --> 03:18:54,440
are documented in the documentation sections. You can use this %a to denote the Slurm Array Task ID.

1527
03:18:54,440 --> 03:19:00,760
So, if you want to create your own output file for the Slurm output, then you can use this

1528
03:19:00,760 --> 03:19:04,600
sort of a syntax for that. But let's... I guess everything's configurable.

1529
03:19:05,320 --> 03:19:12,040
Yeah. Okay. So, what this will do is that it will do two and a half million iterations

1530
03:19:12,040 --> 03:19:19,880
slurms with different seed values, and it will print out the outputs into pi underscore

1531
03:19:19,880 --> 03:19:27,040
and the seed number, and then it will print out the slurm outputs into the pi array hardcoded

1532
03:19:27,040 --> 03:19:30,400
with the array index. So, let's try it out.

1533
03:19:30,400 --> 03:19:33,920
Exit, save, yes.

1534
03:19:33,920 --> 03:19:41,200
And there's, like I said, there's multiple of these different things that, different

1535
03:19:41,200 --> 03:19:45,880
ways that you can do this array kind of like expansion.

1536
03:19:45,880 --> 03:19:51,360
So first, I make sure I'm where I expect to be after the break.

1537
03:19:55,360 --> 03:19:58,400
pi-array.sh.

1538
03:19:58,400 --> 03:20:01,920
If we do `slurm queue`, it's already running.

1539
03:20:01,920 --> 03:20:04,800
So four things.

1540
03:20:04,800 --> 03:20:05,600
And it's done.

1541
03:20:05,600 --> 03:20:07,840
If you want to look at one of the outputs and.

1542
03:20:07,840 --> 03:20:13,520
Okay, now this is a lot of files here.

1543
03:20:13,520 --> 03:20:14,520
Yeah.

1544
03:20:14,520 --> 03:20:15,520
So, what are the new ones?

1545
03:20:15,520 --> 03:20:16,520
The pyarray hardcode.

1546
03:20:16,520 --> 03:20:17,520
These are the output files.

1547
03:20:17,520 --> 03:20:18,520
Yeah.

1548
03:20:18,520 --> 03:20:22,120
Should we look at the first one?

1549
03:20:22,120 --> 03:20:23,120
Yeah.

1550
03:20:23,120 --> 03:20:30,360
So, this is the output that the code, yeah, what the code runs.

1551
03:20:30,360 --> 03:20:37,440
But the actual output of the code is going into the py underscore and then.

1552
03:20:37,440 --> 03:20:38,640
1, 2, 3.

1553
03:20:38,640 --> 03:20:45,120
OK, yeah, and it's a JSON structure that says stuff.

1554
03:20:45,120 --> 03:20:46,760
So I guess this is a way where if you

1555
03:20:46,760 --> 03:20:49,840
have different file names that aren't predictably named,

1556
03:20:49,840 --> 03:20:54,080
you can sort of hard code what the inputs are

1557
03:20:54,080 --> 03:20:58,280
or what the hyperparameters are or whatever like that.

1558
03:20:58,280 --> 03:21:00,040
Yeah, and there's a lot of flexibility

1559
03:21:00,040 --> 03:21:02,720
in the array chops for this.

1560
03:21:02,720 --> 03:21:06,640
But OK, I think you probably get the idea that you can

1561
03:21:06,640 --> 03:21:07,800
Yeah.

1562
03:21:07,800 --> 03:21:12,280
You can check this out later.

1563
03:21:12,280 --> 03:21:14,040
We'll check out the different examples.

1564
03:21:14,040 --> 03:21:16,640
So maybe we should jump into the next section,

1565
03:21:16,640 --> 03:21:19,640
which is about monitoring.

1566
03:21:19,640 --> 03:21:20,920
Yeah.

1567
03:21:20,920 --> 03:21:23,480
So should I come back here?

1568
03:21:26,600 --> 03:21:27,160
Where is it?

1569
03:21:27,160 --> 03:21:28,600
Monitoring.

1570
03:21:28,600 --> 03:21:29,400
Yeah.

1571
03:21:29,400 --> 03:21:32,040
So throughout this, we have already

1572
03:21:32,040 --> 03:21:40,120
started to use some of the tools for monitoring and, of course, one big monitoring thing is

1573
03:21:40,120 --> 03:21:47,920
the output itself. The code produces output. You can check the output and see if it's correct.

1574
03:21:47,920 --> 03:21:52,040
That's one way of monitoring it. But when we talk about monitoring, we often think about

1575
03:21:52,040 --> 03:21:58,480
how does the queue perceive things and what happened when the job run, like what happened

1576
03:21:58,480 --> 03:22:06,800
in the queue. And for that, we have used the Slurm queue to check when we have submitted

1577
03:22:06,800 --> 03:22:12,720
a job, what happens there. That's the first thing. When you submit a job, you usually

1578
03:22:12,720 --> 03:22:17,760
want to check, is it running? Is it queuing? When does it start?

1579
03:22:17,760 --> 03:22:23,640
Will it finish today of the 2,000 things I submitted yesterday? When is it done? And

1580
03:22:23,640 --> 03:22:26,200
so on.

1581
03:22:26,200 --> 03:22:34,440
clusters that don't have the Slurm script that we are using, which is this kind of helper script,

1582
03:22:34,440 --> 03:22:40,200
you can use the sq-user mentioned in the documentation, but we'll also put it into the

1583
03:22:40,200 --> 03:22:48,760
notes to check the... I guess that's here. Yeah. Yeah. Okay. What other kinds of monitoring are

1584
03:22:48,760 --> 03:23:16,760
So the other one and the major one is the history like we want to see what is the like what happened like if the job has finished what has happened did it finish correctly and so forth and for that we use the slam history so when we use the slam history we can we can check okay what was the did it complete correctly did it

1585
03:23:16,760 --> 03:23:25,920
like, what resources actually used, how long did it take, that sort of stuff, like, basic

1586
03:23:25,920 --> 03:23:26,920
stuff.

1587
03:23:26,920 --> 03:23:32,880
There's also, like, if you don't have the Slurm command, you can use this s-act-u user.

1588
03:23:32,880 --> 03:23:40,120
We'll put it into the notes as well, or we'll, yeah, there's many of these Slurm commands

1589
03:23:40,120 --> 03:23:42,040
that you can use to monitor.

1590
03:23:42,040 --> 03:23:46,120
But usually it's a good idea to, yeah, something like that.

1591
03:23:46,120 --> 03:23:54,040
Yeah, you can figure out what information you want from the job and you can get a lot

1592
03:23:54,040 --> 03:23:57,800
of information from the Slurm itself.

1593
03:23:57,800 --> 03:24:03,800
So basically, yeah, Slurm keeps a huge database of all the parameters of everything that's

1594
03:24:03,800 --> 03:24:04,800
run.

1595
03:24:04,800 --> 03:24:10,080
What the commands are, who ran it, where it was run, but then also things like all the

1596
03:24:10,080 --> 03:24:13,960
resources that were requested and the resources that were actually used.

1597
03:24:13,960 --> 03:24:17,400
So you can go and submit all your stuff,

1598
03:24:17,400 --> 03:24:21,200
and then you can return later and then

1599
03:24:21,200 --> 03:24:24,600
see what finished, what didn't finish, what had errors,

1600
03:24:24,600 --> 03:24:26,240
how much resources did it use,

1601
03:24:26,240 --> 03:24:29,760
do I need to adjust any of these things?

1602
03:24:29,760 --> 03:24:35,040
Stuff like that. That's this.

1603
03:24:35,040 --> 03:24:36,040
Okay.

1604
03:24:36,040 --> 03:24:46,320
Maybe we could jump into the terminal now and view a few of the monitoring outputs.

1605
03:24:46,320 --> 03:24:53,280
So there's another like this kind of wrapper script that is usually like added with Slurm

1606
03:24:53,280 --> 03:24:55,720
called `seff`.

1607
03:24:55,720 --> 03:25:04,860
And we have a few example job IDs that we can show in the notes, in our own notes.

1608
03:25:04,860 --> 03:25:09,220
we could try out that you put there.

1609
03:25:09,220 --> 03:25:10,220
Yes.

1610
03:25:10,220 --> 03:25:11,220
I see.

1611
03:25:11,220 --> 03:25:12,220
Okay.

1612
03:25:12,220 --> 03:25:13,220
Yes.

1613
03:25:13,220 --> 03:25:14,220
So let's look at-

1614
03:25:14,220 --> 03:25:16,140
These commands will work on Triton, but not other places.

1615
03:25:16,140 --> 03:25:21,220
Yeah, these are jobs I have run in the past, and let's look at something like that.

1616
03:25:21,220 --> 03:25:25,620
So once you have a job that has run, you get the job ID.

1617
03:25:25,620 --> 03:25:32,540
And if you give that job ID to this command sf, it will print out various efficiency information

1618
03:25:32,540 --> 03:25:33,940
about that.

1619
03:25:33,940 --> 03:25:42,480
So you will see, for example, here, like, okay, did it complete, what was the status?

1620
03:25:42,480 --> 03:25:47,160
Then you see that, okay, how many CPUs did it use?

1621
03:25:47,160 --> 03:25:52,860
And then it tells how much time it used with those CPUs, like the CPU time.

1622
03:25:52,860 --> 03:25:57,640
And then it will tell what is the CPU efficiency.

1623
03:25:57,640 --> 03:26:05,160
So that just means that how much of those reserved CPUs were utilized.

1624
03:26:05,160 --> 03:26:06,940
So what is the time?

1625
03:26:06,940 --> 03:26:09,240
Is 97% considered good?

1626
03:26:09,240 --> 03:26:10,240
Yes.

1627
03:26:10,240 --> 03:26:11,240
Yes.

1628
03:26:11,240 --> 03:26:14,340
Like 100% would be that it's using all of the time.

1629
03:26:14,340 --> 03:26:16,800
So 97% is great.

1630
03:26:16,800 --> 03:26:21,040
And the wall clock time is again like the time that you would see on the wall.

1631
03:26:21,040 --> 03:26:24,340
So it's like the time in real time.

1632
03:26:24,340 --> 03:26:30,780
So if you use multiple CPUs, the CPU time can be bigger than the wall time because you

1633
03:26:30,780 --> 03:26:34,180
have multiple CPUs running the stuff.

1634
03:26:34,180 --> 03:26:42,260
And then, yes, next, but let's look at first the memory utilization.

1635
03:26:42,260 --> 03:26:46,400
So you can see what was the memory consumption and what was the memory efficiency.

1636
03:26:46,400 --> 03:26:48,060
So not very good.

1637
03:26:48,060 --> 03:26:55,820
I do note that many of these numbers are not necessarily the true numbers, they're sampled

1638
03:26:55,820 --> 03:26:56,820
numbers.

1639
03:26:56,820 --> 03:27:02,300
So what Slurm does is that it samples what the process is doing every now and then.

1640
03:27:02,300 --> 03:27:09,020
I think it's 30 seconds by default that it samples what the program is doing.

1641
03:27:09,020 --> 03:27:13,860
So if your program has a huge spike of memory consumption or something, it might not be shown

1642
03:27:13,860 --> 03:27:20,820
in this data, or if the job crashes immediately or something, it might not show correct numbers.

1643
03:27:20,820 --> 03:27:25,420
So these are sampled numbers over the whole runtime.

1644
03:27:25,420 --> 03:27:31,540
So if there's something weird happening that happens quickly, it might not be reflected

1645
03:27:31,540 --> 03:27:32,540
here.

1646
03:27:32,540 --> 03:27:34,860
But you can get the overall big picture.

1647
03:27:34,860 --> 03:27:43,380
So let's look at one of the jobs that uses multiple CPUs.

1648
03:27:43,380 --> 03:27:47,580
So the output here is pretty similar.

1649
03:27:47,580 --> 03:27:51,720
The only difference is that now we see that there's cores per node is four.

1650
03:27:51,720 --> 03:27:57,740
So we're using four cores per node.

1651
03:27:57,740 --> 03:28:01,380
And we noticed that the CPU utilized is actually the same, basically.

1652
03:28:01,380 --> 03:28:05,620
We are doing the same calculation.

1653
03:28:05,620 --> 03:28:11,780
We're doing the same exact amount of CPU time utilizing, but now it's divided for four CPUs,

1654
03:28:11,780 --> 03:28:12,780
basically.

1655
03:28:12,780 --> 03:28:19,260
And the CPU efficiency is still very good, but the wall clock has dropped, like, dramatically.

1656
03:28:20,380 --> 03:28:30,220
Yeah, so instead of taking 41 seconds with one CPU, it's 11 seconds for four CPUs.

1657
03:28:31,660 --> 03:28:37,820
But this also came with a bit more of an increased memory utilization, but at the same time,

1658
03:28:37,820 --> 03:28:46,020
We can't really say if that's correct, because the sample time is so small, like it's 11

1659
03:28:46,020 --> 03:28:47,020
seconds.

1660
03:28:47,020 --> 03:28:50,060
So it's not that big.

1661
03:28:50,060 --> 03:28:55,240
And quite recently in Triton, we've added also GPU stats here.

1662
03:28:55,240 --> 03:29:06,020
So if we take one GPU job, so this was a very simple test PyTorch model, it ran for three

1663
03:29:06,020 --> 03:29:16,740
minutes so it's not very big. So you can see here at the bottom there's now like GPU stats also.

1664
03:29:18,180 --> 03:29:26,580
So these are again sampled on the compute nodes so you can see what GPU was utilized,

1665
03:29:27,140 --> 03:29:32,900
what was the GPU utilization and what was the memory utilization. So the GPU utilization

1666
03:29:32,900 --> 03:29:38,100
basically here means that how much of the time the GPU was doing calculations.

1667
03:29:38,100 --> 03:29:43,700
It doesn't say that whether calculations are efficient or whatever. It just means that how

1668
03:29:43,700 --> 03:29:49,300
much the GPU was just doing calculations. And in this case, the model is so small that

1669
03:29:50,260 --> 03:29:53,300
basically the GPU finishes it immediately when it gets it. So

1670
03:29:53,940 --> 03:30:02,420
it doesn't utilize the GPU very efficiently. But in other clusters, there might be other

1671
03:30:02,420 --> 03:30:09,060
ways of monitoring the GPUs. A common way is that once you get a job running, you can usually

1672
03:30:10,100 --> 03:30:17,140
take an SSH connection to the node where the job is running and use this tool called NVIDIA SMI

1673
03:30:17,780 --> 03:30:23,060
to print out information. There's more information in the documentation about that.

1674
03:30:23,060 --> 03:30:28,900
So you can go to the GPU node and monitor the GPU utilization.

1675
03:30:32,420 --> 03:30:35,540
So while it's running, this is what you can do.

1676
03:30:35,540 --> 03:30:37,860
OK, yeah.

1677
03:30:37,860 --> 03:30:39,660
There is a good question in the notes.

1678
03:30:39,660 --> 03:30:41,340
Considering that we have profilers

1679
03:30:41,340 --> 03:30:43,700
as part of our code, which may be very detailed,

1680
03:30:43,700 --> 03:30:46,820
how can we benefit from the short summary?

1681
03:30:46,820 --> 03:30:48,780
So how would you balance the profilers

1682
03:30:48,780 --> 03:30:53,180
with this kind of reporting?

1683
03:30:53,180 --> 03:30:55,940
And that's a good question.

1684
03:30:55,940 --> 03:31:00,180
I think if you know how to use a profiler

1685
03:31:00,180 --> 03:31:03,860
or if you know how to profile or get the information from your code itself,

1686
03:31:03,860 --> 03:31:09,620
it's of course great, because then you get much more detailed information.

1687
03:31:09,620 --> 03:31:18,020
But in a lot of cases, you might be using a program that you don't control what it's doing.

1688
03:31:18,020 --> 03:31:23,780
And if you want to add profiling to it, it might be an extra effort.

1689
03:31:23,780 --> 03:31:27,140
So with these, you get numbers from the source.

1690
03:31:27,140 --> 03:31:31,140
You get the numbers based from the queue system

1691
03:31:31,140 --> 03:31:33,220
and the hardware itself.

1692
03:31:33,220 --> 03:31:35,940
So it's like these numbers are free and automatic.

1693
03:31:35,940 --> 03:31:37,340
So it's like the big picture.

1694
03:31:37,340 --> 03:31:39,700
And if you see these numbers are low,

1695
03:31:39,700 --> 03:31:43,140
then you go to your profilers, and you can understand why

1696
03:31:43,140 --> 03:31:48,700
and make it better or understand that it's as good as it can be.

1697
03:31:48,700 --> 03:31:49,980
Something like that.

1698
03:31:49,980 --> 03:31:54,980
So is it kind of like, you know, like the, like, have you tried turning it on and off

1699
03:31:54,980 --> 03:31:59,980
again, kind of a situation where like, like you first do the simple things and then you

1700
03:31:59,980 --> 03:32:05,460
like, if it's still like you first do the, you try out the simple things and then you

1701
03:32:05,460 --> 03:32:07,860
try the more, more complicated things usually.

1702
03:32:07,860 --> 03:32:12,620
So if you want to profile your code, the easiest way is usually just look at these numbers

1703
03:32:12,620 --> 03:32:16,620
and see like, okay, what are these numbers saying?

1704
03:32:16,620 --> 03:32:19,300
And then if you want more fine-grained information,

1705
03:32:19,300 --> 03:32:21,260
you use a profile or something.

1706
03:32:21,260 --> 03:32:27,700
We can post some good profiling tools into the notes soonish

1707
03:32:27,700 --> 03:32:29,980
that can do it for you with minimal hassle.

1708
03:32:29,980 --> 03:32:35,220
But yeah, they are not one or the other.

1709
03:32:35,220 --> 03:32:38,900
But this is something you get for free, like Richard said.

1710
03:32:38,900 --> 03:32:41,460
Yeah.

1711
03:32:41,460 --> 03:32:43,420
OK, what else?

1712
03:32:43,420 --> 03:32:45,620
There is an interesting question.

1713
03:32:45,620 --> 03:32:50,740
Is there a way to have it write this efficiency information

1714
03:32:50,740 --> 03:32:55,460
to the job output files automatically instead

1715
03:32:55,460 --> 03:32:58,460
of only being in the database?

1716
03:32:58,460 --> 03:33:02,420
And that's a good question, I guess.

1717
03:33:02,420 --> 03:33:04,860
So when it appeared there automatically

1718
03:33:04,860 --> 03:33:07,420
in the Gutenberg stuff, that's because the code

1719
03:33:07,420 --> 03:33:10,420
itself was written to do that.

1720
03:33:15,620 --> 03:33:24,140
Yeah, I'm not certain. In principle, yes, probably. But I think, because it's hard to

1721
03:33:24,140 --> 03:33:32,740
put it into the job script itself, because the stats are not recorded until the job finishes,

1722
03:33:32,740 --> 03:33:38,120
or if they're not finalized. So it's like you're bootstrapping yourself, basically pulling

1723
03:33:38,120 --> 03:33:42,980
yourself out with your own bootstraps. And it becomes quite complicated. But I can imagine

1724
03:33:42,980 --> 03:33:46,380
that you could do some sort of like a script you can do

1725
03:33:46,380 --> 03:33:48,260
after the job has run?

1726
03:33:48,260 --> 03:33:50,820
Or you can wrap it in a profiler or something

1727
03:33:50,820 --> 03:33:52,100
that will track this.

1728
03:33:52,100 --> 03:33:55,060
Like, for example, one trick that I sometimes

1729
03:33:55,060 --> 03:34:01,220
do, user bin time dash v.

1730
03:34:01,220 --> 03:34:03,500
And it has to be the full path, because otherwise it's

1731
03:34:03,500 --> 03:34:04,700
a bash built in.

1732
03:34:04,700 --> 03:34:13,180
And then if you run something like y.py,

1733
03:34:13,180 --> 03:34:16,460
that's 2 and 1 1,000,000.

1734
03:34:16,460 --> 03:34:18,620
So this will run.

1735
03:34:18,620 --> 03:34:23,700
And it automatically, so this is from time.

1736
03:34:23,700 --> 03:34:27,900
So time prints out all of this other stuff, which will

1737
03:34:27,900 --> 03:34:29,300
tell you some basic summary.

1738
03:34:29,300 --> 03:34:34,420
So the user time in seconds, what percentage

1739
03:34:34,420 --> 03:34:38,900
of a CPU was used during this time period

1740
03:34:38,900 --> 03:34:43,540
and some other interesting technical stats there.

1741
03:34:43,540 --> 03:34:49,940
So this doesn't tell you the overall efficiency of memory

1742
03:34:49,940 --> 03:34:51,500
efficiency and so on, because time

1743
03:34:51,500 --> 03:34:58,140
doesn't know how much memory was allocated to the job and so on.

1744
03:34:58,140 --> 03:35:00,220
But it has stuff.

1745
03:35:00,220 --> 03:35:03,620
But yeah, like you can do various.

1746
03:35:07,180 --> 03:35:07,740
I think it's.

1747
03:35:07,740 --> 03:35:09,980
I do it with two threads.

1748
03:35:09,980 --> 03:35:11,620
It's coarse.

1749
03:35:11,620 --> 03:35:13,260
It's coarse.

1750
03:35:13,260 --> 03:35:14,100
Yeah.

1751
03:35:14,100 --> 03:35:15,500
Let's run it with help.

1752
03:35:15,500 --> 03:35:16,820
Yeah.

1753
03:35:16,820 --> 03:35:18,700
But maybe we should move forward.

1754
03:35:18,700 --> 03:35:20,700
Yeah, I guess we should go on.

1755
03:35:20,700 --> 03:35:22,700
It's nprox.

1756
03:35:22,700 --> 03:35:23,200
Yeah.

1757
03:35:23,200 --> 03:35:33,200
And here we see it says 190% of a CPU, which means it's using almost two CPUs.

1758
03:35:33,200 --> 03:35:41,200
But there's plenty of these kind of programs that you can use to do the monitoring.

1759
03:35:41,200 --> 03:35:43,200
Yeah.

1760
03:35:43,200 --> 03:35:49,040
Yeah, so we'll note, put into the notes, our favorite profilers.

1761
03:35:49,040 --> 03:35:55,640
And if you have your favorite tools that you can use to profile, do add them there as well

1762
03:35:55,640 --> 03:35:59,760
so that other people can benefit from knowing about them.

1763
03:35:59,760 --> 03:36:04,720
But basically this is like usually when you run something in the queue and if you think

1764
03:36:04,720 --> 03:36:09,760
that the job is using like four CPUs, you think you reserve four CPUs and you think

1765
03:36:09,760 --> 03:36:12,080
that the job is using four CPUs.

1766
03:36:12,080 --> 03:36:15,160
And then you usually want to look at the SF or whatever

1767
03:36:15,160 --> 03:36:17,640
to verify that it actually used the four CPUs

1768
03:36:17,640 --> 03:36:20,480
because otherwise it's wasted resources, right?

1769
03:36:20,480 --> 03:36:24,920
So usually you want to use quickly SF or something

1770
03:36:24,920 --> 03:36:26,880
to verify that what is the memory usage,

1771
03:36:26,880 --> 03:36:31,320
what is the time usage, what is the processor usage

1772
03:36:31,320 --> 03:36:35,600
in order to set the requirements of your job

1773
03:36:35,600 --> 03:36:38,520
match more closely to what it actually needs.

1774
03:36:38,520 --> 03:36:47,240
Yeah. And if you tried this and you can't figure out what it is, I'd say always, if you're using

1775
03:36:47,240 --> 03:36:52,360
resources, always check, see the efficiency. If it doesn't look like what you expect,

1776
03:36:53,320 --> 03:36:59,960
spend a little time, see if you can understand why. But if not, come talk to us and we can help

1777
03:36:59,960 --> 03:37:05,240
do that. If everyone would do this, it would make the cluster go much faster because there's

1778
03:37:05,240 --> 03:37:13,640
a lot less wasted stuff there. Anyway, yeah. Should we go on then?

1779
03:37:16,280 --> 03:37:22,920
Yeah, let's go. And next we have a talk. Yeah, next we are going to go through some applications.

1780
03:37:26,200 --> 03:37:26,680
Yeah, so.

1781
03:37:26,680 --> 03:37:29,320
So yes.

1782
03:37:29,320 --> 03:37:33,920
Well, I guess the purpose here isn't

1783
03:37:33,920 --> 03:37:35,920
to talk about specific applications.

1784
03:37:35,920 --> 03:37:39,440
But if you're using a cluster, you want to run something.

1785
03:37:39,440 --> 03:37:44,080
And it's either an application someone else has installed,

1786
03:37:44,080 --> 03:37:48,160
or it's something that you need to install yourself.

1787
03:37:48,160 --> 03:37:51,400
Or for example, you need to install Python or something

1788
03:37:51,400 --> 03:37:53,080
and then run your own code.

1789
03:37:53,080 --> 03:37:56,640
And this is just a very broad overview of what's available.

1790
03:37:56,640 --> 03:38:01,360
Since everyone needs different stuff, we're not going to take the time to go into any detail

1791
03:38:01,360 --> 03:38:07,600
here because most people would be bored and you will need to find it again when you need it anyway.

1792
03:38:08,240 --> 03:38:15,040
But this is the general idea. So some people come to the cluster and say, why can't I do

1793
03:38:16,240 --> 03:38:21,280
sudo apt-get install something, which is the command you would use on a Linux computer to

1794
03:38:21,280 --> 03:38:27,520
install something. And there's several reasons, but the most important of the reasons is that

1795
03:38:28,480 --> 03:38:34,640
this is a shared cluster. And if you can install something or change the version of something,

1796
03:38:35,200 --> 03:38:39,440
then it will break it for everyone else. And even if us as admins do stuff,

1797
03:38:39,440 --> 03:38:44,800
any little change we do has the possibility of breaking someone else's code.

1798
03:38:46,240 --> 03:38:50,080
So it's very conservative what's installed as part of the operating system.

1799
03:38:50,080 --> 03:38:54,720
So if we go down, that's us.

1800
03:38:54,720 --> 03:38:59,680
So yeah, there's a few things we install that way.

1801
03:38:59,680 --> 03:39:02,200
But for the most part,

1802
03:39:02,200 --> 03:39:06,760
anything you need is not just available by default.

1803
03:39:06,760 --> 03:39:12,320
Yeah. Maybe demo in the terminal a few of these applications.

1804
03:39:12,320 --> 03:39:16,560
So many, at least here in Aalto,

1805
03:39:16,560 --> 03:39:22,920
The computing cluster, all of the computers are very minimal installations, so they don't

1806
03:39:22,920 --> 03:39:29,640
have a lot of software installed, because they're not installed into any disk or anything

1807
03:39:29,640 --> 03:39:31,960
when the computer is booted up.

1808
03:39:31,960 --> 03:39:38,080
Everything is in memory, and this is quite common in many clusters, so the whole operating

1809
03:39:38,080 --> 03:39:43,960
system is in memory, and the more you have in the memory, the less.

1810
03:39:43,960 --> 03:39:48,920
The more stuff you have in the operating system, the less you have memory available for the

1811
03:39:48,920 --> 03:39:49,920
users.

1812
03:39:49,920 --> 03:39:54,560
So that's why usually the image is very small.

1813
03:39:54,560 --> 03:39:55,880
But there's some programs there.

1814
03:39:55,880 --> 03:40:05,360
So if we, for example, look which Python 3, so which is this tool that checks, like if

1815
03:40:05,360 --> 03:40:11,120
I would run Python 3, what is the actual application that will run?

1816
03:40:11,120 --> 03:40:15,040
So we noticed that this is, it comes from user bin.

1817
03:40:15,040 --> 03:40:19,640
So this is like, Linux has this file systems through the operating system.

1818
03:40:19,640 --> 03:40:20,640
Yeah.

1819
03:40:20,640 --> 03:40:25,840
Linux has this file system hierarchy where like user is the applications, the operating

1820
03:40:25,840 --> 03:40:29,960
system applications there and bin is usually like the executable binaries.

1821
03:40:29,960 --> 03:40:38,280
So it's part of the operating system, but we want to still run multiple things in the cluster.

1822
03:40:38,280 --> 03:40:42,920
So often, we admins install stuff into the cluster

1823
03:40:42,920 --> 03:40:46,200
and make it available for many of the users.

1824
03:40:46,200 --> 03:40:47,560
Yes.

1825
03:40:47,560 --> 03:40:53,320
And we do that with, well, the most common one

1826
03:40:53,320 --> 03:40:56,080
is called the module system.

1827
03:40:56,080 --> 03:40:58,560
And this is a way you can run a command,

1828
03:40:58,560 --> 03:41:01,680
and it makes other software available by manipulating

1829
03:41:01,680 --> 03:41:05,000
the paths it looks at for software.

1830
03:41:05,000 --> 03:41:10,400
And we don't need to go into depth about exactly where this

1831
03:41:10,400 --> 03:41:12,640
comes from and how it works.

1832
03:41:12,640 --> 03:41:14,680
But can you give one example, then?

1833
03:41:14,680 --> 03:41:18,440
Yeah, let's check if we have MATLAB available.

1834
03:41:18,440 --> 03:41:28,160
So if we run this module spider MATLAB,

1835
03:41:28,160 --> 03:41:30,520
yeah, we can first check if we have it.

1836
03:41:30,520 --> 03:41:33,200
And it says there's no MATLAB anywhere.

1837
03:41:33,200 --> 03:41:34,200
OK, yeah.

1838
03:41:34,200 --> 03:41:36,760
So if we now run module spider matlab,

1839
03:41:36,760 --> 03:41:41,360
so this module spider is a tool that it checks like,

1840
03:41:41,360 --> 03:41:45,760
is there, like, can you find matlab in the modules?

1841
03:41:45,760 --> 03:41:48,200
You can just run module spider to run you

1842
03:41:48,200 --> 03:41:50,680
all of the available modules.

1843
03:41:50,680 --> 03:41:53,440
But you notice that now we see that there's multiple

1844
03:41:53,440 --> 03:41:56,040
versions of matlab available over here.

1845
03:41:57,000 --> 03:41:57,840
Yes.

1846
03:41:57,840 --> 03:41:59,520
You see that there's matlab

1847
03:41:59,520 --> 03:42:01,120
and then there's like multiple versions.

1848
03:42:01,120 --> 03:42:02,800
So let's pick one of those versions.

1849
03:42:02,800 --> 03:42:05,920
So let's pick the latest one.

1850
03:42:05,920 --> 03:42:06,600
Maybe that one.

1851
03:42:06,600 --> 03:42:08,280
Maybe the latest one.

1852
03:42:08,280 --> 03:42:11,640
And we can press Q to quit, and then module load,

1853
03:42:11,640 --> 03:42:14,240
and then give that name.

1854
03:42:14,240 --> 03:42:18,340
So I paste it once.

1855
03:42:18,340 --> 03:42:20,160
And what happens?

1856
03:42:20,160 --> 03:42:21,000
Looks like nothing.

1857
03:42:21,000 --> 03:42:22,640
Well, yeah.

1858
03:42:22,640 --> 03:42:28,600
But we still, if you are on module list,

1859
03:42:28,600 --> 03:42:32,560
yeah, module list shows what modules are loaded.

1860
03:42:32,560 --> 03:42:36,960
So we can see that there's now the MATLAB module is loaded.

1861
03:42:36,960 --> 03:42:40,160
There's also this kind of like environment module.

1862
03:42:40,160 --> 03:42:43,120
So many of, many clusters have this kind of like

1863
03:42:43,120 --> 03:42:46,560
overall yearly installations or something

1864
03:42:46,560 --> 03:42:48,320
and we have them now too.

1865
03:42:48,320 --> 03:42:53,220
So it makes a lot of software available for you.

1866
03:42:54,240 --> 03:42:58,600
And it makes it possible to install a lot of other software.

1867
03:42:58,600 --> 03:43:07,000
But let's now check which MATLAB, did we actually get MATLAB, so okay, now we see.

1868
03:43:07,000 --> 03:43:10,400
Manual installation software MATLAB, yeah, okay.

1869
03:43:10,400 --> 03:43:15,400
So there's now like a system installed MATLAB.

1870
03:43:15,400 --> 03:43:23,640
So this is the most common way that we provide software or the system providers provide software

1871
03:43:23,640 --> 03:43:24,640
for you.

1872
03:43:24,640 --> 03:43:28,400
Maybe we can start the MATLAB and test it.

1873
03:43:28,400 --> 03:43:33,840
let's try that. Let's see, I hope it doesn't do something weird.

1874
03:43:37,040 --> 03:43:42,240
Yeah, we started with the no JDM so that we don't want the graphical interface. But yeah,

1875
03:43:42,240 --> 03:43:49,920
you can see that this is the muscle. It returns. Yeah, okay, so that worked.

1876
03:43:51,040 --> 03:43:55,600
Okay, and what's available in the module system? What kind of stuff do we have there?

1877
03:43:55,600 --> 03:44:08,860
Well, a huge bunch of software. There's many libraries, many finished software installations

1878
03:44:08,860 --> 03:44:14,620
and all sorts of stuff. So you can find it in the applications page and running module

1879
03:44:14,620 --> 03:44:22,160
spider will give you more information on that. But we also have some very specific software.

1880
03:44:22,160 --> 03:44:24,360
So this might be, again, like some of this

1881
03:44:24,360 --> 03:44:26,000
is also only auto-specific.

1882
03:44:26,000 --> 03:44:30,920
You want to check your cluster's stuff, how they are doing.

1883
03:44:30,920 --> 03:44:34,240
But one for whatever, is it safe to say

1884
03:44:34,240 --> 03:44:36,960
what every cluster you have, the first thing to do

1885
03:44:36,960 --> 03:44:39,560
is read the documentation for what you need

1886
03:44:39,560 --> 03:44:41,120
and see if it's already installed

1887
03:44:41,120 --> 03:44:43,680
or there's special instructions, because it

1888
03:44:43,680 --> 03:44:46,640
will be different for everyone.

1889
03:44:46,640 --> 03:44:48,900
Yeah, especially for the very complex programs,

1890
03:44:48,900 --> 03:44:50,640
there might be a specific reason why

1891
03:44:50,640 --> 03:44:57,280
installed the way they are. And the admins have used a lot of effort trying to get the most

1892
03:44:57,280 --> 03:45:03,040
like performant version and most stable version installed to the system. And doing it manually

1893
03:45:03,040 --> 03:45:09,440
by yourself can be quite tricky sometimes. Yeah. Okay.

1894
03:45:09,440 --> 03:45:17,920
Should we demo? We could demo a few more software. So we have in our

1895
03:45:17,920 --> 03:45:22,920
So in our cluster, we also have these containers available.

1896
03:45:27,580 --> 03:45:29,340
So there was, yesterday at least,

1897
03:45:29,340 --> 03:45:31,740
there was a question about like what,

1898
03:45:31,740 --> 03:45:35,660
can you run Docker containers in the cluster?

1899
03:45:35,660 --> 03:45:37,500
So containers, for those who don't know,

1900
03:45:37,500 --> 03:45:39,540
is this basically like an operating system

1901
03:45:39,540 --> 03:45:42,540
paired with the software, like everything is there.

1902
03:45:42,540 --> 03:45:45,900
Like everything is contained in the same package.

1903
03:45:45,900 --> 03:45:48,540
And we use these apptainer containers,

1904
03:45:48,540 --> 03:45:51,500
or they used to be called singularity containers.

1905
03:45:51,500 --> 03:45:54,660
They are called, in some sites, singularity containers

1906
03:45:54,660 --> 03:45:58,260
to have these kind of very complex software

1907
03:45:58,260 --> 03:46:02,460
that wouldn't install into the operating system

1908
03:46:02,460 --> 03:46:03,900
that we're using.

1909
03:46:03,900 --> 03:46:07,200
So, but these can be run in the cluster,

1910
03:46:07,200 --> 03:46:10,140
and we have a few of these available.

1911
03:46:10,140 --> 03:46:15,140
They need usually a bit more manual work to get working,

1912
03:46:15,140 --> 03:46:23,220
But in the notes, we'll link a course page with Code Refinery that we did on creating

1913
03:46:23,220 --> 03:46:29,620
these containers. So if you are interested in this, please check that material.

1914
03:46:32,340 --> 03:46:38,580
And on Triton, at least we do have some software already installed in containers.

1915
03:46:38,580 --> 03:46:43,700
So it's not just, despite what it says here, it's not just under install it yourself.

1916
03:46:43,700 --> 03:46:46,820
So yeah.

1917
03:46:46,820 --> 03:46:51,780
But should we give a demo of running stuff,

1918
03:46:51,780 --> 03:46:53,300
something with a container?

1919
03:46:53,300 --> 03:46:53,940
Yeah.

1920
03:46:53,940 --> 03:46:54,860
Yeah, let's look at it.

1921
03:46:54,860 --> 03:46:57,180
So one example is this FreeSurfer,

1922
03:46:57,180 --> 03:47:02,140
which is this Neo4j imaging suite, which

1923
03:47:02,140 --> 03:47:04,740
is they provide existing containers.

1924
03:47:04,740 --> 03:47:08,060
So it's easiest to install using that.

1925
03:47:08,060 --> 03:47:11,180
So for that, we have this module,

1926
03:47:11,180 --> 03:47:12,540
apptainer-freesurfer.

1927
03:47:12,540 --> 03:47:17,460
So if you load that, it will tell you

1928
03:47:17,460 --> 03:47:19,460
how to get more information on how to run it.

1929
03:47:19,460 --> 03:47:26,500
But we have read it, so [name] can maybe execute the command.

1930
03:47:26,500 --> 03:47:28,460
And is this a typo here?

1931
03:47:28,460 --> 03:47:30,300
Should that be a curly bracket?

1932
03:47:30,300 --> 03:47:31,220
Oh, that's true.

1933
03:47:31,220 --> 03:47:32,940
Yes, good point.

1934
03:47:32,940 --> 03:47:33,780
We need to fix that.

1935
03:47:33,780 --> 03:47:36,540
So now we run it with aptainer execute,

1936
03:47:36,540 --> 03:47:39,420
and I guess the path to it?

1937
03:47:39,420 --> 03:47:41,140
Yeah, the mesh path.

1938
03:47:41,140 --> 03:47:44,620
And then we execute some program inside of it.

1939
03:47:44,620 --> 03:47:46,340
So this is running.

1940
03:47:46,340 --> 03:47:49,820
So if I can unpack this command, apptainer's the container

1941
03:47:49,820 --> 03:47:50,580
program.

1942
03:47:50,580 --> 03:47:54,300
Exec means we want to run some command in a container.

1943
03:47:54,300 --> 03:47:58,020
Image path has been defined by the module that tells me

1944
03:47:58,020 --> 03:47:59,660
this is where the container is.

1945
03:47:59,660 --> 03:48:01,300
And if you make a container yourself,

1946
03:48:01,300 --> 03:48:03,980
you would just give it the path there directly.

1947
03:48:03,980 --> 03:48:04,700
Yeah.

1948
03:48:04,700 --> 03:48:08,380
And FreeSurfer is now a thing that will run inside of there.

1949
03:48:08,380 --> 03:48:11,260
So it's like it's starting up this other, almost

1950
03:48:11,260 --> 03:48:13,780
like an operating system that's self-contained with all

1951
03:48:13,780 --> 03:48:17,860
the stuff, and then says, hey, you, this box I just made,

1952
03:48:17,860 --> 03:48:19,140
run FreeSurfer.

1953
03:48:19,140 --> 03:48:23,660
And it connects it to what's outside.

1954
03:48:23,660 --> 03:48:24,420
Yes.

1955
03:48:24,420 --> 03:48:27,340
Yes, very well.

1956
03:48:27,340 --> 03:48:29,700
And I guess we can run it with the Help option

1957
03:48:29,700 --> 03:48:34,700
to verify that it does something in there.

1958
03:48:34,700 --> 03:48:42,340
And it sure looked like it gives us help from it.

1959
03:48:42,340 --> 03:48:48,620
And I guess if we do FreeSurfer outside the container,

1960
03:48:48,620 --> 03:48:49,420
there's nothing.

1961
03:48:49,420 --> 03:48:51,020
So yeah, OK.

1962
03:48:54,460 --> 03:49:01,100
Are there any other big, major ways of software?

1963
03:49:01,100 --> 03:49:02,940
I guess there's Conda that we already

1964
03:49:02,940 --> 03:49:04,780
went over in the morning.

1965
03:49:04,780 --> 03:49:10,820
So actually, what is the most common way of doing things?

1966
03:49:10,820 --> 03:49:14,740
Yeah, well, that's, at least in the Python world,

1967
03:49:14,740 --> 03:49:15,900
it's quite common.

1968
03:49:15,900 --> 03:49:19,260
But for many people who don't necessarily

1969
03:49:19,260 --> 03:49:22,780
like who want to use Python, but they don't necessarily

1970
03:49:22,780 --> 03:49:27,380
want to do stuff themselves or install their own environment,

1971
03:49:27,380 --> 03:49:30,020
we provide existing environments that

1972
03:49:30,020 --> 03:49:33,200
are like handcrafted to have a huge bunch of packages

1973
03:49:33,200 --> 03:49:36,560
available, at least here in Alta.

1974
03:49:36,560 --> 03:49:39,480
So we have this SciComp Python environment

1975
03:49:39,480 --> 03:49:42,240
that has a lot of packages already installed.

1976
03:49:42,240 --> 03:49:45,080
But of course, you can create your own environments.

1977
03:49:45,080 --> 03:49:53,120
So maybe we should demo that quickly, loading that.

1978
03:49:53,120 --> 03:49:56,640
Demo, ah, so the pre-made content things, yes, OK.

1979
03:49:56,640 --> 03:49:58,480
Yes.

1980
03:49:58,480 --> 03:50:00,080
And I have a visitor here.

1981
03:50:00,080 --> 03:50:05,000
So let's see how much I could type.

1982
03:50:05,000 --> 03:50:07,360
So module load.

1983
03:50:07,360 --> 03:50:12,200
And I know from my experience that it is called `scicomp-python-env`.

1984
03:50:17,280 --> 03:50:20,520
And what's in this environment?

1985
03:50:20,520 --> 03:50:26,320
A huge bunch of Python packages he installed already.

1986
03:50:26,320 --> 03:50:29,120
So now we can see that the Python has changed.

1987
03:50:29,120 --> 03:50:32,680
Like, what is the Python version that we're using?

1988
03:50:32,680 --> 03:50:34,880
It comes from our installation.

1989
03:50:36,040 --> 03:50:39,880
But like, yeah, these are something that we provide,

1990
03:50:39,880 --> 03:50:42,880
but there's a lot of stuff you can, of course, install yourself.

1991
03:50:42,880 --> 03:50:46,520
And if you encounter any problems, it's always a good idea to ask help

1992
03:50:47,040 --> 03:50:50,160
from the admins, or if you know a software

1993
03:50:50,160 --> 03:50:52,240
that other people might be interested in using,

1994
03:50:52,240 --> 03:50:56,000
it might be good to let us know, then we can install it for everybody.

1995
03:50:56,000 --> 03:50:59,600
in the cluster because that's that makes it life easier for everybody.

1996
03:51:00,320 --> 03:51:07,360
Yeah, and even if you aren't sure about it, you can ask. So there'll be sometimes we'll say,

1997
03:51:07,360 --> 03:51:13,040
okay, yeah, I mean, we haven't had many requests from this. It seems easier to install yourself

1998
03:51:13,040 --> 03:51:18,560
and we'll help you install it yourself. But as we see the patterns, we might add it to one of the

1999
03:51:18,560 --> 03:51:24,640
existing environments, especially if it's a Python or R thing, install it within one of these. If it's

2000
03:51:24,640 --> 03:51:29,640
it's LLM-related, install it to our standard LLM environment.

2001
03:51:33,040 --> 03:51:33,880
Yeah.

2002
03:51:33,880 --> 03:51:34,720
Yeah.

2003
03:51:34,720 --> 03:51:37,880
So, and depending on your, yeah,

2004
03:51:37,880 --> 03:51:41,640
but usually like as a good rule of thumb,

2005
03:51:41,640 --> 03:51:44,720
go check out module spider in the cluster

2006
03:51:44,720 --> 03:51:47,760
that you're running in and check what's there

2007
03:51:47,760 --> 03:51:51,560
and it's your program that you're planning on running there.

2008
03:51:51,560 --> 03:51:54,360
That's a good starting point usually.

2009
03:51:54,360 --> 03:52:00,680
and check the application page for the program.

2010
03:52:00,680 --> 03:52:06,240
But I think now is a good time to switch gears,

2011
03:52:06,240 --> 03:52:12,480
to talk about, like we have a talk by [name and [name].

2012
03:52:12,480 --> 03:52:15,240
And I think the cat is getting pretty hungry,

2013
03:52:15,240 --> 03:52:19,240
so it's a great time to switch.

2014
03:52:19,240 --> 03:52:19,740
Yeah.

2015
03:52:19,740 --> 03:52:31,740
There is this interesting question about using Python 2 on Triton.

2016
03:52:31,740 --> 03:52:37,100
So that's one of the cases where we'd say it's not installed in any default environment,

2017
03:52:37,100 --> 03:52:40,060
but you can install it yourself with Conda.

2018
03:52:40,060 --> 03:52:43,140
And then we point you that way and give you any help you might need.

2019
03:52:43,140 --> 03:52:45,420
And that's that basically.

2020
03:52:45,420 --> 03:52:52,700
Yeah. But also, I would say that if you have to run some Python 2 code, that's the least

2021
03:52:52,700 --> 03:53:00,180
of your worries. It's been deprecated for so long that transitioning to Python 3 in

2022
03:53:00,180 --> 03:53:08,780
that code might be... Asking people supporting you, can they help with the transition process

2023
03:53:08,780 --> 03:53:14,060
from Python 2 to Python 3 might be a good worthwhile investment.

2024
03:53:14,060 --> 03:53:17,940
Yeah, but I mean, if it's some code that they haven't made

2025
03:53:17,940 --> 03:53:22,780
and someone else is like, yeah, you just

2026
03:53:22,780 --> 03:53:26,020
aren't going to update that.

2027
03:53:26,020 --> 03:53:32,580
But yeah, OK, so with that said, let's close this out.

2028
03:53:32,580 --> 03:53:34,740
There's a lot more to read about applications.

2029
03:53:34,740 --> 03:53:37,300
We've just prepared you to do your own reading.

2030
03:53:37,300 --> 03:53:42,100
So by all means, go do that.

2031
03:53:42,100 --> 03:53:45,260
And if you have questions about the application of your choice,

2032
03:53:45,260 --> 03:53:48,580
put them into the notes, and we can try to answer, like,

2033
03:53:48,580 --> 03:53:51,060
well, how it should go about installing.

2034
03:53:51,060 --> 03:53:53,100
Keep writing there.

2035
03:53:53,100 --> 03:53:56,620
And now we're switching gears for the second to last session

2036
03:53:56,620 --> 03:54:01,620
of the day, which is a more philosophical discussion,

2037
03:54:01,620 --> 03:54:02,140
I guess.

2038
03:54:02,140 --> 03:54:07,220
So it's more about how you use stuff.

2039
03:54:07,220 --> 03:54:09,660
Or no, not how you use stuff, about how

2040
03:54:09,660 --> 03:54:11,540
you do the science itself.

2041
03:54:11,540 --> 03:54:16,580
And this is with [name], who's one of our, well,

2042
03:54:16,580 --> 03:54:18,620
I want to say one of the reproducibility people.

2043
03:54:18,620 --> 03:54:21,580
But really, we all care about reproducibility in science.

2044
03:54:21,580 --> 03:54:23,220
So anyway.

2045
03:54:23,220 --> 03:54:24,740
Yes.

2046
03:54:24,740 --> 03:54:26,300
Yeah, have a good one.

2047
03:54:26,300 --> 03:54:27,580
Thanks.

2048
03:54:27,580 --> 03:54:31,380
Can you switch to my share?

2049
03:54:31,380 --> 03:54:32,340
Screen share, please.

2050
03:54:32,340 --> 03:54:33,060
There you go.

2051
03:54:35,740 --> 03:54:37,380
And Thomas is also with me.

2052
03:54:37,380 --> 03:54:44,380
So, basically what we covered so far, you are now able to run so-called embarrassingly

2053
03:54:44,380 --> 03:54:50,780
parallel programs on a HPC cluster, and you understood how to manage the data, move the

2054
03:54:50,780 --> 03:54:54,020
data into the cluster, out from the cluster.

2055
03:54:54,020 --> 03:54:59,460
So I would say, well, I don't know if it's the majority of workflows, but a good portion

2056
03:54:59,460 --> 03:55:03,480
of the typical use of these systems is basically already covered.

2057
03:55:03,480 --> 03:55:10,640
The rest of the course will go more into parallelization, which is the so-called non-embarrassing parallelization

2058
03:55:10,640 --> 03:55:17,240
and this type of specific nodes that are called GPUs, but I don't want to spoil the fun so

2059
03:55:17,240 --> 03:55:19,920
you will hear later about this.

2060
03:55:19,920 --> 03:55:24,600
So to have a little break and consider if what you're doing is worth doing and I don't

2061
03:55:24,600 --> 03:55:31,600
want to, you know, depress anyone here, it's good to also consider and be aware of the

2062
03:55:31,600 --> 03:55:37,960
responsible conduct of research and specifically in the case of computation one could talk

2063
03:55:37,960 --> 03:55:45,800
about responsible computational research and you can write if you want in the notes document

2064
03:55:45,800 --> 03:55:51,600
what type of ethical or moral or legal issues that you might not even know that you have

2065
03:55:51,600 --> 03:55:56,080
or maybe you think that you have but they're not issues at all but in general what is making

2066
03:55:56,080 --> 03:56:02,120
you doubtful about your research. I wrote there, for example, that reproducibility,

2067
03:56:02,120 --> 03:56:10,320
which we have mentioned many times, is something that kind of I feel that often in my past

2068
03:56:10,320 --> 03:56:16,920
as a researcher that I had issues of reproducibility. What about you, [name]? What is your kind

2069
03:56:16,920 --> 03:56:17,920
of...

2070
03:56:17,920 --> 03:56:25,320
I completely agree. Either other people's stuff that I wanted to replicate or my own

2071
03:56:25,320 --> 03:56:31,160
stuff. In both cases, I had issues with getting things to run again.

2072
03:56:31,160 --> 03:56:35,920
Yeah. And you actually mentioned really well my own stuff, because one could think that

2073
03:56:35,920 --> 03:56:41,120
reproducibility is something, you know, I'm trying to figure out the universal law of

2074
03:56:41,120 --> 03:56:46,800
whatever. And, you know, it's good that other people repeat my experiment. But sometimes

2075
03:56:46,800 --> 03:56:51,360
the issue is really that I was doing six months ago something, and I was able to obtain some

2076
03:56:51,360 --> 03:56:56,560
results and I'm not able to rerun the same code anymore. Was it that the library has changed?

2077
03:56:56,560 --> 03:57:03,520
The operating system has changed? So this is very common. I've seen it many times with my work,

2078
03:57:03,520 --> 03:57:10,000
with other people's work. So a few of the topics that I will mention now, they cover or they show

2079
03:57:10,000 --> 03:57:15,440
you ways on how to deal with reproducibility issues. And you kind of already got a glimpse

2080
03:57:15,440 --> 03:57:20,400
of this when earlier we talked about Conda and the Conda environments and now someone was just

2081
03:57:20,400 --> 03:57:25,600
asking about Python 2 which is like traveling back in time and trying to reproduce or replicate

2082
03:57:25,600 --> 03:57:33,920
something from the past. So it's impossible to cover everything exhaustively when it comes to

2083
03:57:34,800 --> 03:57:39,920
research ethics and responsible conduct of research so I will try to give you a very

2084
03:57:39,920 --> 03:57:47,680
short five minutes intro but this page has lots of links that ideally every researcher should check

2085
03:57:47,680 --> 03:57:54,800
and read and be aware. The kind of conceptual framework that you can think of is the so-called

2086
03:57:54,800 --> 03:58:02,080
normative cascade which is how basically society works. You can understand that or you maybe feel

2087
03:58:02,080 --> 03:58:08,720
that there are these general ethics principles that can drive basically the creation of laws.

2088
03:58:08,720 --> 03:58:15,120
In the ideal case, ethics, all the good ethical principles would overlap completely with the laws

2089
03:58:15,120 --> 03:58:20,640
but in practice it is not like that, so there is never a full overlap between ethics and law.

2090
03:58:21,360 --> 03:58:28,880
And then of course laws will cause the creation or will influence so-called research policies,

2091
03:58:28,880 --> 03:58:35,360
so how the legislations stemming from the ethical principle will actually be applied in the work you

2092
03:58:35,360 --> 03:58:40,160
need to do with research. And then at the end of course it's the actual researchers that are

2093
03:58:40,160 --> 03:58:45,320
affected by the cascade. On the other hand, if the researchers notice that there are new

2094
03:58:45,320 --> 03:58:52,400
issues that the core ethical principle needs to be revised, they can together influence

2095
03:58:52,400 --> 03:58:57,960
the cascade and go back at the beginning and change the ethical principles.

2096
03:58:57,960 --> 03:59:02,440
So if we talk about the ethical principle, I'm not going to talk about as many ethical

2097
03:59:02,440 --> 03:59:08,180
principles. The Universal Declaration of Human Rights is one example. But in the context

2098
03:59:08,180 --> 03:59:13,520
of Research, I hope that everyone here, if you are in Europe, you should all read this

2099
03:59:13,520 --> 03:59:19,380
very short book which is the ALLEA European Code of Conduct for Research Integrity. Basically

2100
03:59:19,380 --> 03:59:23,760
there's everything there. If you know that book by heart, you just need to apply that

2101
03:59:23,760 --> 03:59:30,180
book whether you do computational science, I don't know, artistic research or whatever

2102
03:59:30,180 --> 03:59:36,500
type of research activities that you are doing. The four principles of the ALLEA Code of Conduct

2103
03:59:36,500 --> 03:59:44,020
are reliability, ensuring basically the quality of your of your research. Honesty, that what you

2104
03:59:44,020 --> 03:59:49,620
develop and what you do can be basically audited by others. So again, we're kind of covering this

2105
03:59:49,620 --> 03:59:55,300
type of reproducibility and transparency. And of course, respect is very important,

2106
03:59:55,300 --> 04:00:00,820
respect towards your colleagues, respect towards the administrator of your cluster, respect towards

2107
04:00:00,820 --> 04:00:07,660
the people that you will encounter on your career, others, authors in other universities

2108
04:00:07,660 --> 04:00:12,740
and more in general respects towards society and the ecosystem and so on.

2109
04:00:12,740 --> 04:00:20,100
And finally, accountability, given that, you know, from the accountability for the research

2110
04:00:20,100 --> 04:00:26,020
from the idea stage, the publication stage, and all its type of management and organisation,

2111
04:00:26,020 --> 04:00:31,580
which also requires you know this type of relationship between supervisor and mentors

2112
04:00:31,580 --> 04:00:39,140
and let's say junior researchers who are supervised and so on.

2113
04:00:39,140 --> 04:00:45,060
So that is kind of the general level and then from this core ethical principle there are

2114
04:00:45,060 --> 04:00:51,140
many legislations that apply to research where I will not go into the detail of any of these

2115
04:00:51,140 --> 04:00:54,740
But the typical case, maybe I can ask this actually to Thomas,

2116
04:00:54,740 --> 04:00:57,660
have you ever experienced in your work

2117
04:00:57,660 --> 04:01:00,020
that some researcher thinks

2118
04:01:00,020 --> 04:01:02,380
that they're not working with personal data,

2119
04:01:02,380 --> 04:01:05,180
but actually they were processing personal data?

2120
04:01:08,300 --> 04:01:09,620
Almost the other way around,

2121
04:01:09,620 --> 04:01:11,540
is there anything that's not personal data?

2122
04:01:11,540 --> 04:01:13,140
Exactly.

2123
04:01:16,060 --> 04:01:19,740
Yeah, I think the biggest issue with respect to personal data

2124
04:01:19,740 --> 04:01:27,820
is that it's really, really difficult to define what exactly personal data is, or rather what

2125
04:01:27,820 --> 04:01:30,700
does not constitute personal data anymore.

2126
04:01:30,700 --> 04:01:33,600
Yeah, I totally agree.

2127
04:01:33,600 --> 04:01:38,500
It's very difficult to anonymize data and we see this, you know, very often with people

2128
04:01:38,500 --> 04:01:41,820
who come and ask for help that they think that they're not presenting personal data

2129
04:01:41,820 --> 04:01:45,840
because whatever direct identifiers are missing.

2130
04:01:45,840 --> 04:01:51,300
But if it's a data about an individual, then let's just agree that it's personal data rather

2131
04:01:51,300 --> 04:01:56,400
than trying to mathematically demonstrate that the probability of re-identifying this

2132
04:01:56,400 --> 04:02:00,600
person is whatever is your favorite threshold.

2133
04:02:00,600 --> 04:02:05,860
But in general, again, here we don't have time and maybe we don't even have the energy

2134
04:02:05,860 --> 04:02:10,680
to go through legislations, but at least this list that is mentioned here is something that

2135
04:02:10,680 --> 04:02:18,440
you should be aware if your research kind of you know applies in this with this type of data.

2136
04:02:19,320 --> 04:02:26,920
And then of course from the core ethical principle to the legislation and regulations we have the

2137
04:02:26,920 --> 04:02:32,680
kind of national policies or even university level policies. So in the page you find some

2138
04:02:32,680 --> 04:02:37,240
links related to Aalto University but if you're from other university most likely you have the

2139
04:02:37,240 --> 04:02:42,680
similar policy whether it's about the ethical review if that's what you need in your research

2140
04:02:42,680 --> 04:02:50,040
or open science policies, open data policies, code of conduct and things like that.

2141
04:02:51,240 --> 04:03:00,440
So then at the end it's you the researchers who will depending on the case need to consider

2142
04:03:00,440 --> 04:03:08,200
these policies and this legislation and maybe these core ethical principles and trying to do

2143
04:03:08,200 --> 04:03:13,480
the best you can. I want to stress here that sometimes the best practices are some,

2144
04:03:15,000 --> 04:03:21,000
how can I say, state that it will never be reached and I really like that in this paper

2145
04:03:21,000 --> 04:03:27,800
by Wilson 2017 that is linked here, they mention good enough computational practices in this case

2146
04:03:27,800 --> 04:03:35,400
because sometimes it's trying to avoid that type of sloppy practices so that by adopting good

2147
04:03:35,400 --> 04:03:42,920
enough practices you can, you know, do the best you can and maybe slowly adopt more good enough

2148
04:03:42,920 --> 04:03:50,680
practices until you reach the best practices. I would like to add that one problem with

2149
04:03:50,680 --> 04:03:56,680
best practices is that very often to actually achieve best practices you need multiple people

2150
04:03:56,680 --> 04:04:05,720
working on the same thing and one person doesn't have all the knowledge and very often also not the

2151
04:04:06,440 --> 04:04:12,920
capabilities to do all things that would be best practice because it's just getting too much.

2152
04:04:13,720 --> 04:04:20,840
So this concept of good enough practices is something that is quite important in my opinion.

2153
04:04:20,840 --> 04:04:27,320
I totally agree. In this figure here, I tried to represent this is not exhaustive. I'm sure

2154
04:04:27,320 --> 04:04:33,880
there's more best practices in computational science and there's more, how should we call

2155
04:04:33,880 --> 04:04:40,680
them, worst practices. But in this continuum, so basically in the green side, we would have,

2156
04:04:40,680 --> 04:04:47,000
you know, that all the data is archived with the DOI, there is data versioning, we have protocols,

2157
04:04:47,000 --> 04:04:52,760
register protocols for data collection, version control for the code, so full reproducibility,

2158
04:04:52,760 --> 04:04:58,920
unit tests, you can add you know all the things that also we have mentioned today earlier,

2159
04:04:58,920 --> 04:05:03,560
and on the other end you really have this case that there are no backups, there's no documentation,

2160
04:05:03,560 --> 04:05:10,440
no readme file, no idea how to rerun things, no dependencies listed, no history log on which

2161
04:05:10,440 --> 04:05:17,480
script was from before the other. So I'm not asking you now, Thomas, to disclose something

2162
04:05:17,480 --> 04:05:24,040
sensitive, but if you put yourself in this type of continuum, or maybe let's rephrase this. Have

2163
04:05:24,040 --> 04:05:34,920
you had experience of some worst practices, actually? Okay, I have myself been in the

2164
04:05:34,920 --> 04:05:44,520
situation that I had code that was not documented well enough and that where I then two years later

2165
04:05:44,520 --> 04:05:50,440
was trying to think okay how did I do this, where did I put the configuration files, where did I do

2166
04:05:50,440 --> 04:05:57,640
this and that and needed to go back and not completely reinvent but it took me quite some

2167
04:05:57,640 --> 04:06:09,560
some time to set this up again. I have seen enough kind of bad things online from others

2168
04:06:09,560 --> 04:06:21,720
where it's like, you're providing the data, but informants that are completely unusable

2169
04:06:21,720 --> 04:06:26,720
and that essentially it would feel kind of more honest

2170
04:06:27,680 --> 04:06:29,240
to just not provide the data.

2171
04:06:31,600 --> 04:06:34,600
And I hope that I'm nowadays somewhere

2172
04:06:34,600 --> 04:06:39,600
on the yellow to greenish border there,

2173
04:06:40,680 --> 04:06:44,880
because yeah, I also won't be always able

2174
04:06:44,880 --> 04:06:48,600
to go through all the different things

2175
04:06:48,600 --> 04:06:52,440
that should be on the list.

2176
04:06:53,940 --> 04:06:58,100
Because it's also quite a bit of things

2177
04:06:58,100 --> 04:07:03,100
come with a lot of administrative work,

2178
04:07:03,120 --> 04:07:05,020
which essentially means

2179
04:07:05,020 --> 04:07:06,780
while you're doing the administrative work

2180
04:07:06,780 --> 04:07:08,100
on a couple of things,

2181
04:07:08,100 --> 04:07:10,580
you're not actually doing anything

2182
04:07:10,580 --> 04:07:13,460
to progress the project that you have.

2183
04:07:13,460 --> 04:07:18,460
And that's getting frustrating very quickly.

2184
04:07:18,600 --> 04:07:26,080
I agree. And the administrative work is sometimes not even valued, meaning that, for example,

2185
04:07:26,080 --> 04:07:31,560
I wrote this here, this single folder for all projects where all the researchers from

2186
04:07:31,560 --> 04:07:36,200
the same group have read and write. And, you know, basically I've seen myself, I was part

2187
04:07:36,200 --> 04:07:41,600
of this type of, you know, gigantic research folders where things, I don't know, more

2188
04:07:41,600 --> 04:07:47,240
or less self-organized, but never really, you know, nobody had the time to do this type

2189
04:07:47,240 --> 04:07:55,160
of administrative work, even though the policies, whether they come from EU horizon or whether

2190
04:07:55,160 --> 04:07:59,920
they come from Academy of Finland, they kind of stress the importance of managing the data

2191
04:07:59,920 --> 04:08:05,720
and managing the software. But, you know, maybe you get a very good point earlier that

2192
04:08:05,720 --> 04:08:10,960
when it's not anymore this type of single person job that needs to do everything from

2193
04:08:10,960 --> 04:08:17,080
inventing the idea, collecting the data, writing the code, if it becomes a teamwork that then

2194
04:08:17,080 --> 04:08:24,920
you have the data steward, the research software engineer, and then it's the researchers,

2195
04:08:24,920 --> 04:08:30,440
the expert can focus on their expertise. And then in the end, best practices and even

2196
04:08:30,440 --> 04:08:39,640
administrative tasks can be taken care of. Just along those lines, I often see the problem that

2197
04:08:39,640 --> 04:08:44,640
that I would like to follow best practices,

2198
04:08:45,080 --> 04:08:50,080
but the best practices are written down so vaguely that,

2199
04:08:52,680 --> 04:08:54,420
yeah, like I just said,

2200
04:08:54,420 --> 04:08:57,080
they stress that you should care about data management,

2201
04:08:57,080 --> 04:08:58,680
but how?

2202
04:08:58,680 --> 04:09:00,140
What should you actually do?

2203
04:09:03,100 --> 04:09:06,400
These kind of really concrete guidelines,

2204
04:09:06,400 --> 04:09:09,520
they are, at least to me, very often lacking.

2205
04:09:13,840 --> 04:09:14,800
Just to mention it again,

2206
04:09:14,800 --> 04:09:17,440
with the administrative stuff that is undervalued,

2207
04:09:19,000 --> 04:09:20,680
especially as a researcher

2208
04:09:20,680 --> 04:09:23,120
that does something with personal data,

2209
04:09:23,120 --> 04:09:27,640
you fill in the same data into 20 different forms

2210
04:09:27,640 --> 04:09:31,440
to submit to 20 different places for approval.

2211
04:09:31,440 --> 04:09:32,600
And it gets really frustrating.

2212
04:09:32,600 --> 04:09:34,320
Why can't you just do this once?

2213
04:09:34,320 --> 04:09:39,320
and everyone who wants to know something can extract from what you just submitted.

2214
04:09:39,320 --> 04:09:47,320
So these are the kind of things that then lead to people not following protocol, not, yeah.

2215
04:09:47,320 --> 04:09:49,320
Yeah.

2216
04:09:49,320 --> 04:09:54,320
But I would say in general, I feel that things are much better.

2217
04:09:54,320 --> 04:09:58,320
I don't know if it's because I've been involved in dealing with these issues,

2218
04:09:58,320 --> 04:10:03,320
but maybe there is more awareness in general among researchers.

2219
04:10:03,320 --> 04:10:10,120
It is getting better. Also because higher levels are enforcing it more.

2220
04:10:11,320 --> 04:10:18,840
That's too good. All right, but basically to conclude, this page also has this little mention

2221
04:10:18,840 --> 04:10:23,880
of cyber security and again the point here, you know, it's not to give a course on cyber

2222
04:10:23,880 --> 04:10:28,680
security and most likely your organization has a mandatory course on cyber security.

2223
04:10:28,680 --> 04:10:34,200
What is very important that I often try to remind to our researchers is that they need to understand

2224
04:10:34,200 --> 04:10:39,400
the classification of information, meaning that they need to understand whether it's a script,

2225
04:10:39,400 --> 04:10:45,000
whether it's a piece of data, whether it's your internal note or the picture for the summer trip

2226
04:10:45,000 --> 04:10:50,840
of the department. You need to understand is it public data, is it internal data,

2227
04:10:50,840 --> 04:10:58,120
is it confidential or is it secret. In general you could assume that most of the work we do

2228
04:10:58,680 --> 04:11:04,960
goes between the confidential or internal if you are for example drafting a paper or

2229
04:11:04,960 --> 04:11:10,440
still working on something that you're not ready to fully make public.

2230
04:11:10,440 --> 04:11:15,320
But then of course there's also lots of public work that we do whether it's our open source

2231
04:11:15,320 --> 04:11:19,680
code projects web pages and things like that.

2232
04:11:19,680 --> 04:11:24,600
Maybe I would say that a minority of us need to work with secret data but of course there

2233
04:11:24,600 --> 04:11:27,160
There are legislations, for example,

2234
04:11:27,160 --> 04:11:29,320
when you need to reuse health data,

2235
04:11:29,320 --> 04:11:31,960
so data that was collected for medical purposes.

2236
04:11:31,960 --> 04:11:35,680
There are legislation that forces to be secret.

2237
04:11:35,680 --> 04:11:39,680
Then in this last three minutes, we

2238
04:11:39,680 --> 04:11:42,640
were discussing a few days ago that it's

2239
04:11:42,640 --> 04:11:46,440
important to maybe mention what could be the issues,

2240
04:11:46,440 --> 04:11:48,240
whether they are ethical or legal.

2241
04:11:48,240 --> 04:11:53,760
It's a blurt of using generative AI in your daily work.

2242
04:11:53,760 --> 04:11:58,600
Now here, I try to think of many types of issues,

2243
04:11:58,600 --> 04:12:00,280
but to keep it short without,

2244
04:12:00,280 --> 04:12:02,940
you can read the whole thing yourself.

2245
04:12:02,940 --> 04:12:06,200
In general, I see when it comes to computational science

2246
04:12:06,200 --> 04:12:09,000
as to write code, that there could be

2247
04:12:09,000 --> 04:12:12,000
this type of unwanted plagiarism issues

2248
04:12:12,000 --> 04:12:14,720
that I might be, that the generative AI

2249
04:12:14,720 --> 04:12:18,280
might synthesize some code that is verbatim,

2250
04:12:18,280 --> 04:12:20,900
some excerpt from a library,

2251
04:12:20,900 --> 04:12:23,520
but then I might not realize this,

2252
04:12:23,520 --> 04:12:25,520
most likely I would not start searching

2253
04:12:25,520 --> 04:12:28,240
if that code is verbatim from a library.

2254
04:12:28,240 --> 04:12:30,560
And then the issues becomes that maybe that library

2255
04:12:30,560 --> 04:12:32,640
had a specific type of software license

2256
04:12:32,640 --> 04:12:35,080
that wouldn't allow me to reuse it

2257
04:12:35,080 --> 04:12:38,160
unless I also adopt the same license.

2258
04:12:38,160 --> 04:12:41,560
There's no point here to go down to these details,

2259
04:12:41,560 --> 04:12:44,560
but you can understand that there are multiple risks

2260
04:12:44,560 --> 04:12:46,920
of using this type of generative AI

2261
04:12:46,920 --> 04:12:50,440
without carefully considering basically the output.

2262
04:12:50,440 --> 04:12:55,240
So again, if you are so-called vibe coding afternoon project

2263
04:12:55,240 --> 04:12:58,840
because you just want to make some funny cat pictures

2264
04:12:58,840 --> 04:13:01,560
through some code, maybe it's OK.

2265
04:13:01,560 --> 04:13:05,120
But if you're writing the core functions for your research

2266
04:13:05,120 --> 04:13:09,160
analysis, and you are not sure if the output

2267
04:13:09,160 --> 04:13:12,000
from this generative AI system is the actual output

2268
04:13:12,000 --> 04:13:16,000
that you would need, you need to reconsider or maybe

2269
04:13:16,000 --> 04:13:19,320
ask for help from other experts for doing code review

2270
04:13:19,320 --> 04:13:25,880
things like that. Maybe one that I like to mention is recently they noticed that

2271
04:13:27,480 --> 04:13:33,160
when you work for example with Python you might need to import some NumPy or Pandas or whatever

2272
04:13:33,160 --> 04:13:37,400
and if you don't have them in your system you need to pip install NumPy, Pandas and so on.

2273
04:13:38,120 --> 04:13:44,120
And recently there are some consistent hallucinations of packages and then in the Python

2274
04:13:44,120 --> 04:13:48,840
ecosystem but also in many other languages there is this type of typosquatting so that

2275
04:13:48,840 --> 04:13:54,840
malicious people actually have created packages with a similar name and then you do a typo when

2276
04:13:54,840 --> 04:14:02,200
you or the generative AI does a typo and then suddenly you have basically you know some

2277
04:14:02,200 --> 04:14:09,240
malware installed in your system. I would like to add something that also recently came up

2278
04:14:09,240 --> 04:14:20,280
when it comes to tools allowing the LLM to collect and process additional data or additional

2279
04:14:20,280 --> 04:14:29,400
public data, and particularly if that same thing also allows the model to access some

2280
04:14:29,400 --> 04:14:35,600
private information, because there have been recent attacks where essentially the public

2281
04:14:35,600 --> 04:14:42,440
data that was consumed by the LLM contained instructions to the LLM, at which point it

2282
04:14:42,440 --> 04:14:51,460
generated content that, when you looked at it, had image links or things in there that

2283
04:14:51,460 --> 04:14:57,780
essentially were leaking private information.

2284
04:14:57,780 --> 04:15:09,860
So essentially my recommendation is assume that the LLM is just another human, just another

2285
04:15:09,860 --> 04:15:15,700
random human and think about whether you want to give it access to whatever you are currently

2286
04:15:15,700 --> 04:15:19,700
giving it access to and that includes the whole conversation that you're currently having with it.

2287
04:15:20,980 --> 04:15:26,500
I had to quote this, it's not [name]'s quote but [name] often says this that there is no cloud

2288
04:15:26,500 --> 04:15:31,860
computing it's just someone else's computer and in my opinion it's the whole point because unless

2289
04:15:31,860 --> 04:15:37,940
you run these LLMs locally and truly locally in your machine you're just sending data to

2290
04:15:37,940 --> 04:15:43,860
somebody else's computer and even if they promise don't worry we will never give this data to anyone

2291
04:15:43,860 --> 04:15:52,100
you know it's exactly yeah all right but hopefully this was motivational enough to think if what

2292
04:15:52,100 --> 04:15:58,660
you're doing is good, is right, is moral, is ethical, is legal and so on. Feel free to

2293
04:15:59,300 --> 04:16:06,980
write something in the chat of this type of philosophical thoughts but I guess it's time

2294
04:16:06,980 --> 04:16:12,340
for a break and then later we can go back to code and computing. Thank you Thomas for

2295
04:16:12,340 --> 04:16:20,820
the nice conversation and I guess see you in 10 minutes

2296
04:16:20,820 --> 04:16:26,580
I don't see any clock now so 12 p.m. bye

2297
04:16:42,340 --> 04:16:44,400
you

2298
04:17:12,340 --> 04:17:14,400
you

2299
04:17:42,340 --> 04:17:44,400
you

2300
04:18:12,340 --> 04:18:14,400
you

2301
04:18:42,340 --> 04:18:44,400
you

2302
04:19:12,340 --> 04:19:14,400
you

2303
04:19:42,340 --> 04:19:44,400
you

2304
04:20:12,340 --> 04:20:14,400
you

2305
04:20:42,340 --> 04:20:44,400
you

2306
04:21:12,340 --> 04:21:14,400
you

2307
04:21:42,340 --> 04:21:44,400
you

2308
04:22:12,340 --> 04:22:14,400
you

2309
04:22:42,340 --> 04:22:44,400
you

2310
04:23:12,340 --> 04:23:14,400
you

2311
04:23:42,340 --> 04:23:44,400
you

2312
04:24:12,340 --> 04:24:14,400
you

2313
04:24:42,340 --> 04:24:44,400
you

2314
04:25:12,340 --> 04:25:14,400
you

2315
04:25:42,340 --> 04:25:44,400
you

2316
04:26:12,340 --> 04:26:14,400
you

2317
04:26:42,340 --> 04:26:54,180
Oh, hello.

2318
04:26:54,180 --> 04:26:55,860
We are back.

2319
04:26:55,860 --> 04:26:58,140
Hello, hello.

2320
04:26:58,140 --> 04:27:00,780
So I see a shadow moving under the table.

2321
04:27:00,780 --> 04:27:04,740
I wonder if my feet are about to be attacked.

2322
04:27:04,740 --> 04:27:06,940
OK.

2323
04:27:06,940 --> 04:27:10,740
Yes, so we're back for the last session of the day.

2324
04:27:10,740 --> 04:27:12,260
Go ahead, [name].

2325
04:27:12,260 --> 04:27:14,420
Yeah, I was going to say the exact same thing.

2326
04:27:14,420 --> 04:27:16,140
Yeah, you go right ahead.

2327
04:27:16,140 --> 04:27:18,940
OK, last session of the day.

2328
04:27:18,940 --> 04:27:21,580
And this is something which you need a little bit

2329
04:27:21,580 --> 04:27:22,620
of an introduction to.

2330
04:27:22,620 --> 04:27:24,880
But like many things, you'll probably

2331
04:27:24,880 --> 04:27:30,780
come back to it in more depth whenever you actually need it.

2332
04:27:30,780 --> 04:27:33,780
We're not telling you how to write code in parallel,

2333
04:27:33,780 --> 04:27:36,900
but how if you have a code which should run in parallel,

2334
04:27:36,900 --> 04:27:42,300
how you can actually use it and run it on the cluster.

2335
04:27:42,300 --> 04:27:42,860
Yeah.

2336
04:27:42,860 --> 04:27:44,340
Maybe.

2337
04:27:44,340 --> 04:27:46,020
So let's look at, maybe we should

2338
04:27:46,020 --> 04:27:52,340
start with the picture of the Shared Memory Parallelism.

2339
04:27:52,340 --> 04:27:53,100
OK.

2340
04:27:53,100 --> 04:27:56,900
So I'm opening this page.

2341
04:27:56,900 --> 04:27:57,400
Yes.

2342
04:28:00,300 --> 04:28:02,420
I need to go to the right screen.

2343
04:28:02,420 --> 04:28:02,980
There we go.

2344
04:28:02,980 --> 04:28:03,980
Yes.

2345
04:28:03,980 --> 04:28:08,780
So yeah, we talked previously about the Embarrassingly Parallel and the

2346
04:28:10,700 --> 04:28:17,340
like array jobs and how to run it. Lots of individual jobs basically in the cluster and

2347
04:28:17,340 --> 04:28:22,140
that's already like very good, like you can get a lot of stuff. But there's of course a lot more

2348
04:28:23,340 --> 04:28:27,740
available left on the table when it comes to the parallelism in the cluster because the

2349
04:28:27,740 --> 04:28:31,580
the computing nodes, like these computers,

2350
04:28:31,580 --> 04:28:36,420
they are basically, the CPUs are pretty similar

2351
04:28:36,420 --> 04:28:39,680
to what you would have in your laptop or in your computer,

2352
04:28:39,680 --> 04:28:42,100
but there's just usually more of them.

2353
04:28:42,100 --> 04:28:43,420
They're like server CPUs,

2354
04:28:43,420 --> 04:28:46,740
and they usually have much more resources.

2355
04:28:46,740 --> 04:28:49,020
They have more memory, more CPUs.

2356
04:28:49,020 --> 04:28:52,580
So if it's possible for your code

2357
04:28:52,580 --> 04:28:55,460
to utilize all of those resources,

2358
04:28:55,460 --> 04:28:59,620
you can, in theory, get a lot of speed up to your code.

2359
04:29:01,140 --> 04:29:05,220
And you can get your code done faster.

2360
04:29:05,220 --> 04:29:07,980
And that's basically this part of the parallel.

2361
04:29:07,980 --> 04:29:12,500
So the array jobs are more like maximum throughput

2362
04:29:12,500 --> 04:29:13,340
kind of parallel.

2363
04:29:13,340 --> 04:29:15,780
You get maximum amount of jobs through the system

2364
04:29:15,780 --> 04:29:18,260
and maximum amount of stuff done.

2365
04:29:18,260 --> 04:29:20,620
And they're very good if you have this kind of problem

2366
04:29:20,620 --> 04:29:22,380
that you can split into chunks.

2367
04:29:22,380 --> 04:29:24,620
But if you have like, let's say a big simulation

2368
04:29:24,620 --> 04:29:30,620
something and it just takes a long time. It takes a long time and it would benefit from

2369
04:29:30,620 --> 04:29:37,900
having multiple CPUs to run on. Then, yeah, let's look how you can do that in the cluster.

2370
04:29:39,020 --> 04:29:49,740
Okay. Should I go to the terminal for a demo? Yeah. So, there's two things you need to

2371
04:29:49,740 --> 04:29:53,900
think about. So, the first thing, of course, is that does your program work in parallel? Can it

2372
04:29:53,900 --> 04:30:02,460
do stuff in Parallel? That's a big question. Many programs can nowadays because many normal

2373
04:30:02,460 --> 04:30:09,500
computers have multiple CPUs. They are nowadays written to be able to utilize those CPUs. For

2374
04:30:09,500 --> 04:30:17,180
example, if you use Python, libraries like NumPy, Scikit-learn or whatever, they allow you to use

2375
04:30:17,180 --> 04:30:26,060
parallel CPUs natively, or MATLAB does. Or if you use R, you can use parallel in R to do it.

2376
04:30:26,060 --> 04:30:32,940
And there's various ways you can run without many code changes utilized. But of course,

2377
04:30:32,940 --> 04:30:39,340
like the efficiency, whether you get best efficiency, that is up to the air. But at

2378
04:30:39,340 --> 04:30:43,500
at least in principle, they could utilize multiple CPUs.

2379
04:30:45,180 --> 04:30:49,020
And to test it out in the cluster right now,

2380
04:30:49,020 --> 04:30:51,540
maybe [name], if you were on module purge

2381
04:30:51,540 --> 04:30:56,540
to verify that there's no like previous modules loaded.

2382
04:30:57,060 --> 04:30:57,940
Yes.

2383
04:30:57,940 --> 04:31:02,940
So we can start by testing out an example code that we have,

2384
04:31:02,940 --> 04:31:05,820
by testing out an example code that we have,

2385
04:31:05,820 --> 04:31:09,420
which is the Pi code that we mentioned previously

2386
04:31:09,420 --> 04:31:10,780
in the example.

2387
04:31:10,780 --> 04:31:15,700
So we have this in the Slurm folder,

2388
04:31:15,700 --> 04:31:16,540
that is Pi code.

2389
04:31:16,540 --> 04:31:18,900
And if you give it like a thousand or whatever,

2390
04:31:18,900 --> 04:31:20,820
like a number of thousands,

2391
04:31:20,820 --> 04:31:23,780
and if you run it like here in the login node,

2392
04:31:25,060 --> 04:31:26,820
okay, you see that.

2393
04:31:26,820 --> 04:31:27,660
That's very fast.

2394
04:31:28,940 --> 04:31:30,140
Yes, it's very fast,

2395
04:31:30,140 --> 04:31:32,540
but of course it's only like a thousand tries.

2396
04:31:32,540 --> 04:31:35,180
And this is like a very simple code,

2397
04:31:35,180 --> 04:31:37,700
but because it only does calculations,

2398
04:31:37,700 --> 04:31:39,460
it's quite easy to parallelize.

2399
04:31:39,460 --> 04:31:42,380
And that's why we can use it as an example

2400
04:31:42,380 --> 04:31:47,060
of how do you reserve resources with multiple CPUs.

2401
04:31:47,060 --> 04:31:50,260
So let's try running this in the queue

2402
04:31:50,260 --> 04:31:52,940
with a bit more requirements.

2403
04:31:52,940 --> 04:31:55,660
So if you add the normal stuff at the front there,

2404
04:31:55,660 --> 04:31:57,780
like srun meme.

2405
04:31:57,780 --> 04:32:08,740
what does this dash dash pty mean yes so we didn't think i'm copying yeah yeah we didn't

2406
04:32:08,740 --> 04:32:14,820
mention it before but you can add this that's a pty and it means like zelda terminal so

2407
04:32:14,820 --> 04:32:22,500
uh what it means that it will uh without spaces origin yeah i'm just verifying i'm doing it right

2408
04:32:22,500 --> 04:32:33,700
Yeah, like the PTY, it will allocate like the input and output for the terminal. So, basically,

2409
04:32:33,700 --> 04:32:38,660
if your code would have like interactive stuff and that sort of things, like it would ask for

2410
04:32:38,660 --> 04:32:42,820
input or something, it will work. It prints, yeah, okay.

2411
04:32:43,540 --> 04:32:48,340
Yeah, it will print everything automatically. It looks just like the normal shell. Okay, yeah.

2412
04:32:48,340 --> 04:32:53,700
Yeah, if you're running with this interactive SRUN, you might sometimes want to add the PTY there.

2413
04:32:54,820 --> 04:33:01,140
Yeah. But yeah, so let's add a bit more numbers here. So we have now, what's, is it 50 million?

2414
04:33:01,140 --> 04:33:07,060
It's 50 million. Yeah. Yes. So let's run it. It takes a bit longer. So this is about,

2415
04:33:07,940 --> 04:33:11,940
I think, maybe 40 seconds or something, if I remember correctly.

2416
04:33:11,940 --> 04:33:19,620
vc srun says it's queued. And now this is doing what we learned in the interactive job part

2417
04:33:20,820 --> 04:33:27,460
yesterday. And this is the kind of a program that, okay, like this could use multiple CPUs and it

2418
04:33:27,460 --> 04:33:34,260
could run faster with multiple CPUs. So let's get first a benchmark. What often you want to do is

2419
04:33:34,260 --> 04:33:40,740
that you want to, if you have this sort of like a program, you first want to try running it out

2420
04:33:40,740 --> 04:33:48,500
without any bells and whistles like with single CPU and then see how long does it take. If you're

2421
04:33:48,500 --> 04:33:53,860
running it already on your own computer you can look at the process manager usually and see how

2422
04:33:53,860 --> 04:34:00,500
many processors it's using and then try using the same sort of requirements in Triton for that.

2423
04:34:02,740 --> 04:34:05,460
So it shouldn't take that much more longer.

2424
04:34:05,460 --> 04:34:13,780
Yeah, let's see.

2425
04:34:13,780 --> 04:34:17,980
But we can see that, like, yeah, it takes, okay, now we can, yeah.

2426
04:34:17,980 --> 04:34:19,020
So it took some time.

2427
04:34:19,020 --> 04:34:23,260
Maybe if you run quickly the seff to check what is the, how long did it take?

2428
04:34:23,260 --> 04:34:34,620
On the job ID, and it says 95% efficiency for 40 seconds

2429
04:34:34,620 --> 04:34:38,220
and 42 real-time seconds.

2430
04:34:38,220 --> 04:34:46,860
So if we now want to allocate more CPUs for this job,

2431
04:34:46,860 --> 04:34:52,780
what we need to do is tell Slurm that we want more CPUs.

2432
04:34:52,780 --> 04:35:01,980
That's done with this CPUs per task flag. We just say CPUs per task, and let's put four

2433
04:35:02,860 --> 04:35:09,820
equals four. This would allocate four CPUs for that. We'll talk about tasks later. You don't have

2434
04:35:09,820 --> 04:35:23,780
I can't worry about that too much right now, but that is just a Slurm internal thing.

2435
04:35:23,780 --> 04:35:27,660
But basically, you just specify how many CPUs you want to get.

2436
04:35:27,660 --> 04:35:30,980
And we need, of course, the code to understand this as well.

2437
04:35:30,980 --> 04:35:36,420
The code needs to be able to utilize those, because otherwise, it might run with a single

2438
04:35:36,420 --> 04:35:37,500
CPU.

2439
04:35:37,500 --> 04:35:45,660
So in this case, we use this nprox, dash dash nprox, and we give the same number.

2440
04:35:45,660 --> 04:35:49,980
And it's important that the numbers match, because otherwise you might run into a situation

2441
04:35:49,980 --> 04:35:57,140
where you reserve more CPUs than you use, or you use more CPUs than you reserve.

2442
04:35:57,140 --> 04:36:03,420
And in both cases, like in the case where you reserve too many, you underutilize the

2443
04:36:03,420 --> 04:36:04,420
CPUs.

2444
04:36:04,420 --> 04:36:06,540
So you basically underutilize the resources.

2445
04:36:06,540 --> 04:36:12,540
And if you use too many CPUs, they can get crowded.

2446
04:36:12,540 --> 04:36:19,900
So they compete on who gets to use the CPUs, and then the code runs slower.

2447
04:36:19,900 --> 04:36:25,100
So sometimes if you run some code in the cluster, you might encounter a situation where it runs

2448
04:36:25,100 --> 04:36:26,100
slower.

2449
04:36:26,100 --> 04:36:29,340
And the reason might be that it tries to use, let's say, all of the CPUs, but it's only

2450
04:36:29,340 --> 04:36:32,340
getting one, and suddenly it's slow.

2451
04:36:32,340 --> 04:36:39,060
you need to tell the code to actually use the CPUs you want it to use. So let's try this out.

2452
04:36:41,700 --> 04:36:49,940
And I guess this is a hard problem. I've often seen codes that say it can use multiple

2453
04:36:49,940 --> 04:36:54,580
processors, but it doesn't tell you how it actually works. So you don't know if it's doing

2454
04:36:54,580 --> 04:37:00,900
the right thing. The most annoying one is when you run something and it says,

2455
04:37:00,900 --> 04:37:04,420
Oh, I'm running on a computer node that has 40 processors.

2456
04:37:04,420 --> 04:37:05,740
So I'll try to use 40.

2457
04:37:05,740 --> 04:37:07,940
But it's actually only been allocated four.

2458
04:37:07,940 --> 04:37:14,380
And it's just a huge slow down then.

2459
04:37:14,380 --> 04:37:15,260
OK, it's done.

2460
04:37:15,260 --> 04:37:16,060
Should be seff.

2461
04:37:16,060 --> 04:37:16,860
Yeah.

2462
04:37:16,860 --> 04:37:19,300
Yes, if we check the efficiency of that.

2463
04:37:22,420 --> 04:37:25,220
So compared to my other nodes, this

2464
04:37:25,220 --> 04:37:31,220
says 83% efficiency, compared to 95.

2465
04:37:31,220 --> 04:37:35,820
And we ran the same 40 seconds of CPU utilization,

2466
04:37:35,820 --> 04:37:38,380
because that's how long it takes to run.

2467
04:37:38,380 --> 04:37:42,660
But now it took a shorter amount of time in real time.

2468
04:37:42,660 --> 04:37:45,780
Only 12 real time.

2469
04:37:45,780 --> 04:37:46,260
OK.

2470
04:37:46,260 --> 04:37:48,980
And so basically, it's nothing magical

2471
04:37:48,980 --> 04:37:53,420
about the reserving of CPUs in the submission scripts

2472
04:37:53,420 --> 04:37:57,860
Or in the command line, you can just

2473
04:37:57,860 --> 04:38:00,140
specify the CPUs per task to SLURM,

2474
04:38:00,140 --> 04:38:06,380
and that will give you more resources.

2475
04:38:06,380 --> 04:38:09,780
And there's a nice question in the notes.

2476
04:38:09,780 --> 04:38:12,260
Are you going to answer the same thing?

2477
04:38:12,260 --> 04:38:12,980
Yeah, go ahead.

2478
04:38:12,980 --> 04:38:15,380
I guess we're thinking the same thing.

2479
04:38:15,380 --> 04:38:16,180
You can say it.

2480
04:38:16,180 --> 04:38:16,940
You can say it.

2481
04:38:16,940 --> 04:38:17,780
Yeah.

2482
04:38:17,780 --> 04:38:20,540
So what I've just highlighted here,

2483
04:38:20,540 --> 04:38:27,820
This is the argument to srun and to slurm. So, the CPUs per task equals 4 is a slurm option

2484
04:38:27,820 --> 04:38:34,940
that says please give whatever I'm running for CPUs. And then that wraps this other command.

2485
04:38:35,820 --> 04:38:45,980
And the --nprocs=4 is a command that was programmed into the pi.py file, which tells it I have four

2486
04:38:45,980 --> 04:38:50,620
processors available, I can try to use them. And you can tell if these don't match up,

2487
04:38:50,620 --> 04:38:56,460
then stuff can go wrong. Should we demonstrate what happens if you don't get it right?

2488
04:38:57,980 --> 04:39:03,580
Or is that just maybe people can do that themselves? Yeah, I would say probably.

2489
04:39:05,580 --> 04:39:15,820
But yeah, so maybe we should just jump into exercises. If the exercise is basically

2490
04:39:15,820 --> 04:39:24,460
do the same thing. Okay. Yeah, I see it's already appearing in the notes there.

2491
04:39:25,340 --> 04:39:31,740
Oops, I copied the wrong one. Sorry. Check the right one.

2492
04:39:36,540 --> 04:39:44,380
But yeah, the question is, how do you tell the program what you want it to get?

2493
04:39:45,820 --> 04:39:54,380
Yeah. How do you tell the program what resources it should use? In many cases, this is something

2494
04:39:54,380 --> 04:40:04,300
like nprocs. Many programs use this OMP_NUM_THREADS environment variable, and they use that. For

2495
04:40:04,300 --> 04:40:11,060
example, NumPy uses that to determine how many processes it should use. They are all

2496
04:40:11,060 --> 04:40:18,980
listed in the documentation. So, there's many environment variables that sometimes set these

2497
04:40:19,940 --> 04:40:25,380
numbers. And if you look at the documentation of a library that you're using, it might say

2498
04:40:26,100 --> 04:40:35,060
that, hey, give it the number of processes with n processes or nprocs or nthreads or whatever.

2499
04:40:35,060 --> 04:40:41,220
like there might be various flags for there's no like consistent language across the board

2500
04:40:41,780 --> 04:40:48,420
so you need to look at your your application and if it provides a possibility of using

2501
04:40:48,420 --> 04:40:54,100
multiple processors and if it does you need to give the information to it

2502
04:40:56,260 --> 04:41:02,020
yeah and there's a good question what's the limit of the number of CPUs a program can use

2503
04:41:02,020 --> 04:41:11,620
Yes, that's an excellent question. And the answer is that it depends on the hardware.

2504
04:41:11,620 --> 04:41:18,900
Like in many clusters, you have compute nodes that might have a number of CPUs that might

2505
04:41:18,900 --> 04:41:26,060
run from, let's say, 28 to 256 or something like that. It might be small or it might be

2506
04:41:26,060 --> 04:41:31,940
very large. But because you're all limited into this one computer, so it depends on the

2507
04:41:31,940 --> 04:41:35,060
hardware available in your cluster.

2508
04:41:35,060 --> 04:41:40,220
And of course, you might reach the parallelism maximum.

2509
04:41:40,220 --> 04:41:42,900
At some point, it doesn't run any faster

2510
04:41:42,900 --> 04:41:46,940
after you reach a certain number of processors.

2511
04:41:46,940 --> 04:41:50,100
Usually, quite often, magical numbers

2512
04:41:50,100 --> 04:41:53,180
might be something like 8 or 16 or something.

2513
04:41:53,180 --> 04:41:55,140
But there might be something that

2514
04:41:55,140 --> 04:41:58,860
works with 64 or 128 as well.

2515
04:41:58,860 --> 04:42:03,100
Yeah. I guess it really depends on what it is you're doing.

2516
04:42:04,220 --> 04:42:08,140
Yeah. But usually it's on that ballpark. So we're talking about tens to hundred

2517
04:42:09,260 --> 04:42:16,860
processors usually. Yeah. So how long should people have to try this themselves? And is there

2518
04:42:16,860 --> 04:42:23,180
anything else to try other than what we just did? Let's just do this. I think that's enough.

2519
04:42:23,180 --> 04:42:36,060
and you can run stuff in the examples and run more exercises as a bonus exercise after the courses.

2520
04:42:38,220 --> 04:42:43,420
I will also note that in the exercise, there's a submission script that you can test out,

2521
04:42:43,420 --> 04:42:47,980
and in that we're using an environment variable called slurm CPUs per task,

2522
04:42:47,980 --> 04:42:52,780
which is very useful if you want the job to find out the number of CPUs

2523
04:42:53,180 --> 04:43:01,820
automatically. So Slurm will set this number if you ask for more than one CPU. So you can

2524
04:43:01,820 --> 04:43:07,700
use that in your code to determine numbers. But try it out.

2525
04:43:07,700 --> 04:43:11,300
Okay. How much time do you have, people?

2526
04:43:11,300 --> 04:43:14,300
Like 35, maybe?

2527
04:43:14,300 --> 04:43:23,100
Still 35. So that's seven minutes or six. Well, seven minutes. Okay. Yeah. Okay.

2528
04:43:25,100 --> 04:43:30,940
Then see you in a little bit. Yeah. Bye. Bye.

2529
04:43:44,300 --> 04:43:46,360
you

2530
04:44:14,300 --> 04:44:16,360
you

2531
04:44:44,300 --> 04:44:46,360
you

2532
04:45:14,300 --> 04:45:16,360
you

2533
04:45:44,300 --> 04:45:46,360
you

2534
04:46:14,300 --> 04:46:16,360
you

2535
04:46:44,300 --> 04:46:46,360
you

2536
04:47:14,300 --> 04:47:16,360
you

2537
04:47:44,300 --> 04:47:46,360
you

2538
04:48:14,300 --> 04:48:16,360
you

2539
04:48:44,300 --> 04:48:46,360
you

2540
04:49:14,300 --> 04:49:16,360
you

2541
04:49:44,300 --> 04:49:55,620
We're back.

2542
04:49:55,620 --> 04:49:56,620
Hello.

2543
04:49:56,620 --> 04:49:57,220
Hello.

2544
04:49:57,220 --> 04:50:02,700
So what now?

2545
04:50:02,700 --> 04:50:07,940
I think we'll go straight to the next parallel part

2546
04:50:07,940 --> 04:50:11,740
and take all the questions later.

2547
04:50:11,740 --> 04:50:13,620
Yeah, if you want to fill out, I'm

2548
04:50:13,620 --> 04:50:16,900
adding the poll to the exercise block.

2549
04:50:16,900 --> 04:50:18,500
Forgot to add it previously.

2550
04:50:18,500 --> 04:50:24,460
So if you want to feel there, if you

2551
04:50:24,460 --> 04:50:26,900
managed to do the exercises, sorry about there

2552
04:50:26,900 --> 04:50:32,500
being quite not that much time for these.

2553
04:50:32,500 --> 04:50:35,380
But hopefully, you got it done.

2554
04:50:35,380 --> 04:50:39,220
But yeah, asking to see this, it's basically one flag.

2555
04:50:39,220 --> 04:50:46,580
So hopefully, you got it done.

2556
04:50:46,580 --> 04:50:49,260
But yeah, now we are switching gears to,

2557
04:50:49,260 --> 04:50:53,540
so this is quite a quick explanation

2558
04:50:53,540 --> 04:50:59,060
of the overview of the MPI, like parallelism, what it is.

2559
04:50:59,060 --> 04:51:03,380
So there was already a question in the notes about,

2560
04:51:03,380 --> 04:51:07,500
OK, how can I parallelize across multiple CPUs?

2561
04:51:07,500 --> 04:51:11,020
So how can I analyze across multiple computers, basically?

2562
04:51:11,020 --> 04:51:16,380
And this is why MPI originally was created, like the MPI thing.

2563
04:51:16,380 --> 04:51:20,140
So MPI stands for Message Passing Interface.

2564
04:51:20,700 --> 04:51:24,220
And it's basically like this kind of library that allows you to do

2565
04:51:25,580 --> 04:51:30,940
message passing between computers and different processes running on different CPUs

2566
04:51:31,580 --> 04:51:34,140
through various network messes.

2567
04:51:34,140 --> 04:51:42,540
When writing for these supercomputers, there's a high-speed interconnect usually connecting

2568
04:51:42,540 --> 04:51:45,620
these CPU nodes.

2569
04:51:45,620 --> 04:51:51,620
If you want to have a really large program, so if you think about a weather model, if

2570
04:51:51,620 --> 04:51:57,300
you want to predict the weather, you need to have a very big simulation of the weather

2571
04:51:57,300 --> 04:52:05,620
happening at different places, at different times, and you integrate the physics equations

2572
04:52:05,620 --> 04:52:10,820
to get the next time step of, okay, what is the weather going to be tomorrow?

2573
04:52:10,820 --> 04:52:15,620
And for that, you need a big computer to calculate together.

2574
04:52:15,620 --> 04:52:20,020
You need the whole simulation to be able to be calculated together.

2575
04:52:20,020 --> 04:52:23,340
And for that, MPI has been constructed, basically.

2576
04:52:23,340 --> 04:52:32,620
it's still a standard in many of the supercomputers when it comes to this kind of big-scale programs.

2577
04:52:37,740 --> 04:52:45,980
It's important to remember about MPI is that either your code uses MPI or it doesn't.

2578
04:52:47,980 --> 04:52:53,020
If your code hasn't been constructed around MPI, if it hasn't been constructed in a way

2579
04:52:53,020 --> 04:53:01,980
that it will use message-passing interface, it won't use it. So it's very important to remember

2580
04:53:01,980 --> 04:53:07,740
that if it uses MPI, if you see in the documentation that there's an MPI build of this,

2581
04:53:07,740 --> 04:53:14,460
or you can add MPI support or whatever, then it uses MPI. Or if you build a program from the

2582
04:53:14,460 --> 04:53:19,100
ground up to use MPI, then it uses MPI. But if it doesn't, then it doesn't.

2583
04:53:19,100 --> 04:53:25,340
Making a new MPI program is a very big process.

2584
04:53:25,340 --> 04:53:36,340
Yeah, depending on the program, but yes, usually you need to figure out whether your program can use MPI.

2585
04:53:36,340 --> 04:53:44,340
But there's already lots of programs, especially physics programs and that sort of stuff, that use MPI on the background.

2586
04:53:44,340 --> 04:53:46,780
And for those users of those programs,

2587
04:53:46,780 --> 04:53:49,780
this is a very good way.

2588
04:53:49,780 --> 04:53:51,900
Like, you just install your program

2589
04:53:51,900 --> 04:53:55,260
with the MPI capabilities available,

2590
04:53:55,260 --> 04:53:57,740
and then you can utilize multiple computers

2591
04:53:57,740 --> 04:53:59,020
at the same time.

2592
04:53:59,020 --> 04:53:59,980
Yeah.

2593
04:53:59,980 --> 04:54:02,540
So should we do the example?

2594
04:54:02,540 --> 04:54:03,780
Yes.

2595
04:54:03,780 --> 04:54:05,660
Let's look at the example.

2596
04:54:05,660 --> 04:54:12,340
So we have the Pi version written with MPI support.

2597
04:54:12,340 --> 04:54:16,420
And because you need to bake it into the program,

2598
04:54:16,420 --> 04:54:19,580
so the Python version doesn't cut it.

2599
04:54:19,580 --> 04:54:22,860
There is this MPI for Python that you can use

2600
04:54:22,860 --> 04:54:27,060
to use Python and MPI together,

2601
04:54:27,060 --> 04:54:29,180
which is a nice library if you want to start,

2602
04:54:29,180 --> 04:54:30,740
if you just want to use Python,

2603
04:54:30,740 --> 04:54:33,460
but that requires additional libraries.

2604
04:54:33,460 --> 04:54:37,020
So for this example, we are going to use C,

2605
04:54:38,020 --> 04:54:42,220
like C compiled, like C version of a program

2606
04:54:42,220 --> 04:54:47,820
does the exact same calculation that the Python one did, but it does it in C and it uses MPI.

2607
04:54:48,700 --> 04:54:55,100
Okay, and so how do I start? So in order to, usually when you have an MPI program,

2608
04:54:55,100 --> 04:55:00,220
the first thing you need to do is you need to load up the MPI installed by the cluster

2609
04:55:00,220 --> 04:55:09,740
administrators, because the MPI is tied directly to the queue system and it's tied to the network

2610
04:55:09,740 --> 04:55:17,660
infrastructure. So it's very laborious usually to install the MPI. So that's why the system

2611
04:55:17,660 --> 04:55:23,180
administrators usually provide it and you install your code using that MPI.

2612
04:55:23,980 --> 04:55:26,060
This will be different for every cluster.

2613
04:55:26,780 --> 04:55:36,140
Yes, yes. So if you run module spider MPI, open MPI is one flavor of MPI. That might be

2614
04:55:36,140 --> 04:55:38,980
be something you want to use.

2615
04:55:38,980 --> 04:55:43,500
So then we can compile our program using MPI CC.

2616
04:55:43,500 --> 04:55:57,540
So if you type `mpicc -o pi-mpi slurm/pi-mpi.c`.

2617
04:55:57,540 --> 04:55:58,980
Yeah.

2618
04:55:58,980 --> 04:56:03,540
So what this does is, yeah.

2619
04:56:03,540 --> 04:56:13,380
What it does is it compiles this `pi.mpi` executable that is now MPI-capable.

2620
04:56:13,380 --> 04:56:17,820
You can check what the source code is if you want to.

2621
04:56:17,820 --> 04:56:20,840
But now, okay, we have this.

2622
04:56:20,840 --> 04:56:26,780
Maybe you should try running it with srun, with the normal stuff, and see how it goes.

2623
04:56:26,780 --> 04:56:38,640
Like, if we just put like 10 minutes and 500 megabytes of memory and just run it.

2624
04:56:38,640 --> 04:56:44,840
So without anything, it should run similarly.

2625
04:56:44,840 --> 04:56:48,080
How many steps should I do?

2626
04:56:48,080 --> 04:56:52,000
Let's put the same 50 million.

2627
04:56:52,000 --> 04:56:54,240
It shouldn't take that long because it's C code,

2628
04:56:54,240 --> 04:56:57,040
so it's faster than the Python code.

2629
04:56:57,040 --> 04:56:57,800
Let's see.

2630
04:56:57,800 --> 04:57:00,000
I bet it will be very fast.

2631
04:57:03,800 --> 04:57:04,440
Yeah.

2632
04:57:04,440 --> 04:57:08,000
So it's quite a bit faster.

2633
04:57:08,000 --> 04:57:10,280
Should we SF it?

2634
04:57:10,280 --> 04:57:12,440
Yeah, sure.

2635
04:57:12,440 --> 04:57:13,080
Yeah.

2636
04:57:13,080 --> 04:57:18,760
So it said it used one second of CPU and took one second.

2637
04:57:18,760 --> 04:57:21,080
So it's quite a bit faster than the Python version.

2638
04:57:21,080 --> 04:57:29,640
So that's how it usually goes if you use the lower level stuff instead of like higher level

2639
04:57:29,640 --> 04:57:30,880
languages.

2640
04:57:30,880 --> 04:57:34,720
Of course, Python can be fast if you use the correct libraries, but in this case.

2641
04:57:34,720 --> 04:57:35,720
Yeah.

2642
04:57:35,720 --> 04:57:39,960
I mean, that's why you write a C library and run it from Python.

2643
04:57:39,960 --> 04:57:44,160
Or you use NumPy and that's fast itself.

2644
04:57:44,160 --> 04:57:48,440
But in this case, let's try now adding some more MPI tasks.

2645
04:57:48,440 --> 04:57:50,320
You notice that in the output,

2646
04:57:50,320 --> 04:57:54,580
it said that what was the computer's name,

2647
04:57:54,580 --> 04:57:55,940
where it was running,

2648
04:57:55,940 --> 04:57:58,420
and then it says something about rank.

2649
04:57:58,420 --> 04:58:00,980
MPI has these MPI ranks,

2650
04:58:00,980 --> 04:58:09,360
so basically, every CPU in the MPI tasks,

2651
04:58:09,360 --> 04:58:11,080
it's this rank number.

2652
04:58:11,080 --> 04:58:12,860
It's similar to the array ID,

2653
04:58:12,860 --> 04:58:14,060
but in this case,

2654
04:58:14,060 --> 04:58:16,160
they are like a collective.

2655
04:58:16,160 --> 04:58:19,560
So in the MPI, everybody works as a collective,

2656
04:58:19,560 --> 04:58:21,840
and they get this number.

2657
04:58:21,840 --> 04:58:24,720
So we can ask for more of these tasks.

2658
04:58:24,720 --> 04:58:28,080
So previously, when we saw the CPUs per task kind

2659
04:58:28,080 --> 04:58:30,120
of a situation, so these are now the tasks

2660
04:58:30,120 --> 04:58:32,640
that we are requesting.

2661
04:58:32,640 --> 04:58:43,120
So if you give the SRUN n tasks, yeah, nodes 1 and n tasks.

2662
04:58:43,120 --> 04:58:45,440
Let's go with 4, yeah.

2663
04:58:45,440 --> 04:58:46,440
Yeah, okay.

2664
04:58:46,440 --> 04:58:54,200
And let's add at least one zero at the end, so we get some like reasonable, like 10 times,

2665
04:58:54,200 --> 04:58:55,200
make it 10 times harder.

2666
04:58:55,200 --> 04:58:59,240
So maybe it runs for a few seconds.

2667
04:58:59,240 --> 04:59:00,240
Okay.

2668
04:59:00,240 --> 04:59:08,500
So, in this case, what we are asking the queue system, we are asking, okay, give me one computer

2669
04:59:08,500 --> 04:59:15,060
and give me four, on one computer, give me four of these MPI tasks.

2670
04:59:15,060 --> 04:59:17,700
So we didn't mention the CPUs per task here.

2671
04:59:17,700 --> 04:59:20,620
We are asking these MPI tasks.

2672
04:59:20,620 --> 04:59:26,980
And what it does basically is that when the program starts, it starts the individual programs

2673
04:59:26,980 --> 04:59:33,900
and then each of these connects into a collective that then solves the problem together.

2674
04:59:33,900 --> 04:59:39,180
But if you use the end tasks without an MPI program, you run into all sorts of problems

2675
04:59:39,180 --> 04:59:44,640
and the same program might run multiple times and overlap.

2676
04:59:44,640 --> 04:59:53,120
don't use the end tasks if you don't have an MPI program. Okay. Yeah. And I guess the pi-mpi,

2677
04:59:53,120 --> 04:59:58,960
we didn't tell it how many tasks there were, so it sort of automatically knows what's available.

2678
04:59:58,960 --> 05:00:05,520
Yes. It creates this communication world where everybody knows about each other and then they

2679
05:00:05,520 --> 05:00:11,360
can do the work together. And you might see here that the output is a bit scrambled because

2680
05:00:11,360 --> 05:00:18,080
everybody works independently and they might print out stuff in different orders. Some might

2681
05:00:18,880 --> 05:00:25,920
print out stuff before the other tasks. It's like one starting zero, it's done,

2682
05:00:25,920 --> 05:00:32,080
and then two and three report they're starting. But that's pretty typical when

2683
05:00:32,080 --> 05:00:38,560
you're trying to do this stuff. Anyway, should we SF it? Yes, let's do that.

2684
05:00:41,360 --> 05:00:48,360
It used nine seconds of CPU and the efficiency wasn't three seconds.

2685
05:00:48,360 --> 05:00:53,360
Yeah, because the efficiency wasn't that good because it's still so short.

2686
05:00:53,360 --> 05:00:57,360
So if we would have increased the.

2687
05:00:57,360 --> 05:01:01,360
Yeah, like these numbers are so short, it's not good statistics.

2688
05:01:01,360 --> 05:01:03,360
So, yeah.

2689
05:01:03,360 --> 05:01:09,360
It's clearly taking those times four and dividing nine by that.

2690
05:01:09,360 --> 05:01:10,360
Yeah.

2691
05:01:10,360 --> 05:01:11,360
Okay.

2692
05:01:11,360 --> 05:01:17,400
And in the notes, we have a good question of like, does it mean that the end tasks for

2693
05:01:17,400 --> 05:01:22,400
that we run for independent tasks and they are not independent.

2694
05:01:22,400 --> 05:01:26,040
They are a collective, like in MPI, everything is a collective.

2695
05:01:26,040 --> 05:01:34,000
So there's like four tasks running in the same collective, which is the whole program.

2696
05:01:34,000 --> 05:01:43,000
So let's say you would run with 30 computers, if you run in Mahti or if you run in Lumi

2697
05:01:43,000 --> 05:01:48,480
or somewhere like a really big machine, you might run with, let's say, a thousand processors.

2698
05:01:48,480 --> 05:01:53,280
And in those cases, you need to run with, let's say, 20 computers.

2699
05:01:53,280 --> 05:02:02,800
So you might ask for a thousand tasks and then get that from the queue system.

2700
05:02:02,800 --> 05:02:09,040
technically, it's not threads here, but it's independent processes that communicate between

2701
05:02:09,040 --> 05:02:14,640
each other. But if that doesn't make any sense to you, it really doesn't matter.

2702
05:02:15,680 --> 05:02:28,000
Yeah. But yes, so this MPI is still, for many bigger things, it's still very

2703
05:02:28,000 --> 05:02:31,200
like very heavily utilized.

2704
05:02:31,200 --> 05:02:34,440
But it's like many of the smaller programs,

2705
05:02:34,440 --> 05:02:39,720
it's usually better to use the array structure in addition

2706
05:02:39,720 --> 05:02:45,680
with the shared memory parallelism to run your stuff.

2707
05:02:45,680 --> 05:02:48,400
Because this requires your program

2708
05:02:48,400 --> 05:02:52,400
to support this from the ground up, basically.

2709
05:02:52,400 --> 05:02:54,520
OK, so what now?

2710
05:02:54,520 --> 05:02:57,040
We've got 12 minutes left.

2711
05:02:57,040 --> 05:03:01,360
Should we give people time to try it themselves and then come for a wrap-up?

2712
05:03:01,360 --> 05:03:02,360
Yes.

2713
05:03:02,360 --> 05:03:03,360
Okay.

2714
05:03:03,360 --> 05:03:06,840
Yeah, I will copy the commands we run.

2715
05:03:06,840 --> 05:03:20,480
In here also there's the SBatch script that you can use to run this in the queue.

2716
05:03:20,480 --> 05:03:28,480
And do note that if you're running this in the queue with the script, you will want to

2717
05:03:28,480 --> 05:03:36,400
add the srun before you run the program.

2718
05:03:36,400 --> 05:03:40,760
And the reason, well, it depends on the cluster, but in most clusters, you want to do this.

2719
05:03:40,760 --> 05:03:48,560
And the reason for that is that the srun basically ties the program to the queue system that

2720
05:03:48,560 --> 05:03:52,640
then tells each program that they're part of the collective.

2721
05:03:52,640 --> 05:03:54,560
If you don't run it with the `srun`,

2722
05:03:54,560 --> 05:03:56,160
they don't necessarily understand

2723
05:03:56,160 --> 05:03:59,040
that they're supposed to know about the other ones.

2724
05:03:59,040 --> 05:04:03,840
Because basically, Slurm starts multiple processes

2725
05:04:03,840 --> 05:04:04,600
at the same time.

2726
05:04:04,600 --> 05:04:07,720
And all of those call home and ask, who am I?

2727
05:04:07,720 --> 05:04:11,040
And then they start working as a collective.

2728
05:04:11,040 --> 05:04:15,200
So if you don't add the `srun`, then the program

2729
05:04:15,200 --> 05:04:20,000
doesn't necessarily work as intended.

2730
05:04:20,000 --> 05:04:20,500
Yeah.

2731
05:04:26,720 --> 05:04:28,160
OK, there's the exercise stuff.

2732
05:04:28,160 --> 05:04:30,640
So should we return at what time?

2733
05:04:35,320 --> 05:04:38,760
Maybe, again, five minutes and then have a wrap up.

2734
05:04:38,760 --> 05:04:40,360
Yeah, OK.

2735
05:04:40,360 --> 05:04:43,280
We'll take a short bit of time, see what you can do.

2736
05:04:43,280 --> 05:04:44,640
See you in five minutes.

2737
05:04:44,640 --> 05:04:46,480
and bye for now.

2738
05:05:14,640 --> 05:05:16,700
you

2739
05:05:44,640 --> 05:05:46,700
you

2740
05:06:14,640 --> 05:06:16,700
you

2741
05:06:44,640 --> 05:06:46,700
you

2742
05:07:14,640 --> 05:07:16,700
you

2743
05:07:44,640 --> 05:07:46,700
you

2744
05:08:14,640 --> 05:08:16,700
you

2745
05:08:44,640 --> 05:08:46,700
you

2746
05:09:14,640 --> 05:09:16,700
you

2747
05:09:44,640 --> 05:09:58,560
Hello, we're back, all four of us.

2748
05:09:58,560 --> 05:10:05,560
So yeah, what's the wrap up here?

2749
05:10:05,560 --> 05:10:11,720
From the notes, there's some good questions.

2750
05:10:14,640 --> 05:10:18,600
a question like, what does nodes and what does tasks mean?

2751
05:10:18,600 --> 05:10:22,800
The different MPI implementations.

2752
05:10:22,800 --> 05:10:25,280
This can get really deep really fast.

2753
05:10:25,280 --> 05:10:30,880
And I guess we're not even trying to go into it that deep.

2754
05:10:30,880 --> 05:10:31,720
Yeah.

2755
05:10:31,720 --> 05:10:35,320
So I highly suggest looking at our documentation

2756
05:10:35,320 --> 05:10:37,320
and other sites documentation if you plan

2757
05:10:37,320 --> 05:10:38,640
on using any of these frameworks.

2758
05:10:38,640 --> 05:10:41,360
Like the problem with, I would say,

2759
05:10:41,360 --> 05:10:44,400
like there was a great feedback that there

2760
05:10:44,400 --> 05:10:48,960
be more exercises, and I completely agree. But especially for these topics, it's very hard to

2761
05:10:48,960 --> 05:10:54,880
have exercises because they depend so heavily on the application. But the main thing to remember,

2762
05:10:54,880 --> 05:11:02,080
I would say, is to remember that these are the paradigms that are usable in the systems.

2763
05:11:02,080 --> 05:11:11,040
If you have a program that mentions something about threads or workers or whatever,

2764
05:11:11,040 --> 05:11:14,160
it usually means that you can use multiple CPUs.

2765
05:11:14,160 --> 05:11:16,560
And if you have something that mentions MPI,

2766
05:11:16,560 --> 05:11:18,480
then it usually can use MPI.

2767
05:11:18,480 --> 05:11:22,080
And remembering these words and these connections

2768
05:11:22,080 --> 05:11:24,200
allows you to then ask the queue

2769
05:11:24,200 --> 05:11:25,760
to provide you those resources.

2770
05:11:25,760 --> 05:11:28,240
But those exact flags you want to use

2771
05:11:28,240 --> 05:11:30,360
and exact implementations you want to use

2772
05:11:30,360 --> 05:11:32,760
differ based on the cluster.

2773
05:11:32,760 --> 05:11:35,160
And then it's good to look at the documentation.

2774
05:11:35,160 --> 05:11:37,960
But basically, in order to make the connection

2775
05:11:37,960 --> 05:11:43,880
okay, now we are talking about this sort of approach is very good, because then you can

2776
05:11:45,240 --> 05:11:49,000
make certain that your code uses all the resources it can use.

2777
05:11:50,440 --> 05:11:57,320
Yeah. And I see in the notes here, there's two questions about weird internal MPI errors,

2778
05:11:57,960 --> 05:12:05,560
which are caused by who knows what. And yeah, this is what I think of when I think of MPI. So,

2779
05:12:05,560 --> 05:12:09,140
So having to figure out the cluster thing,

2780
05:12:09,140 --> 05:12:12,260
get your code working, get all the problems solved,

2781
05:12:12,260 --> 05:12:15,140
it can make stuff run faster, but it takes some time

2782
05:12:15,140 --> 05:12:17,140
to figure it out.

2783
05:12:17,140 --> 05:12:20,460
And at least if you're at Aalto, come ask us

2784
05:12:20,460 --> 05:12:23,680
rather than digging into it, unless you just

2785
05:12:23,680 --> 05:12:26,940
want to dig into it, in which case, by all means, go ahead.

2786
05:12:26,940 --> 05:12:30,460
And I don't think we can really answer these here.

2787
05:12:30,460 --> 05:12:33,460
Who knows what it is?

2788
05:12:35,560 --> 05:12:40,920
I guess you've probably seen there's feedback of the day here.

2789
05:12:40,920 --> 05:12:42,840
You can start filling that in.

2790
05:12:42,840 --> 05:12:48,720
Is there anything about parallel or any other general questions we should answer before

2791
05:12:48,720 --> 05:12:51,440
we leave for the day?

2792
05:12:51,440 --> 05:12:55,360
I guess if so, write them down.

2793
05:12:55,360 --> 05:13:01,220
Any other general questions we may have missed from before or you'd like us to talk more.

2794
05:13:01,220 --> 05:13:05,780
So what's the expectations for day three now?

2795
05:13:09,140 --> 05:13:10,620
We covered what was in the schedule.

2796
05:13:13,220 --> 05:13:18,060
Are there many exercises and hands-on things tomorrow?

2797
05:13:18,060 --> 05:13:21,740
Does anyone know?

2798
05:13:21,740 --> 05:13:25,140
Well, at least in the GPU part, we

2799
05:13:25,140 --> 05:13:28,700
will be doing some small examples.

2800
05:13:28,700 --> 05:13:36,300
But again, it depends on the application you're using.

2801
05:13:36,300 --> 05:13:39,660
So it's quite a hard thing to say.

2802
05:13:39,660 --> 05:13:44,460
And in the LLM session, in the example,

2803
05:13:44,460 --> 05:13:48,340
we will definitely show you how you can do stuff, at least

2804
05:13:48,340 --> 05:13:49,060
here in Aalto.

2805
05:13:49,060 --> 05:13:53,740
And we show code that you can use to run local LLMs.

2806
05:13:53,740 --> 05:14:01,340
But yeah, we will have hands-on exercises, but of course, yeah.

2807
05:14:03,580 --> 05:14:07,060
Depends on how involved you want to be.

2808
05:14:10,220 --> 05:14:17,700
And we also have two philosophical sessions, one about how to ask for help with supercomputers,

2809
05:14:17,700 --> 05:14:23,060
which is a talk written by one of our collaborators in Norway, but I'll be

2810
05:14:23,060 --> 05:14:30,420
presenting. It sort of gives you some insight for, you know, when and how and what it's like

2811
05:14:31,140 --> 05:14:38,260
to ask for support. And then there's a wrap-up session at the end of the day which has 20

2812
05:14:38,260 --> 05:14:42,900
minutes budgeted. And what's usually happened other years, sort of all the instructors come

2813
05:14:42,900 --> 05:14:49,220
here and you can ask us all the questions about anything at all. So all the big broad things,

2814
05:14:49,220 --> 05:14:56,260
putting stuff together and we can see what happens there. So, yeah.

2815
05:15:03,380 --> 05:15:09,700
Yeah, so do stay for that. And I guess there's nothing special to prepare. If you have access

2816
05:15:09,700 --> 05:15:16,260
to the cluster, you can probably run the stuff we do tomorrow. The GPU stuff may be different

2817
05:15:16,260 --> 05:15:22,980
on different clusters. So it would be good to review the GPU info for whatever cluster you have

2818
05:15:23,620 --> 05:15:27,620
and then come prepared with that tomorrow to see if you can get it working.

2819
05:15:30,100 --> 05:15:37,540
Or even see if you can get it working over the night. If you are hungry for more exercises,

2820
05:15:37,540 --> 05:15:44,100
like all of the tutorial pages linked in the material, they have at the end multiple exercises.

2821
05:15:44,100 --> 05:15:49,900
Because if you want to do them, and even better, if you want to give feedback on if you had

2822
05:15:49,900 --> 05:15:55,460
done them, like how could they be improved, or which one would you want to see in the

2823
05:15:55,460 --> 05:15:58,660
course, let us know, that would be great.

2824
05:15:58,660 --> 05:16:05,300
But no worries, there's no homework, we don't force you to do something if you don't want

2825
05:16:05,300 --> 05:16:06,300
to do it.

2826
05:16:06,300 --> 05:16:13,980
But if you feel like you still have the hunger to write some Slurm scripts, do go and check

2827
05:16:13,980 --> 05:16:15,260
the tutorial, basically.

2828
05:16:18,700 --> 05:16:21,700
Yeah, OK.

2829
05:16:21,700 --> 05:16:22,540
Great.

2830
05:16:22,540 --> 05:16:27,940
Should we wrap up for now?

2831
05:16:31,380 --> 05:16:36,580
And I guess see you tomorrow at the same time.

2832
05:16:36,580 --> 05:16:37,080
Yeah.

2833
05:16:37,080 --> 05:16:39,380
Come prepared for all your stuff.

2834
05:16:39,380 --> 05:16:45,740
Yeah, OK, great.

2835
05:16:45,740 --> 05:16:50,220
Have a good, or wait, was there any other feedback questions?

2836
05:16:50,220 --> 05:16:52,380
No, no questions.

2837
05:16:52,380 --> 05:16:54,580
Lots of love for the cat.

2838
05:16:54,580 --> 05:16:57,660
Yeah, thanks for all the stuff.

2839
05:16:57,660 --> 05:16:59,420
Hopefully cats will come back tomorrow.

2840
05:16:59,420 --> 05:17:04,580
It's only morning, so it might be sleeping.

2841
05:17:04,580 --> 05:17:07,340
OK, great, see you later.

2842
05:17:07,340 --> 05:17:08,620
See you.

2843
05:17:08,620 --> 05:17:09,120
Bye.

2844
05:17:38,620 --> 05:17:40,680
you

2845
05:18:08,620 --> 05:18:10,680
you

2846
05:18:38,620 --> 05:18:40,680
you

