- workshop_title: HPC/SciComp Kickstart summer 2025
- workshop_description: >
    This is part of the Aalto Scientific Computing "Getting started
    with Scientific Computing and HPC Kickstart" 2025
    workshop.  The videos are available to everyone, but may be most
    useful to the people who attended the workshop and want to review
    later.

    This course covers the basics of using HPC clusters and related
    scientific computing skills like data management, reproducible
    research, GPUs, etc.

    Playlist: https://www.youtube.com/playlist?list=PLZLVmS9rf3nNK5qWN6FdrQPHns4fNZyMX

    Workshop webpage: https://scicomp.aalto.fi/training/scip/kickstart-2025/

    Aalto Scientific Computing: https://scicomp.aalto.fi/


- input: raw/day1-obs.mkv
- schedulesync: 02:04:01=11:44:21

#- output: out/day1-icebreaker.mkv
#  title: 1.1 Icebreaker
#  description: >-
#    General discussion before the workshop starts, about who we are
#    and what we do.  You probably want to skip this unless you want to
#    get a feeling for the course.
#
#  editlist:
#  - start: 00:06:46
#  - end: 00:17:14


- output: out/day1-intro.mkv
  title: 1.1 Introduction
  description: >-
    General introduction to the workshop.

    https://scicomp.aalto.fi/training/kickstart/intro/

  editlist:
  - start: 00:21:44
  - end: 00:30:41


#- output: out/day1-from-data-storage-to-your-science.mkv
#  title: "1.3 From data storage to your science"
#  description: >-
#    Data is how most computational work starts, whether it is
#    externally collected, simulation code, or generated. And these
#    days, you can work on data even remotely, and these workflows
#    aren't obvious. We discuss how data storage choices lead to
#    computational workflows.
#
#    https://hackmd.io/@AaltoSciComp/SciCompIntro
#
#  editlist:
#  - start: 00:27:30
#  - end: 00:41:48
#
#- output: out/day1-computational-reproducibility.mkv
#  title: 1.4 (Computational) reproducibility and open science
#  description: >-
#    Transparency in science is one of the core principles in research
#    integrity.  Did you know that half of published studies are
#    actually not reproducible?  Here we give an overview of
#    CodeRefinery learning materials for those who want to start
#    picking up good enough practices like git version control, clear
#    project folder structure, conda environments, containers.
#
#    You can read more about CodeRefinery and its dedicated workshops
#    at https://coderefinery.org/ .
#
#    https://coderefinery.github.io/reproducible-research/
#
#
#  editlist:
#  - start: 00:41:48
#  - end: 01:06:59
#
#
#
#
#- output: out/day1-what-can-do-with-cluster.mkv
#  title: "1.6 What can you do with a computational cluster?"
#  description: >-
#    A couple of real examples of how people use the cluster
#    1) Multi-cpu-node computations with LAMMPS, 2) text synthesis
#    with open source Large Language Models (LLMs).  This is a preview
#    of what we will be learning the next two days, but it is *not*
#    supposed to be enough to understand how to do it right now.
#
#  editlist:
#    - start: 01:42:08
#    - 01:43:24: "First demo: LAMMPS molecular dynamics simulator using MPI"
#    - 01:55:30: "Second demo: Visualizing with the Open OnDemand desktop"
#    - 02:00:00: "Third example: Deep learning with LLM inference"
#    - stop: 02:08:12

- output: out/day1-hpc-kitchen.mkv
  title: 1.2 The HPC Kitchen
  description: >-
    A computer cluster, or "supercomputer" may seem like some powerful
    thing, but it's composed of a lot of relatively normal computers.
    It can be hard to wrap your head around what this means, so we
    present a clear metaphor to cooking.  We don't have time to do the
    metaphor properly, so this is just the start and you can
    read/watch more below.

    Material: https://docs.google.com/presentation/d/16BTILZlUvEzCt6FfMsB9sSZm0PZHHXLBthE5QfoSrjo/edit

    Video playlist: https://www.youtube.com/watch?v=yqGtnA7CUtU&list=PLZLVmS9rf3nNDHRo1Baz_JVQWDI0mTYyB

  editlist:
    - start: 00:31:35
    - 00:39:20: 'Q&A'
    - stop: 00:44:40


- output: out/day1-connecting.mkv
  title: 1.3 Connecting to the cluster
  description: >-
    How to connect to the cluster.  This is in preparation for
    tomorrow, and not needed right now.  We give various demos, but
    you need to apply this for yourself by tomorrow

    https://scicomp.aalto.fi/triton/tut/connecting/

  editlist:
    - start: 00:45:22
    #- -: What's the login node?  What are we trying to do?
    - 00:45:58: SSH connection
    - 00:47:18: What you see once you log in?  The login node
    - 00:48:55: Connecting via Open OnDemand (web interface)
    - 00:52:34: VSCode Remote-SSH plugin
    - 00:57:06: Q&A and other wrap-up
    - 00:58:13: Exercise intro (Connecting) and how to ask questions during exercises
    - end: 00:59:42
    - start: 01:09:31
    - -: After the exercise, commentary, what comes next
    - stop: 01:11:17

- output: out/day1-csc.mkv
  title: 1.4  CSC resources for scientific computing, CSC
  description: >-
    What if you need more than what a university can provide?  In
    Finland, CSC (https://csc.fi, https://docs.csc.fi) have even more
    resources, and this is a tour of them.

  editlist:
  - start: 01:22:02
  - -: About CSC
  #- : Introduction
  - 01:54:55: Getting a CSC account and initial logins
  - 02:05:03: Log in to CSC OnDemand on the Mahti computer
  - 02:11:37: Running some on Mahti
  - 02:24:37: 'Q&A'
  - stop: 02:25:18
  #- : About CSC
  #- : CSC computing services
  #- : CSC cloud computing services
  #- : Programming for CSC supercomputers and other tech details
  #- : CSC data management and storage services
  #- : Other services
  #- : Topical trainings
  #- : Getting access to the services
  #- : Q&A
  #- end: 


- output: out/day1-setting-up-project.mkv
  title: 1.5 Setting up for a new project
  description: >-
    How do you get set up on the cluster?  This itself can be a bit of
    a process.  We discuss creating your directories, copying your code
    and data, and doing an initial test of the code.  We don't cover
    using the command line shell, data storage, and a lot of other
    important things in depth, but we have links to all of that.

    https://scicomp.aalto.fi/triton/tut/intro/

    https://scicomp.aalto.fi/triton/tut/cluster-shell/#triton-tut-example-repo

    https://scicomp.aalto.fi/triton/tut/storage/

    https://scicomp.aalto.fi/triton/tut/remotedata/

  editlist:
  - start: 03:21:19
  - 03:23:34: What is a cluster?
  - 03:25:13: From your computer to the cluster.  How?
  - 03:31:42: Introducing our example
  - 03:33:42: How to following along (demos vs exercise)
  - 03:35:10: Copying your code to the cluster (using git)
  - 03:38:48: Copying the data
  - 03:42:51: Initial test of code (on the login node)
  - 03:48:20: Exercise introduction (in notes)
  - stop: 03:51:11
  - start: 04:06:04
  - -: 'Discussion after the exercise, Q&A'
  - stop: 04:17:10


- output: out/day1-slurm.mkv
  title: '1.6 Slurm: the queueing system'
  description: >-
    Slurm is the "workload manager" or queuing system which manages
    all the resources.  It takes requests for jobs (CPU, memory, time,
    etc) and schedules them among all of the rest of the cluster.
    We discuss the basics of this system and we'll see how it actually
    works soon.

    https://scicomp.aalto.fi/triton/tut/slurm/
  editlist:
  - start: 04:28:34
  - 04:30:43: Slurm
  - 04:33:20: The resources managed by Slurm
  - 04:37:58: How many resources to allocate for a job?
  - stop: 04:40:46

- output: out/day1-interactive.mkv
  title: 1.7 Interactive jobs
  description: >-
    Before we get to scripted jobs (like most people use on the
    cluster), we will talk about interactive jobs.  This lets us get a
    little bit familiar with the Slurm system.  You shouldn't use this
    for running real calculations, but for testing and debugging, it is
    very useful.

    https://scicomp.aalto.fi/triton/tut/interactive/
  editlist:
  - start: 04:40:46
  - -: Why and what are interactive jobs?
  - 04:41:03: Run with srun
  - stop: 04:46:21

  #- 00:47:15: Running the jobs and looking at the history
  #- 00:56:24: Interactive shells
  #- 00:59:20: Checking job history
  #- 01:00:03: Exercise introduction and some Q&A
  #- stop: 01:02:02
  #- start: 01:17:12
  #- -: Post-exercise Q&A
  #- 01:19:12: Exercises Interactive-1 as a demo
  #- stop: 01:24:01



- output: out/day1-serial.mkv
  title: 1.8 Batch (Serial) jobs and day 1 wrap-up
  description: >-
     Running jobs in simple Slurm batch scripts: this is the starting point
     of everything that comes next.  This is the most important lesson
     that everything built up to, and everything else will build upon.

     https://scicomp.aalto.fi/triton/tut/serial/
  editlist:
  - start: 04:46:21
  - -: Make the script
  - 04:50:34: Run the script (and look at history)
  - 04:54:31: Why non-interactive is important
  - 04:56:18: Exercise preparation
  - stop: 04:58:05
  - start: 05:16:18
  - -: 'Q&A after the exercise'
  - 05:25:34: Preparation for the next day
  - stop: 05:30:02

  #- 01:42:59: Demo
  #- 01:56:46: Exercises
  #- stop: 01:58:08
  #- start: 02:31:06
  #- -: Q&A and discussion
  #- 02:32:18: Demo of exercises Serial-3 and Serial-5
  #- stop: 02:46:21



##- input: raw/day1b-obs.mkv
#
#- output: out/day1-ask-for-help.mkv
#  title: "1.8 How to ask for help with (super)computers"
#  description: >-
#      It’s dangerous to go alone, take us! Don’t waste time
#      struggling, there are plenty of people here for you.  This talk
#      gives you an insight into how to ask good questions, when to ask,
#      and who would be answering and trying to help you.
#
#      Right before this lesson, we had a technical problem (internet
#      outage) and thus had to switch broadcast computers.  Thus, we
#      had to change broadcaster on short notice, but it worked.  We
#      are sorry for the inconvenience.
#
#      https://zenodo.org/records/8392763
#
#  editlist:
#    - start: 00:02:03
#    - -: Intro
#    - 00:04:43: Begin presentation
#    - 00:27:09: Summary
#    - stop: 00:29:23
#
#- input: raw/day1c-obs.mkv
#
#- output: out/day1-vscode.mkv
#  title: "1.9 VScode on HPC"
#  description: >-
#
#    VS Code can be used as an interface to a cluster via the
#    Remote-SSH extension.  How does this work?  It has some advantages
#    and can be a good interface, but it comes with some extra things
#    you need to be careful about when connecting this way.
#
#    https://scicomp.aalto.fi/triton/apps/vscode/
#
#  editlist:
#    - start: 00:02:20
#    - end: 00:23:20
#
#- output: out/day1-qa.mkv
#  title: "1.10 Q&A and final comments, day 1"
#  description: >-
#    The final wrap-up / Q&A of day 1 and preparation for day 2,
#    including what to do to prepare.
#  editlist:
#    - start: 00:23:30
#    - stop: 00:30:44




- input: raw/day2-obs.mkv
- schedulesync: 00:45:58=10:31:44

- output: out/day2-the-humans-of-scientific-computing.mkv
  title: "2.1 The humans of scientific computing"
  description: >-
    Who are we that provide these services? What makes it such a
    fascinating career?  How did we learn what we know?  Learn about
    what goes on behind the scenes and how you could join us.  Our
    guest works at CSC - The IT Center for Science (https://csc.fi)

  editlist:
    - start: 00:15:48
    - stop: 00:36:59

- output: out/day2-conda.mkv
  title: "2.2 Conda"
  description: >-
    Conda is a package manager, not just for Python packages, but many
    types of scientific software: Python, R, compiled libraries, and
    so on.  It's become the easiest way to install a wide variety of
    software, whether on your own computer on or the cluster.  Here, we
    demo the basics, but you'll need to study the details for
    recommended practices of whatever cluster you work on: there may be
    different recommendations to preserve disk performance and so on.

    Mamba is an interchangeable replacement that is much faster at
    resolving the dependencies.  We mainly use Mamba.

    https://scicomp.aalto.fi/triton/apps/python-conda/

  editlist:
  - start: 00:36:59
  - -: About installing software; why is it hard?
  - 00:39:44: What is Conda?
  - 00:42:53: Usage of Mamba
  - 00:44:22: conda channels
  - 00:48:02: Environments via environment.yml files
  - 00:50:02: Building the environment from the yml file
  - 00:52:09: Using the built environment
  - 00:55:47: How to exit an environment
  - 00:58:15: Tykky container wrapper on CSC systems
  - 00:59:36: How this makes research reproducible
  - 01:02:38: Listing what is in an environment
  - 01:03:31: Removing an environment
  - 01:05:37: Conda environments with CUDA (for GPUs)
  - stop: 01:16:00


- output: out/day2-array.mkv
  title: 2.3 Array jobs
  description: >-
    When there is no dependency or communication among the individual
    program runs, these individual runs can be run in parallel on
    separate Slurm jobs called array jobs.  These are very useful and
    used often, including with other types of parallelism.

    https://scicomp.aalto.fi/triton/tut/array/

  editlist:
  - start: 01:27:14
  - -: Overview of array jobs
  - 01:29:37: Types of parallelism
  - 01:35:47: Start of array job demos
  - 01:37:41: Re-make the serial job from yesterday
  - 01:41:52: Transform the serial job to an array job
  - 01:49:36: Running the job
  - 01:53:23: Combine all the outputs to one
  - 01:55:55: Exercise intro
  - stop: 01:58:05
  - start: 02:10:28
  - -: After the exercise Q&A
  - stop: 02:16:57
  - start: 03:14:26
  - -: After break, example of hard-coding array parameters
  - stop: 03:21:18

- output: out/day2-monitoring.mkv
  title: 2.4 Monitoring jobs (summary)
  description: >-
    In order to use large amounts of resources, you need to be able to
    monitor how many resources you used, so that you can properly adjust
    the resources you request later.  We go over the main parts: output
    during the job, time, memory efficiency, CPU efficiency, GPU
    efficiency, and so on.

    We have already seen most of the content there, but we summarize
    everything now in one place.

    https://scicomp.aalto.fi/triton/tut/monitoring/
  editlist:
  - start: 03:21:18
  - 03:21:47: Checking while it is queuing
  - 03:22:47: Checking the history
  - 03:24:36: Example of checking efficiency
  - 03:30:30: 'Question: monitoring vs profilers'
  - 03:32:39: Efficiency info directly in the outputs
  - stop: 03:37:27


- output: out/day2-applications.mkv
  title: '2.5 Applications and Modules: software on the cluster'
  description: >-
    Software installation is one of our most time-consuming tasks in
    supporting cluster usage.  In "Applications", we'll talk about the
    general principles of managing software on the cluster: can you
    install things?  Do you need to ask us?  Do both happen at the
    same time?  Then we look at the `module` command that lets you
    make other pre-installed software available.

    https://scicomp.aalto.fi/triton/tut/applications/

    https://scicomp.aalto.fi/triton/tut/modules/
  editlist:
    - start: 03:37:27
    - 03:39:14: Demo, modules
    - 03:45:13: Demo, containers (apptainer/singularity)
    - 03:48:53: Conda
    - 03:49:53: Our pre-made conda environments
    - stop: 03:54:33


- output: out/day2-rcr.mkv
  title: 2.6 Responsible computational research
  description: >-
    Doing research comes with responsibilities, how to make sure the
    principles of research integrity are translated into scientific
    computing practices? We present a short structured view of ethical
    and legal considerations in computational research in Europe, with
    an extra overview of responsible use of generative AI for writing
    code.
  editlist:
  - start: 03:55:19
  - 03:57:29: The normative cascade
  - 03:58:58: 'Level 1: foundational ethical principles in research'
  - 04:00:42: EU legislation and regulations that can affect research
  - 04:02:19: National and university-level guidelines
  - 04:02:53: Researchers
  - 04:03:47: Responsible research in practice
  - 04:11:35: Generative AI considerations
  - stop: 04:16:27

- output: out/day2-parallel.mkv
  title: 2.7 Different methods of parallel computing
  description: >-
    Before we get to how to run parallel jobs, let's talk about the
    different forms, since a person must keep these straight in order
    to run them the right way on the cluster.  The forms are listed
    below.

    https://scicomp.aalto.fi/triton/tut/parallel/

  editlist:
  - start: 04:26:48
  - 04:27:44: Shared memory parallelism
  - 04:30:45: Demo of shared memory parallelism
  - 04:39:25: Q&A
  - 04:43:06: Exercise (shared memory)
  - stop: 04:43:32
  - start: 04:49:50
  - -: Message passing (MPI)
  - 04:53:59: Demo of MPI
  - 05:04:24: Exercise (MPI)
  - stop: 05:04:48
  - start: 05:09:47
  - -: Back from exercise
  - 05:12:56: Daily wrap-up / preparation for the next day
  - stop: 05:17:10


#- output: out/day2_01-icebreaker.mkv
#  title: 2.1 Icebreakers and introduction
#  description: >-
#    Icebreaker discussion of day 2.  Most people will go straight to
#    the other videos.
#  editlist:
#  - start: 00:11:27
#  - end: 00:22:05
#
#- output: out/day2_02-about-clusters.mkv
#  title: 2.2 About clusters and using them
#  description: >-
#    What is a cluster and why would we use one?  Brief reminder about
#    the previous day and comments on how to use them and ask for help.
#
#    https://scicomp.aalto.fi/triton/tut/intro/
#
#  editlist:
#  - start: 00:22:05
#  #- 00:36:04: How to get help
#  - end: 00:27:49
#
#- output: out/day2_03-slurm.mkv
#  title: '2.3 Slurm: the queueing system'
#  description: >-
#    Slurm is the "workload manager" or queuing system which manages
#    all the resources.  It takes requests for jobs (CPU, memory, time,
#    etc) and schedules them among all of the rest of the cluster.
#    We discuss the basics of this system and we'll see how it actually
#    works soon.
#
#    https://scicomp.aalto.fi/triton/tut/slurm/
#
#  editlist:
#  - start: 00:27:49
#  - 00:28:47: "Food metaphor: the HPC Diner"
#  - 00:34:40: The resources Slurm manages
#  - end: 00:44:30
#
#- output: out/day2_04-copying-code-to-cluster.mkv
#  title: 2.4 Copy your code to a cluster (git clone)
#  description: >-
#    We describe how to copy your code to the cluster.  We use this
#    later.
#
#    https://scicomp.aalto.fi/triton/tut/cluster-shell/#triton-tut-example-repo
#  editlist:
#    - start: 00:44:30
#    - stop: 00:45:52
#
#- output: out/day2_05-interactive.mkv
#  title: 2.5 Interactive jobs
#  description: >-
#    Before we get to scripted jobs (like most people use on the
#    cluster), we will talk about interactive jobs.  This lets us get a
#    little bit familiar with the Slurm system.  You shouldn't use this
#    for running real calculations, but for testing and debugging, it is
#    very useful.
#
#    https://scicomp.aalto.fi/triton/tut/interactive/
#  editlist:
#  - start: 00:45:52
#  - -: Why and what are interactive jobs?
#  - 00:47:15: Running the jobs and looking at the history
#  - 00:56:24: Interactive shells
#  - 00:59:20: Checking job history
#  - 01:00:03: Exercise introduction and some Q&A
#  - stop: 01:02:02
#  - start: 01:17:12
#  - -: Post-exercise Q&A
#  - 01:19:12: Exercises Interactive-1 as a demo
#  - stop: 01:24:01
#
#- output: out/day2_06-serial.mkv
#  title: 2.6 Serial jobs
#  description: >-
#     Running jobs in simple Slurm batch scripts: this is the starting point
#     of everything that comes next.  This is the most important lesson
#     that everything built up to, and everything else will build upon.
#
#     https://scicomp.aalto.fi/triton/tut/serial/
#  editlist:
#  - start: 01:34:37
#  - 01:42:59: Demo
#  - 01:56:46: Exercises
#  - stop: 01:58:08
#  - start: 02:31:06
#  - -: Q&A and discussion
#  - 02:32:18: Demo of exercises Serial-3 and Serial-5
#  - stop: 02:46:21
#
#
#- output: out/day2_08-applications.mkv
#  title: '2.8 Applications, Modules, Data, Remote data'
#  description: >-
#    We give a lightning overview of four topics: applications (how to
#    get software to run), modules (how some software is made
#    available), data storage (there are many options, and each with a
#    different trade-off: you do need to know these), and how to access
#    data remotely and transfer it.  Each of these could easily take
#    much longer time, but we only go over the high-level and then let
#    you read on your own time.
#
#    https://scicomp.aalto.fi/triton/tut/applications/
#
#    https://scicomp.aalto.fi/triton/tut/modules/
#
#    https://scicomp.aalto.fi/triton/tut/storage/
#
#    https://scicomp.aalto.fi/triton/tut/remotedata/
#  editlist:
#    - start: 03:33:23
#    - 03:35:10: Different ways of installing software on the cluster
#    - 03:39:36: Software installed by admin (modules)
#    - 03:42:25: Quick overview how software on cluster works
#    - 03:50:47: Short overview of using modules
#    - end: 03:54:42
#
#
##
##- output: out/day2-data-storage.mkv
##  title: 2.8 Data storage and accessing it remotely
##  description: >-
##    We go over data storage on the cluster: why it is important, main
##    considerations, where to store it, and so on.  We only give a bit of
##    discussion, and leave you to read for the details.
##
##    https://scicomp.aalto.fi/triton/tut/storage/
##
##    You have data on the cluster, but you need to be able to access it
##    from outside, or copy new data to the cluster.  This can be
##    surprisingly frustrating, so we discuss transferring data vs
##    mounting a remote filesystem for transparent access.
##
##    https://scicomp.aalto.fi/triton/tut/remotedata/
##
##  editlist:
##  - start: 03:53:32
##  - -: Different places of storing data
##  - 03:58:17: Overview of options on Triton
##  - 04:02:35: Explaining storage quotas
##  - 04:02:51: 'Remote access to data: basics'
##  - 04:06:17: Remote mounting
##  - 04:07:33: Transfering data
##  - end: 4:09:26
#
#
#- output: out/day2_09-outro.mkv
#  title: '2.9 Q&A day 2'
#  description: >-
#    Q&A with anything the audience throws at us.
#  editlist:
#  - start: 03:54:42
#  - end: 04:15:36
#- output: out/day2_10-outro.mkv
#  title: '2.10 Daily wrap-up, discussion, and Q&A'
#  description: >-
#    Wrap-up of the day, and preparing for the next day.
#  editlist:
#  - start: 04:15:36
#  - end: 04:19:11
#
##- output: out/day2-modules.mkv
##  title: 2.8 Software modules
##  description: >-
##    "module" is the command you use to make more software available.
##     Here, we go over the idea behind it, but mainly we leave it to
##     you to read the tutorial page.
##
##     https://scicomp.aalto.fi/triton/tut/modules/
##  editlist:
##  - start: 3:48:40
##  - end: 3:55:00
##
##
##- output: out/day2-remote-data.mkv
##  title: 2.10 Remote data access
##  description: >-
##    You have data on the cluster, but you need to be able to access it
##    from outside, or copy new data to the cluster.  This can be
##    surprisingly frustrating, so we discuss transferring data vs
##    mounting a remote filesystem for transparent access.
##
##    https://scicomp.aalto.fi/triton/tut/remotedata/
##  editlist:
##  - start: 4:07:28
##  - end: 4:17:03
#
#
#
#
#
#- input: raw/day3-obs.mkv
#
#- output: out/day3_01-icebreaker.mkv
#  title: 3.1 Icebreaker and intro
#  description: >-
#    Introduction of day 3.  Most people will go straight to the other
#    videos. This segment does however contain some useful discussion
#    about the goals of the course and how you should approach
#    learning scientific computing, given how overwhelming this course
#    can seem.
#  editlist:
#  - start: 00:10:57
#  - end: 00:22:29
#
#
#
#
#
#
#- output: out/day3_04-shared-memory.mkv
#  title: 3.4 Shared memory parallelism (part 1)
#  description: >-
#    Shared memory or multiprocessing parallelism can scale to one node
#    and allow communication between processors on a node.  This is run
#    with `--cpus-per-task`.
#
#    https://scicomp.aalto.fi/triton/tut/parallel-shared/
#  editlist:
#  - start: 01:44:19
#  - -: Overview of shared memory parallelism
#  - 01:49:27: 'Example: running pi.py in parallel'
#  - 02:02:54: Monitoring efficiency
#  - 02:04:02: More comments and Q&A on using this
#  - end: 02:11:21
#
#
#
#- output: out/day3_05-CSC-l2l.mkv
#  title: 3.5 From laptops to LUMI - CSC resources for researchers, CSC
#  description: >-
#    What if you need more than what a university can provide?  In
#    Finland, CSC (https://csc.fi, https://docs.csc.fi) have even more
#    resources, and this is a tour of them.
#
#    Slides:
#    https://github.com/AaltoSciComp/scicomp-docs/raw/master/training/scip/CSC-services_062024.pdf
#  editlist:
#  - start: 02:21:22
#  - -: About this talk, about CSC
#  - 02:23:00: Introduction
#  - 02:23:58: About CSC
#  - 02:29:42: CSC computing services
#  - 02:40:22: CSC cloud computing services
#  - 02:41:49: Programming for CSC supercomputers and other tech details
#  - 02:43:36: CSC data management and storage services
#  - 02:45:43: Other services
#  - 02:47:07: Topical trainings
#  - 02:48:53: Getting access to the services
#  - 02:51:49: Q&A
#  - end: 02:57:04
#
#
#
#
#- output: out/day3_06-MPI.mkv
#  title: 3.6 MPI overview
#  description: >-
#    MPI (message-passing interface) is the standard way for jobs to
#    communicate across processes or nodes on a massive scale.  Here,
#    we talk very briefly about how to run MPI jobs on a cluster.
#
#    https://scicomp.aalto.fi/triton/tut/parallel-mpi/
#  editlist:
#  - start: 02:58:14
#  - -: What is MPI?
#  - end: 03:07:54
#
#- output: out/day3_07-gpus.mkv
#  title: 3.7 GPU computing
#  description: >-
#    GPUs, short for graphical processing unit, are massively-parallel
#    processors that are optimized to perform parallel
#    operations. Computations that might take days to run on CPUs, take
#    substantially less time on GPUs.  We discuss how to use them with
#    Slurm and what are some common pitfalls when running these
#    programs, but we don't go into detail about just how they are
#    programmed or anything like that.
#
#    https://scicomp.aalto.fi/triton/tut/gpu/
#  editlist:
#  - start: 03:18:19
#  - -: What's a GPU and why?
#  - 03:22:31: What to think about using a GPU
#  - 03:26:21: 'Example: pi with CUDA on a GPU'
#  - 03:29:19: Monitoring performance and more
#
#  - end: 03:46:34
#
#- output: out/day3_08-outro.mkv
#  title: 3.8 General Q&A and day 3 and workshop wrap-up
#  description: >-
#    Wrap up of the workshop, including some hints about what to do
#    next, our future plans, etc.
#  editlist:
#  - start: 03:46:34
#  - -: General Q&A
#  - 04:12:58: Final wrap up and recommendations on where to go next.
#  - 04:17:50: Recommended follow-up courses
#  - end: 04:21:15
